---
title: "A Hodge-Podge Theory of Method (HP-TOM)"
author: "Matt Crump"
date: "`r format(Sys.time(), '%d %B, %Y')`"
twitter: "https://twitter.com/MattCrump_"
github: "https://github.com/CrumpLab"
website: "https://crumplab.gihub.io"
bibliography: refs.bib
csl: web/apa.csl
output: 
  html_document:
    template: web/template.html
    toc: true
    toc_float: true
    collapsed: false
    code_folding: show
    number_sections: false
    toc_depth: 4
    theme: yeti
    highlight: kate
    css: web/crump_basic.css
    includes:
      in_header: web/header.html
    md_extensions: -autolink_bare_uris
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

---

Once in a while the philosophies of science spin around my head making me wonder if I ascribe to any of them. Their proponents say I should, but the opponents say I shouldn't. At the end of the day, I just do things, make mistakes and learn from them. I'm guessing trying to form my own theory of method will be a mistake that I will learn from.

Because I'm very far behind in my reading of the philosophy of science, I don't know if anyone has proposed the hodge-podge theory of method. So, for fun, I'll propose it. The hodge-podge theory of method (HP-TOM) is: **do things that are useful for what you are doing**. Some additional tenets might be:

## Tenets of HP-TOM

1. Productive levels of vagueness are OK (a Lee Brooksism)
2. Fundamentalism in science is annoying (is there one ring to rule them all, is there really?)
3. The logical forms of "duction" do the things they do: deduction, induction, abduction...I'm "pro"-duction...a let-all-flowers-bloom gardener (i.e., do the things that are useful for what you are doing)
4. There don't appear to be ways to sign up as card-carrying affiliates of the "isms" of science. Do you really want that extra card?
5. Four is already too many for a chance at a coherent hodge-podge.

## How HP-TOM deals with big questions

1. Is the world real? YES.
2. Can we learn about the world using HP-TOM? YES.
3. Does HP-TOM sound like an IT-guy from Hewlett Packard? Yes.

## Theory isn't data. Theory is theory. Data is Data.

The other theory of methods seem to be mostly about the connection between theory and data and discovering the secrets of the universe. HP-TOM is about this too.

What is data in HP-TOM? Just records of observations made about the world using tools from within the world to make the observations.

What is theory in HP-TOM? Alien systems for explaining the structure of the observations. Systems is plural because it is possible to construct multiple systems to explain the same observations. Which one is right is one of the annoying questions (see tenet 2). Which ones are useful depend on what you are doing. Screwdrivers can be used to drive in specific screws, but they have other uses too. Same goes for theories. The systems are alien because of the next section.

## Being alone together

Some people say we are born alone and die alone. HP-TOM says this about theories and data. They are alone from each other from beginning to end.

Data can be borne alone without a theory to explain it. And, there is no doubt that plain old dust-bowl empiricism knows how to abandon data babies. The offspring from "what happens if I do X?" beats Ghengis Khan for number of progeny everytime. I suppose a datum borne in the absence of parent theoretical alternatives is in some sense not alone because of its many possible siblings; but those data are, according to HP-TOM, just besides themselves, and still alone without a reason for being.

In what sense does theory provide a reason for some data's being? According to HP-TOM, in a very alone sense. A theory is borne alone when it has enough internal structure to be capable of production. It produces cousins of the real data, but more like the fake cousins you wish you had (I love my real-life cousins). Just like the data, the cousin simulations have observable behavior, and the observable behavior of the cousins can be attributed to the theory that produced the behavior.

When the observable behavior of the simulated cousins matches, by some criteria, the behavior of the data, can the behavior of the data be attributed to the theory? No, because there is no DNA test for that, theories don't produce data, they produce simulated cousins of data, and even if there was a DNA test it would show that any plausible theory (e.g., one that could produce identical zombie cousins to the data) is a rightful parent. The court systems seem unprepared for multiple extra parent conception. So, theories are alien to their putative real-world data babies.

According to HP-TOM, theories and data are so alone from each other, that assigning theoretical parenthood to a data baby doesn't matter too much, if at all. So, what matters? That again depends on what you are trying to do, and I'll go more into that in the next section on "things that happen". HP-TOM doesn't pretend that nothing matters. It still embraces the logical "ductions". So, for example, some parent theories couldn't be parents of some data babies. Those ones have a way of producing cousin simulations that are too unlike the behavior of some data babies. But, if a parent theory is exposed as an uncle, aunt, or unrelated god-parent do they play no role in caring for the children? They could be useful for advice on what to do or not to do next. 

## Things that happen

People do things in science. They make the data and the theories. What are the goals of the things people are doing in science? HP-TOM doesn't have much to say about this. It's a bit like trying to figure out what other people really think when they are contestants on Survivor. Some of the things people say about what they are doing fall roughly into "basic" and "applied" science; perhaps involving goals of "explaining data" with a theory, perhaps with the eventual goal of "applying" the explanation to solve some problem; or perhaps to "add" to that ethereal library of human knowledge. There are many examples of this sort of success happening. HP-TOM organizes the things that happen in terms of what gets rubbed up against what.

## Rubbing theory against data

Rubbing theory against data is the hardest thing to do because they are so alone from each, and can't really be rubbed together at all. This enterprise might be better characterized in terms of spooky-rubbing-at-a-distance. It's spooky because when it works, it works. That is, when a productive theory is put into play in the real world, and it happens to line up (in a good-enough-way) with the structure of the real-world, then it goes some distance toward doing the things it says it will...and things like technology start working. 

HP-TOM isn't mean enough to reject theories when they rub the data the wrong way. It is mean enough to draw a grey zone between theories that have enough "duction" in them to do something tractable, and developing theories that partly do something (grey zone), or "dis-dunctional" hot messes that sit about inert abandon. Rejected theories are like internet memes that go out of popularity, but might return to relevance in the appropriate context; or like old laptops that you don't use, but keep around because they still work and you might use them one day.

As a sidenote, I use theories in my research to help me understand, at some productive level of vagueness, some ways in which process assumptions can work together to produce some behavior of interest. I find it useful, especially for generating new questions, and HP-TOM says this usefulness is OK, thanks HP-TOM.

## Rubbing data on itself

Data gets rubbed together all time. Theories be damned. Data babies are presumably related to each other in various ways, so it is natural to establish patterns of co-relationship by rubbing. The modern way to do this is by machine, for which there are many rubbing options to suit your taste.

Find a laundromat capable of cleaning your data. Make sure you have lots of examples. Project your data into a high-dimensional similarity space so it is truly rubbed onto itself as much as possible, fit a classifier to the space, tweak it until it has all been rubbed everywhere, and then accept your classifier accuracy for what it is. Data is as data rubs.

For all the shortcomings, there is no doubt that modern machine learning methods are capable of getting data to do things. When the methods work, that is just what they do. When they misclassify, they do that too.

Should you rub data against data? That depends on what you are trying to do. Maybe you should, maybe you shouldn't. What are you trying to do? HP-TOM doesn't know.

## Chaos everywhere

"Chaos in the brickyard" [@forscher1963chaos] is one of my favorite letters to science. It's a warning about overpopulation of data babies by dust-bowl empiricism (brickmakers), and urges population control by theoretical parenting (builders/architects). HP-TOM recognizes the opportunity for chaos, and it finds chaos outside of the brickyard too.

For example, what does HP-TOM say about Occam's razor? It doesn't much care about that. There will be all sorts of theories that could explain the same data. Is the simplest one the best one? Is the one with the most penalized parameter fits the best one? Is your pet theory the best one? There is no best one. There are just the many ones that are there. If there as many theories to explain one brick as there are bricks in need of a theory, there is chaos in the brickyard and the architect's office. And, that's OK, because the chaos is controlled, according to HP-TOM, when you do the things that are useful for what you are doing. 

## What should you be doing?

This isn't moral philosophy. That's way too hard.

## Does order matter?

I almost forgot why I used "hodge-podge" for this theory of method. Hodge podges are confused mixtures, much like the adornments on the houses in my neighborhood in Brooklyn (it's like folks rolled the dice each time they were deciding the style for their stairs, railings, porches, etc., it's so weird, but it's a thing). HP-TOM says that the order of doing things in science, especially with respect to theories making predictions about data, is a hodge podge: order doesn't matter much because theory and data are so alone to begin with, and they both do what they do largely independently from one another (what people claim about what those things do is a different story entirely).

So for example, does HP-TOM recommend pre-registration? It doesn't make a recommendation one way or the other with respect to the connection between theory and data (or lack of one). There are many benefits to pre-registering or registered reports that can be useful for what you are trying to do, so HP-TOM recommends those useful things when they are useful. But, HP-TOM allows for unordered confused mixtures as well (maybe that can be a new report type, oh wait it's the kind I do everytime).

For example, you have a semi-informed idea/insight (you're not perfect, you are where you are, you know what you know, you're still learning) that has enough push to get you collecting some data. You do that. The data is a confused mixture that prompts more thinking, and some theory development. You have some theories in a grey zone of development that make half-baked predictions, so you test them in a new experiment. But, when you collect the data and think about it and analyze it some more, you discover that what you did didn't make as much sense as you initially thought. And, you might sometimes be fortuitous in realizing that what you did happens to be useful for testing some predictions, perhaps even from different (possibly more developed) theories than you were initially thinking. HP-TOM says those theories make those predictions regardless of what you did, or when you did it. 

But what good is that? It depends. It's good for mapping theory to data, but not good for boasting about how you predicted everything after the fact. Because HP-TOM says that theories exist in a temporally disconnected alternate alien universe, it doesn't care about when the data was collected. Once the data is collected it will map onto some theories and not others. The mapping is an atemporal property of the strength of the match between the theory and data. Any regions of the theory that map to the data are mappable. Of course, if the theory specifies many additional mappings that can't be tested by the data, nothing else can be said until additional data appropriate to mapping the uncharted territory is obtained. And, if one region of the theory is mapped to the data, it doesn't mean the rest of the untested mappings would map.

## The value of explanation

I'm getting the feeling from HP-TOM that it doesn't place much value on explanation. Perhaps so. HP-TOM says the value in explaining depends on what you are doing. It's clear that HP-TOM says you can collect some data, then create a theory of any complexity to "explain" the data. HP-TOM says, "have fun with that, if that's what you want to do." If you want to take that explanation for test drive in the real world, HP-TOM will cross its fingers for you, but that is all. If you are incrementally building and testing and refining an explanation that applies across increasing swaths of data babies, then HP-TOM might say, "you've got a point there".

## The value of HP-TOM

By definition, a hodge podge.

## References
