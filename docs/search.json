[
  {
    "objectID": "Publications.html",
    "href": "Publications.html",
    "title": "Publications",
    "section": "",
    "text": "Copyright Notice: Some of the documents listed below are available for downloading. They are provided as a means to ensure timely dissemination of scholarly and technical work on a noncommercial basis. Copyright and all rights therein are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by each author’s copyright. These works may not be re-posted without the explicit permission of the copyright holder."
  },
  {
    "objectID": "Publications.html#in-progress",
    "href": "Publications.html#in-progress",
    "title": "Publications",
    "section": "In Progress",
    "text": "In Progress\n\nCrump, M. J. C. (2021). Instances of cognition: Questions, methods, findings, explanations, applications, and implications. (1st ed.). crumplab.com.   website    github \nPiech, R. M., Crump, M. J., & Zald, D. H. (2021). The negative contingency illusion: A cognitive bias leading to misjudgement of protection. https://doi.org/10.21203/rs.3.rs-671507/v1   pdf \nBrosowsky, N., Parshina, O., Locicero, A., & Crump, M. (2020). Teaching undergraduate students to read empirical articles: An evaluation and revision of the QALMRI method. https://doi.org/10.31234/osf.io/p39sc   pdf"
  },
  {
    "objectID": "Publications.html#published",
    "href": "Publications.html#published",
    "title": "Publications",
    "section": "Published",
    "text": "Published\n\nBehmer, L. P., Crump, M. J. C., & Jantzen, K. J. (2023). Motor-evoked potentials for early individual elements of an action sequence during planning reflect parallel activation processes. Motor Control, 1–20. https://doi.org/10.1123/mc.2022-0106 \nBrosowsky, N. P., & Crump, M. J. C. (2021). Contextual recruitment of selective attention can be updated via changes in task relevance. Canadian Journal of Experimental Psychology, 75, 19–34. https://doi.org/10.1037/cep0000221   pdf    data \nVuorre, M., & Crump, M. J. C. (2021). Sharing and organizing research products as r packages. Behavior Research Methods, 53, 792–802. https://doi.org/10.3758/s13428-020-01436-x   pdf    website    github \nCrump, M. J. C., Jamieson, R. K., Johns, B. T., & Jones, M. N. (2020). Controlling the retrieval of general vs specific semantic knowledge in the instance theory of semantic memory. In S. Denison, M. Mack, Y. Xu, & B. C. Armstrong (Eds.), Proceedings of the 42nd annual conference of the cognitive science society (pp. 3261–3267). Cognitive Science Society.   pdf    website \nCrump, M. J. C. (2020). Reproducible statistics for psychologists with r: Lab tutorials. OSF. https://crumplab.github.io/rstatsforpsych/   website \nJohns, B. T., Jamieson, R. K., Crump, M. J. C., Jones, M. N., & Mewhort, D. J. K. (2020). Production without rules: Using an instance memory model to exploit structure in natural language. Journal of Memory and Language, 115, 104165. https://doi.org/ghcm2c   pdf \nAujla, H., Crump, M. J. C., Cook, M. T., & Jamieson, R. K. (2019). The semantic librarian: A search engine built from vector-space models of semantics. Behavior Research Methods, 51(6), 2405–2418. https://doi.org/gf6cmv   pdf    website \nBraem, S., Bugg, J. M., Schmidt, J. R., Crump, M. J. C., Weissman, D. H., Notebaert, W., & Egner, T. (2019). Measuring adaptive control in conflict tasks. Trends in Cognitive Sciences, 23(9), 769–783. https://doi.org/gf48x7   pdf \nCrump, M. (2019). Answering questions with data: Course website. https://doi.org/ghrn62   website \nCrump, M., Navarro, D., & Suzuki, J. (2019). Answering questions with data (textbook): Introductory statistics for psychology students. https://doi.org/ghrn59   website \nCrump, M., Krishnan, A., Volz, S., & Chavarga, A. (2019). Answering questions with data: The lab manual for r, excel, SPSS and jamovi. https://doi.org/ghrn63   website \nCrump, M. J. C., Lai, W., & Brosowsky, N. P. (2019). Instance theory predicts information theory: Episodic uncertainty as a determinant of keystroke dynamics. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 73(4), 203–215. https://doi.org/http://dx.doi.org/10.1037/cep0000182   pdf    website \nCrump, M. J. C. (2019). Portfolio and prosper. Nature Human Behaviour, 3(10), 1008–1008. https://doi.org/ghrnn6   pdf \nBehmer, L. P., Jantzen, K. J., Martinez, S., Walls, R., Amir-Brownstein, E., Jaye, A., Leytze, M., Lucier, K., & Crump, M. J. C. (2018). Parallel regulation of past, present, and future actions during sequencing. Journal of Experimental Psychology: Human Perception and Performance, 44(8), 1147–1152. https://doi.org/gdznzb   pdf \nBrosowsky, N. P., & Crump, M. J. C. (2018). Memory-guided selective attention: Single experiences with conflict have long-lasting effects on cognitive control. Journal of Experimental Psychology: General, 147(8), 1134–1153. https://doi.org/gd2w6z   pdf \nCrump, M. J. C., Milliken, B., Leboe-McGowan, J., Leboe-McGowan, L., & Gao, X. (2018). Context-dependent control of attention capture: Evidence from proportion congruent effects. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 72(2), 91–104. https://doi.org/gdrskv   pdf \nCrump, M. J. C., Brosowsky, N. P., & Milliken, B. (2017). Reproducing the location-based context-specific proportion congruent effect for frequency unbiased items: A reply to hutcheon and spieler (2016). Quarterly Journal of Experimental Psychology, 70(9), 1792–1807. https://doi.org/gcx8qn   pdf    data \nBehmer, L. P., & Crump, M. J. C. (2017). The dynamic range of response set activation during action sequencing. Journal of Experimental Psychology: Human Perception and Performance, 43(3), 537–554. https://doi.org/f9w78w   pdf \nBehmer, L. P., & Crump, M. J. C. (2017). Crunching big data with finger tips: How typists tune their performance towards the statistics of natural language. In M. N. Jones (Ed.), Big data in cognitive science (pp. 319–341). Routledge.   pdf    data \nBehmer, L. P., & Crump, M. J. C. (2017). Spatial knowledge during skilled action sequencing: Hierarchical versus non-hierarchical representations. Attention, Perception & Psychophysics, 79, 2435–2448. https://doi.org/10.3758/s13414-017-1389-3   pdf \nZumsteg, J. W., Crump, M. J., Logan, G. D., Weikert, D. R., & Lee, D. H. (2017). The effect of carpal tunnel release on typing performance. The Journal of Hand Surgery, 42(1), 16–23. https://doi.org/f9mjkj   pdf \nBrosowsky, N. P., & Crump, M. J. C. (2016). Context-specific attentional sampling: Intentional control as a pre-requisite for contextual control. Consciousness and Cognition, 44, 146–160. https://doi.org/f848wz   pdf \nCrump, M. J. C. (2016). Learning to selectively attend from context-specific attentional histories: A demonstration and some constraints. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 70(1), 59–77. https://doi.org/gf7h25   pdf \nCurtis, E. T., Chubala, C. M., Spear, J., Jamieson, R. K., Hockley, W. E., & Crump, M. J. C. (2016). False recognition of instruction-set lures. Memory, 24, 32–43. https://doi.org/10.1080/09658211.2014.982657   pdf \nJohns, B. T., Jamieson, R., Crump, M., Jones, M. N., & Mewhort, D. J. (2016). The combinatorial power of experience. Proceedings of the 38th Annual Conference of the Cognitive Science Society.   pdf \nCrump, M. J. C., McDonnell, J. V., & Gureckis, T. M. (2013). Evaluating amazon’s mechanical turk as a tool for experimental behavioral research. PLoS ONE, 8(3), e57410. https://doi.org/f4qw94   pdf \nCrump, M. J. C., & Logan, G. D. (2013). Prevention and correction in post-error performance: An ounce of prevention, a pound of cure. Journal of Experimental Psychology: General, 142(3), 692–709. https://doi.org/f46hg6   pdf    data \nYamaguchi, M., Crump, M. J. C., & Logan, G. D. (2013). Speed–accuracy trade-off in skilled typewriting: Decomposing the contributions of hierarchical control loops. Journal of Experimental Psychology: Human Perception and Performance, 39(3), 678–699. https://doi.org/10.1037/a0030512   pdf \nBugg, J. M., & Crump, M. J. C. (2012). In support of a distinction between voluntary and stimulus-driven control: A review of the literature on proportion congruent effects. Frontiers in Psychology, 3(367), 1–16. https://doi.org/10.3389/fpsyg.2012.00367   pdf \nCrump, M. J. C., Logan, G. D., & Kimbrough, J. (2012). Keeping an eye on guitar skill: Visual representations of guitar chords. Music Perception: An Interdisciplinary Journal, 30(1), 37–47. https://www.jstor.org/stable/10.1525/mp.2012.30.1.37   pdf \nCrump, M. J. C. (2012). Review of guitar zero: The new musician and the science of learning. https://doi.org/10.1037/a0030741   pdf \nJamieson, R. K., Crump, M. J. C., & Hannah, S. D. (2012). An instance theory of associative learning. Learning & Behavior, 40(1), 61–82. https://doi.org/dwkrm5   pdf \nLogan, G. D., & Crump, M. J. C. (2011). Hierarchical control of cognitive processes: The case for skilled typewriting. In B. H. Ross (Ed.), Psychology of learning and motivation (Vol. 54, pp. 1–27). Elsevier.   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Contextual control over task-set retrieval. Attention, Perception, & Psychophysics, 72(8), 2047–2053. https://doi.org/c6psw7   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Warning: This keyboard will deconstruct— the role of the keyboard in skilled typewriting. Psychonomic Bulletin & Review, 17(3), 394–399. https://doi.org/d9jmzm   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Hierarchical control and skilled typing: Evidence for word-level control over the execution of individual keystrokes. Journal of Experimental Psychology: Learning, Memory, and Cognition, 36(6), 1369–1380. https://doi.org/ccjxg5   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Episodic contributions to sequential control: Learning from a typist’s touch. Journal of Experimental Psychology: Human Perception and Performance, 36(3), 662–672. https://doi.org/ccw3b5   pdf \nJamieson, R. K., Hannah, S. D., & Crump, M. J. C. (2010). A memory-based account of retrospective revaluation. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 64(3), 153–164. https://doi.org/fn46rb   pdf \nLiu, X., Crump, M. J. C., & Logan, G. D. (2010). Do you know where your fingers have been? Explicit knowledge of the spatial layout of the keyboard in skilled typists. Memory & Cognition, 38(4), 474–484. https://doi.org/ccq7jw   pdf \nLogan, G. D., & Crump, M. J. C. (2010). Cognitive illusions of authorship reveal hierarchical error detection in skilled typists. Science, 330(6004), 683–686. https://doi.org/bktxxk   pdf \nCrump, M. J. C., & Milliken, B. (2009). The flexibility of context-specific control: Evidence for context-driven generalization of item-specific control settings. The Quarterly Journal of Experimental Psychology, 62(8), 1523–1532. https://doi.org/10.1080/17470210902752096   pdf \nHannah, S. D., Crump, M. J. C., Allan, L. G., & Siegel, S. (2009). Cue-interaction effects in contingency judgments using the streamed-trial procedure. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 63(2), 103–112. https://doi.org/fgwn3x   pdf \nLogan, G. D., & Crump, M. J. C. (2009). The left hand doesn’t know what the right hand is doing: The disruptive effects of attention to the hands in skilled typewriting. Psychological Science, 20(10), 1296–1300. https://doi.org/10.1111/j.1467-9280.2009.02442.x   pdf \nSiegel, S., Allan, L. G., Hannah, S. D., & Crump, M. J. C. (2009). Applying signal detection theory to contingency assessment. Comparative Cognition & Behavior Reviews, 4, 116–134. https://doi.org/10.3819/ccbr.2009.40012   pdf \nAllan, L. G., Hannah, S. D., Crump, M. J. C., & Siegel, S. (2008). The psychophysics of contingency assessment. Journal of Experimental Psychology: General, 137(2), 226–243. https://doi.org/10.1037/0096-3445.137.2.226   pdf \nCrump, M. J. C., Vaquero, J. M. M., & Milliken, B. (2008). Context-specific learning and control: The roles of awareness, task relevance, and relative salience. Consciousness and Cognition, 17(1), 22–36. https://doi.org/d2fm7p   pdf \nCrump, M. J. C., Milliken, B., & Ansari, I. (2008). Shifting views on the symbolic cueing effect: Cueing attention through recent prior experience. Psicológica, 29(1), 97–114. https://CrumpLab.github.io/CognitionPerformanceLab/CrumpPubs/Crump et al. - 2008.pdf   pdf \nLeboe, J. P., Wong, J., Crump, M. J. C., & Stobbe, K. (2008). Probe-specific proportion task repetition effects on switching costs. Perception & Psychophysics, 70(6), 935–945. https://doi.org/10.3758/PP.70.6.935   pdf \nCrump, M. J. C., Hannah, S. D., Allan, L. G., & Hord, L. K. (2007). Contingency judgements on the fly. Quarterly Journal of Experimental Psychology, 60(6), 753–761. https://doi.org/b9jjc4   pdf \nSchmidt, J. R., Crump, M. J. C., Cheesman, J., & Besner, D. (2007). Contingency learning without awareness: Evidence for implicit control. Consciousness and Cognition, 16(2), 421–435. https://doi.org/d9bv53   pdf \nCrump, M. J. C., Gong, Z., & Milliken, B. (2006). The context-specific proportion congruent stroop effect: Location as a contextual cue. Psychonomic Bulletin & Review, 13(2), 316–321. https://doi.org/fpxkfs   pdf"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "crumplab",
    "section": "",
    "text": "The Computational Cognition Lab at Brooklyn College of CUNY investigates learning, memory, attention, performance, and semantic cognition.\nCurrent and previous lab members include undergraduate, master’s , doctoral, and postdoctoral researcher associates.\nThe lab is located in the Department of Psychology at Brooklyn College of CUNY, and affiliated with the Cognitive and Comparative Psychology Training area of the Psychology Doctoral program at the Graduate Center of CUNY."
  },
  {
    "objectID": "index.html#pages",
    "href": "index.html#pages",
    "title": "crumplab",
    "section": "Pages",
    "text": "Pages\n\n\n\n\n  \n\n\n\n\nBlog\n\n\n\n\n\nVarious musings, usually about cognition, teaching, and other stuff, incomplete notes, digital breadcrumbs on scratchpads.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPeople\n\n\n\n\n\nThe lab is run by Dr. Matthew Crump and student research assistants from undergraduates to doctoral students.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPublications\n\n\n\n\n\nPeer-reviewed publications. They should all have downloadable pdfs, and if they don’t email me.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBooks\n\n\n\n\n\nOpen-educational textbooks and resources developed written by Matt Crump. These resources are free to use and share.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nCourses\n\n\n\n\n\nA list of current and previous courses taught at Brooklyn College of CUNY and the Graduate Center of CUNY. Many of them include freely shared course materials.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nJoin\n\n\n\n\n\nInterested in joining the lab? Check this page out.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFun\n\n\n\n\n\nSome links to extra-curricular fun stuff like music and visual creations.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nYoutube Channel\n\n\n\n\n\nThis channel contains screencasts and tutorial videos, as well as lectures for whole courses. The focus is usually on cognition or learning programming skills (R mostly) for psychologists.\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "crumplab",
    "section": "Contact",
    "text": "Contact\nMatthew Crump\n\nProfessor\nDepartment of Psychology\nBrooklyn College of CUNY\n2900 Bedford Avenue, Brooklyn, NY 11210\nOffice: 4401 James Hall\nPhone: 718-951-5000 x. 6068\nemail: mcrump@brooklyn.cuny.edu\nLab: 4303 James Hall"
  },
  {
    "objectID": "People.html#lab-members",
    "href": "People.html#lab-members",
    "title": "People",
    "section": "Lab Members",
    "text": "Lab Members\n\n\n\n\n\n\n\n\n\n\nMatt Crump\n\n\nPrincipal Investigator mcrump@brooklyn.cuny.edu\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrew Shives\n\n\nDoctoral Student\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWesley Huang\n\n\nUndergraduate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShifa Maqsood\n\n\nUndergraduate\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "People.html#previous",
    "href": "People.html#previous",
    "title": "People",
    "section": "Previous",
    "text": "Previous\n\nPostdoctoral\n\nLawrence Behmer (2014 - 2017), Idaho State University\n\n\n\nDoctoral\n\nNicholaus Brosowsky (2014 - 2019), University of Manitoba\nKevonte Mitchell (2012 - 2023), Mit + Mill Consulting\n\n\n\nMasters\n\n2016: Ashot Balayan, “Subjective Confidence in the Evaluations of Typing Speed:Testing the Self-Consistency Model”, Master’s Thesis\n2016: Michelle Villavicencio, “Aesthetic Preference in Dance Movement: Motor Fluency and the Mere Exposure Effect”, Master’s Thesis\n\n\n\nUndergraduate\n\n2022: Patrick Ihejirika, “Try and forget this image: The role of stimulus duration in directed forgetting for natural scenes”, Undergraduate MARC Honors thesis, Barry Goldwater Scholar\n2022: Kendra Scarlett Reynoso Moreno, Undergraduate CUNY BA Program\n2021: Austin Kaplan, “Explaining contingency judgments with a computational model of instance-based memory”, Undergraduate Honors Thesis\n2019: Mark Rayev, “Deception detection through word usage and word production time in typing”, Undergraduate Macaulay Honors\n2018: Walter Lai, Contributing author on “Instance theory predicts information theory: Episodic uncertainty as a determinant of keystroke dynamics”, currently completing a Masters in Data Science at Southern Methodist University\n2018: Rochelle Hall, Undergraduate REU\n2017: Chin Tan, “Examining cognitive control and information theory accounts of mid-word slowing in skilled typing”, Undergraduate\n2017: Marissa Scotto, Undergraduate REU\n2016: Niles Uy, “A twofold investigation into the nature of dual-task interference”, Honor’s Thesis\n2016: Ana Sanchez, “EEG and learning to type on a novel keyboard”, REU program\n2015: Shawn Lauzon, “Escape from the canyon: an objective measure of insight through convergent and divergent thinking”, Independent Study\n2015: Rebecca Colon, “Resource Demands of a Dual-Task Disrupts Skilled Typing”, REU program\n2014-2015: Elena Dominguez, “Explaining the list-wide proportion congruent effect”, “Reliability and precision of basic and manipulated flanker tasks”, MARC program, currently a Ph.D. Candidate at UCI\n2014: Michael Blecher, “False-recognition by test-induced priming for non-studied lists”, Independent Study\n2014: Niles Uy, “Is the flanker task reliable?”, Independent Study, went on to KU Leuven for a Masters in Statistics\n2013: Emily Paolillo, “The role of explicit and implicit knowledge in typing skill”, Honor’s Thesis. Completing a Ph.D. in Neuropsychology @ UC San Diego\n2013: Esthena Brutten, “Online investigations of contextual interference in motor learning”, Independent Study\n2013: Esthena Brutten, “Proportion congruent manipulations on Amazon’s mechanical Turk”, Honor’s thesis"
  },
  {
    "objectID": "people/wesley_huang.html",
    "href": "people/wesley_huang.html",
    "title": "Wesley Huang",
    "section": "",
    "text": "Wesley Huang is an undergraduate researcher, and presidential mentoring initiative scholar for Fall 2022."
  },
  {
    "objectID": "people/shifa_maqsood.html",
    "href": "people/shifa_maqsood.html",
    "title": "Shifa Maqsood",
    "section": "",
    "text": "Shifa Maqsood is an undergraduate researcher, and Tow presidential mentoring scholar for Spring 2023."
  },
  {
    "objectID": "people/matt_crump.html",
    "href": "people/matt_crump.html",
    "title": "Matt Crump",
    "section": "",
    "text": "Matt Crump is a cognitive psychologist with research interests in learning, memory, attention, skill learning, semantics, and computational modeling. He runs the computational cognition lab at Brooklyn College of CUNY."
  },
  {
    "objectID": "people/matt_crump.html#education",
    "href": "people/matt_crump.html#education",
    "title": "Matt Crump",
    "section": "Education",
    "text": "Education\nPostdoc, Vanderbilt University - 2011 (Psychology)\nPh.D., McMaster University - 2007 (Psychology)\nB.Sc., University of Lethbridge - 2002 (Psychology)"
  },
  {
    "objectID": "people/matt_crump.html#experience",
    "href": "people/matt_crump.html#experience",
    "title": "Matt Crump",
    "section": "Experience",
    "text": "Experience\nAssistant Professor - Brooklyn College of CUNY (2011)\nAssociate Professor - Brooklyn College of CUNY (2016)\nFull Professor - Brooklyn College of CUNY (2022)"
  },
  {
    "objectID": "people/drew_shives.html",
    "href": "people/drew_shives.html",
    "title": "Drew Shives",
    "section": "",
    "text": "Drew Shives is a doctoral student at the Graduate Center of CUNY."
  },
  {
    "objectID": "Opportunities.html",
    "href": "Opportunities.html",
    "title": "Join",
    "section": "",
    "text": "Dr. Crump has mentored students interested in cognition at all levels, including undergraduate, master’s, doctoral, and postdoctoral researchers. The lab is always looking for students interested in human cognition (how people think, learn, remember, attend, etc.), and who want to gain research experience by learning computational techniques for running experiments and analyzing data. This page describes current opportunities for prospective students at the undergraduate, master’s, doctoral levels. Interested students should also read some of the lab publications to learn more about the research questions we are asking."
  },
  {
    "objectID": "Opportunities.html#undergraduate-students",
    "href": "Opportunities.html#undergraduate-students",
    "title": "Join",
    "section": "Undergraduate students",
    "text": "Undergraduate students\nIt is possible to gain research experience as an undergraduate at Brooklyn College, and the skills gained through these experiences can open doors for career opportunities, including pursuing advanced degrees. Dr. Crump is especially interested in mentoring students through the process of completing an undergraduate honor’s thesis in their senior year (see here for departmental requirements). However, students interested in pursuing an honor’s thesis should get lab experience before their final year.\nThe honor’s thesis consists of two semesters of Independent Research (e.g., Psych 5001 and 5002) and culminates in writing a thesis covering the research conducted over the year. The honor’s thesis option is a great opportunity for students interested in pursuing research in a Ph.D. program following undergraduate studies. The honor’s thesis is a major commitment in time and effort for everyone involved, and interested students need to plan ahead.\nStudents who join the lab enroll in research classes so that they receive course credit as they gain research experience in the lab. If you are interested in taking one of the courses, please complete the entry assignment, and then email Dr. Crump about availability. The classes include:\n\nPsych 2001-4 Laboratory Experience (3 credits each)\nPsych 5001-4 Independent Research (3 credits each)\n\nThe Laboratory Experience courses are intended for students who are new to research, and the Independent Research courses are for more senior students (typically completing an honors thesis). They are each one semester long, and involve conducting research in the lab and writing a research report as a final project.\nRecent undergraduate research projects completed in the lab.\n\n2022: Patrick Ihejirika, “Try and forget this image: The role of stimulus duration in directed forgetting for natural scenes”, Undergraduate MARC Honors thesis, Barry Goldwater Scholar\n2019: Mark Rayev, “Deception detection through word usage and word production time in typing”, Undergraduate Macaulay Honors\n2018: Walter Lai, Contributing author on “Instance theory predicts information theory: Episodic uncertainty as a determinant of keystroke dynamics”, currently completing a Masters in Data Science at Southern Methodist University"
  },
  {
    "objectID": "Opportunities.html#masters-students",
    "href": "Opportunities.html#masters-students",
    "title": "Join",
    "section": "Master’s Students",
    "text": "Master’s Students\nThe Master’s of Arts in Experimental Psychology is a two-year research focused master’s program at Brooklyn College. The program website describes general information about the program. Students in the program conduct research with a faculty mentor over two years culminating in a thesis. Master’s students in the computational cognition lab will work with Dr. Crump over two years to complete a research project in cognition.\nStudents will learn advanced statistics, data-analysis, and computational modelling skills, and apply them to research questions in cognition. Students will also learn how to create, conduct, and analyze online behavioral experiments. The degree is typically completed in two years, by taking three courses per semester. Each semester one of the courses involves independent reading and research in the lab. In the first semester, students will acquire sub-domain expertise about a cognitive phenomena through an extensive literature review. The literature review will suggest new directions for empirical work. The second semester of independent research will involve proposals for experiments, and collection of pilot data. By, the second year students should have a well-developed research project that will form the basis for their thesis. Master’s student research projects can also be submitted for publication in peer-reviewed journals."
  },
  {
    "objectID": "Opportunities.html#doctoral-students",
    "href": "Opportunities.html#doctoral-students",
    "title": "Join",
    "section": "Doctoral students",
    "text": "Doctoral students\nStudents interested in pursuing a Ph.D. should apply to the Cognitive and Comparative Psychology (CCP) training area in the Psychology Doctoral Program at the Graduate Center of CUNY. The deadline for applications is December 1st. You can apply directly here. Interested applicants should also email Matt Crump (mcrump@brooklyn.cuny.edu) to introduce themselves, their research interests, and why they want to gain research skills in the lab"
  },
  {
    "objectID": "Opportunities.html#entry",
    "href": "Opportunities.html#entry",
    "title": "Join",
    "section": "Entry Assignment",
    "text": "Entry Assignment\nIf you’re interested in becoming part of the lab (volunteering, taking a course etc.), the first thing to do is to complete this entry assignment. The assignment consists of writing a small computer program (no previous programming experience necessary, this is an invitation to start learning programming skills).\n\nWhy are we asking you to do this?\nA lot of the activities in the lab involve computer programming: during experiments, the timing, stimulus presentation and key press registration are all controlled by programs we write ourselves. When we analyze the data from the experiments, we again do this in programs, written by us, which take the raw data, calculate things such as averages, display results in graphs, and perform statistical tests.\nThis assignment allows you to demonstrate your interest in this type of activity, and by investing some time in this assignment you can show your commitment to becoming part of the lab.\n\n\nInstructions\nHere is your assignment. By following these steps you will make a website, and then attempt to solve a problem in R. It sounds complicated, but everything you need to get started is right here, by following these steps:\n\nDownload R and R-studio for your computer.\nMake yourself a github account.\nGeneral info about making websites with R Markdown is here, but see next point for downloading an example you can use straight away. https://rmarkdown.rstudio.com/rmarkdown_websites.htm\nFollow these steps to get started:\n\nthe repository is here https://github.com/CrumpLab/LabJournalWebsite\nFollow the instructions in the read me file for how to compile the website in R-studio, and then host it on github\nYou can see what the website will look like once you get it up and runnning here https://crumplab.github.io/LabJournalWebsite/index.html\nFollow the instructions inside the source for the website, and by reading the website to get started learning R. For example, in the example website, you can read the journal page, that explains the process. You will see there are some example problems to solve in R, and a link to more problems to solve. I solved the first three, you assignment is to attempt to solve one more problem.\n\nAssuming you got everything up and running, then you can send me an email (mcrump@brooklyn.cuny.edu) introducing yourself. Link to your website that you made, and tell me a little bit about why you want to join the lab and we’ll set up a meeting.\n\nEmail your R-script to Dr. Crump (mcrump@brooklyn.cuny.edu) and request a time to meet about gaining research experience in the lab."
  },
  {
    "objectID": "Blog.html",
    "href": "Blog.html",
    "title": "Blog",
    "section": "",
    "text": "Various musings, usually about cognition, teaching, and other stuff, incomplete notes, digital breadcrumbs on scratchpads.\n\n\n\n\n  \n\n\n\n\nA simple visual art portfolio website using Quarto\n\n\n\n\n\n\n\nQuarto\n\n\nportfolio\n\n\nart\n\n\n\n\nNotes on using Quarto to create a basic portfolio website for pictures using list pages.\n\n\n\n\n\n\nJul 13, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nPondering my defaults for Quarto websites and reproducible research projects\n\n\n\n\n\n\n\nQuarto\n\n\nreproducible research\n\n\nrstats\n\n\n\n\nQuarto websites are a great way to package and distribute assets from a reproducible research project. I’m just about to start another project, and I’m thinking about issues with how I get started.\n\n\n\n\n\n\nJun 27, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nAdding a giscus comment section?\n\n\n\n\n\n\n\nBlogging\n\n\ngiscus\n\n\n\n\nTesting out adding a giscus comment section to a blog post.\n\n\n\n\n\n\nJun 26, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nObservations on using LLMs for checking grammar, etc.\n\n\n\n\n\n\n\nLLMs\n\n\nOpenAI\n\n\nShiny\n\n\nRstats\n\n\nRStudio\n\n\nAssisted writing\n\n\n\n\nIn recent posts I’ve been making add-ins and a shiny app for writing assistance tools in R Studio, where I do most of my writing. I’m finally starting to get some usable results. Discussing some observations about the process in this post.\n\n\n\n\n\n\nJun 23, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nScratchpad: Grammar checking Quarto documents with the OpenAI API\n\n\n\n\n\nThis is a scratchpad post. I would like better grammar checking for documents that I write in Rstudio, and I know that I could cobble something together using the OpenAI API. I’m using this post to do the cobbling, which may not result in a working solution. Fingers crossed.\n\n\n\n\n\n\nJun 22, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nPrompts for editing text with GPT\n\n\n\n\n\n\n\nLLMs\n\n\nRstats\n\n\nRStudio\n\n\nAssisted writing\n\n\n\n\nTesting out some strategies for writing assistant functions from GPT\n\n\n\n\n\n\nJun 21, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nChoose-your-own adventure with ChatGPT\n\n\n\n\n\n\n\nLLMs\n\n\nRstats\n\n\nRStudio\n\n\nAssisted writing\n\n\n\n\nMe fiddling around with GPT inside Rstudio to write a choose-your-own adventure story.\n\n\n\n\n\n\nJun 20, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nWriting an R tutorial with GPT in RStudio\n\n\n\n\n\n\n\nLLMs\n\n\nOpenAI\n\n\nRstats\n\n\nRStudio\n\n\nAssisted writing\n\n\n\n\nI’m testing out the process of writing in RStudio using addins that send prompts and receive generative text from OpenAI.\n\n\n\n\n\n\nJun 8, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nUsing GPT for writing in R Studio\n\n\n\n\n\n\n\nLLMs\n\n\nOpenAI\n\n\nRstats\n\n\nRStudio\n\n\n\n\nI’m spending the morning writing addins for RStudio that interface with the OpenAI API. This should make it possible to integrate GPT as a writing aid inside RStudio.\n\n\n\n\n\n\nJun 7, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nSimulating Stroop effects with ChatGPT\n\n\n\n\n\n\n\nLLMs\n\n\nStroop\n\n\nChatGPT\n\n\n\n\nThis is a short post to determine how easy it would be to simulate performance in a classic human attention task using ChatGPT. The short answer is that it can generate data in the style of a Stroop experiment without too much effort on my part.\n\n\n\n\n\n\nJun 6, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nNotes for my students on using ChatGPT\n\n\n\n\n\n\n\nChatGPT\n\n\nLLMs\n\n\n\n\nI’m teaching a class on the people of NYC, and these are some notes that I made for students about ChatGPT.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nTwo new courses and getting into the swing with spring\n\n\n\n\n\n\n\nRSS\n\n\n\n\nWriting for personal motivation and organization around teaching this coming Spring semester. Odd notes about process. A narrative form to-do list. For me, sharing for fun.\n\n\n\n\n\n\nJan 12, 2023\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nGenerative art (note) collection\n\n\n\n\n\n\n\ngenerative art\n\n\nart\n\n\n\n\nCollecting fast notes on using #rstats and potentiall other things to generate visuals.\n\n\n\n\n\n\nNov 10, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nRSS feed my quarto blog\n\n\n\n\n\n\n\nRSS\n\n\n\n\nSeeing what happens if I set up RSS feeds over here.\n\n\n\n\n\n\nNov 10, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nConvincing myself to run a Funkwhale pod\n\n\n\n\n\n\n\nfunkwhale\n\n\nactivitypub\n\n\naudio\n\n\nmusic\n\n\n\n\nFunkwhale is an audio platform thing that supports activitypub. Collecting notes about it.\n\n\n\n\n\n\nNov 9, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nDebriefing my mastodon migration\n\n\n\n\n\n\n\nsocial\n\n\nmastodon\n\n\n\n\nIt’s been a wild ride on social media over the past week. I need some thought collection.\n\n\n\n\n\n\nNov 7, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nSpinning up a mastodon instance with masto.host: First try and notes\n\n\n\n\n\n\n\nsocial\n\n\nmastodon\n\n\n\n\nI decided to try mastodon from inside my own instance, and this is brief guide to what I did and the questions I still have.\n\n\n\n\n\n\nNov 1, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nMastodon migration and getting off twitter?\n\n\n\n\n\n\n\nsocial\n\n\ntwitter\n\n\nmastodon\n\n\n\n\nTrying out Mastodon this weekend and attempting to migrate between instances using an R package.\n\n\n\n\n\n\nOct 30, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nWhat if I made an R command center for tweeting and tooting?\n\n\n\n\n\n\n\nsocial\n\n\ntwitter\n\n\nmastodon\n\n\n\n\nMessing around with stuff in R on a friday Morning\n\n\n\n\n\n\nOct 28, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nArchiving the journal of knowledge\n\n\n\n\n\n\n\nsocial\n\n\ntwitter\n\n\nparody\n\n\n\n\nAttempt to download some previous tweets before deleting an account.\n\n\n\n\n\n\nOct 28, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nA reading list for cognition\n\n\n\n\n\n\n\ncognition\n\n\nteaching\n\n\nreading list\n\n\n\n\nDeveloping a reading list for cognitive psychology to supplement an introductory textbook.\n\n\n\n\n\n\nOct 25, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nUnplanning my next course prep\n\n\n\n\n\n\n\nungrading\n\n\nunplanning\n\n\nteaching\n\n\n\n\nSunday morning thoughts on not overplanning while prepping a new course.\n\n\n\n\n\n\nOct 16, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nQuarto as a tool for reproducible research projects in psychology\n\n\n\n\n\n\n\nquarto\n\n\nRstats\n\n\nvertical\n\n\nReproducible research\n\n\n\n\nSome initial reactions to using quarto as a platform for creating and communicating reproducible research projects in psychology.\n\n\n\n\n\n\nOct 14, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nBlogging with Quarto\n\n\n\n\n\n\n\nquarto\n\n\nRstats\n\n\nblogging\n\n\n\n\nAugust 25th, 2022 - Quick tips on setting up a quarto blog using R Studio.\n\n\n\n\n\n\nAug 25, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nGetting back into the groove and teaching cognition\n\n\n\n\n\n\n\nteaching\n\n\ncognition\n\n\nOER\n\n\n\n\nIt’s been summer time and another semester begins in a couple days. I’m blogging to get words flowing as I polish my syllabus and reflect on goals for this academic year.\n\n\n\n\n\n\nAug 23, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nMaking fonts\n\n\n\n\n\n\n\nfonts\n\n\n\n\nJuly 7th, 2022 - Notes on making custom fonts and using them on the web.\n\n\n\n\n\n\nJul 7, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nA reading list on eugenics\n\n\n\n\n\n\n\neugenics\n\n\n\n\nThis is an annotated bibliography for books I am reading on eugenics and its connections to psychology and society.\n\n\n\n\n\n\nJun 28, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nWriting annotated bibliographies with R Markdown\n\n\n\n\n\n\n\nbibliographies\n\n\nRstats\n\n\n\n\nTrying out ways to write annotated bibliographies in R Markdown.\n\n\n\n\n\n\nJun 28, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nBrief notes on the cheating behavior literature\n\n\n\n\n\n\n\nteaching\n\n\ncognition\n\n\n\n\nNotes on cheating behavior literature\n\n\n\n\n\n\nMay 26, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nTeaching with multiple warp zones: Increasing engagement with assignment choice\n\n\n\n\n\n\n\nteaching\n\n\ncognition\n\n\n\n\nSome thoughts on how I implemented loads of assignment choice in my intro to cognition course this semester.\n\n\n\n\n\n\nMay 20, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nBlogging with pkgdown?\n\n\n\n\n\n\n\nRstats\n\n\npkgdown\n\n\nblogging\n\n\n\n\nAn attempt to blog with pkgdown, including notes to self about how I did this. It was succesful enough that I’m using pkgdown for this blog.\n\n\n\n\n\n\nMay 17, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nCustomizing a publication list with R Markdown\n\n\n\n\n\n\n\nRstats\n\n\npublication list\n\n\n\n\nNotes on creating a customizable list of publications for an academic website using R markdown, .bib files, and other fun stuff.\n\n\n\n\n\n\nMay 17, 2022\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nLearning to code for Ornament and Crime Hemisphere suite\n\n\n\n\n\nSome notes on coding for the open-source eurorack module called Ornament and Crime\n\n\n\n\n\n\nJul 28, 2020\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nPsychology and Eugenics connections\n\n\n\n\n\n\n\neugenics\n\n\npsychology\n\n\n\n\nMaking notes and connecting dots about the pervasiveness of eugenics ideology among psychologists\n\n\n\n\n\n\nJul 13, 2020\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nThe Eugenic Mind Project\n\n\n\n\n\n\n\neugenics\n\n\n\n\nI’m reading the Eugenic Mind Project by R. A. Wilson, and making notes here.\n\n\n\n\n\n\nJul 7, 2020\n\n\nMatt Crump\n\n\n\n\n\n\n  \n\n\n\n\nReading the Journal of Black Psychology\n\n\n\n\n\n\n\nblack psychology\n\n\nABPsi\n\n\n\n\nReading the Journal of Black Psychology from the beginning, and writing about it here.\n\n\n\n\n\n\nJul 2, 2020\n\n\nMatt Crump\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Books.html",
    "href": "Books.html",
    "title": "Books",
    "section": "",
    "text": "These books were made using Quarto, or R Markdown and Bookdown. They are all free, open-source, and licensed on creative commons."
  },
  {
    "objectID": "Books.html#instances-of-cognition",
    "href": "Books.html#instances-of-cognition",
    "title": "Books",
    "section": "Instances of Cognition",
    "text": "Instances of Cognition\n\n\nDescription: This is a free, open-educational textbook and set of course materials for an introductory undergraduate course in cognition. The materials are not yet complete, and I am continuing to develop them across the Fall 2021 and Spring 2022 semesters. All of the materials are CC BY-SA 4.0 creative-commons licensed and free for others to use, copy, remix, re-use.\nWritten in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/cognition\n\n\n\nLicense: CC BY-SA 4.0\n\n\nCITATION IS TBD WHILE THE PROJECT IS UNDER DEVELOPMENT.\nCrump, M. J. C. (2022, April 21). Instances of Cognition: Questions, Methods, Findings, Explanations, Applications, and Implications."
  },
  {
    "objectID": "Books.html#reproducible-statistics-for-psychologists-with-r-lab-tutorials",
    "href": "Books.html#reproducible-statistics-for-psychologists-with-r-lab-tutorials",
    "title": "Books",
    "section": "Reproducible statistics for psychologists with R: Lab Tutorials",
    "text": "Reproducible statistics for psychologists with R: Lab Tutorials\n\n\nDescription: This is a series of labs/tutorials currently under development (2020-2021) for a two-semester graduate-level statistics sequence in Psychology @ Brooklyn College of CUNY. The first set of 13 labs roughly tracks “Thinking with Data” (Vokey & Allen, 2018) and “Answering questions with data” (Crump et al., 2018); the second set of labs (to be written on a weekly basis during the Spring 2021 semester) will roughly track “Experimental Design and Analysis for Psychology” (Abdi et al., 2009).\nWritten in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/rstatsforpsych\n\n\n\nLicense: CC BY-SA 4.0\n\n\nCitation: Crump, M. J. C. (2020, December 10). Reproducible statistics for psychologists with R: Lab Tutorials. https://doi.org/10.17605/OSF.IO/KBHGA"
  },
  {
    "objectID": "Books.html#using-r-for-reproducible-research-student-contributed-tutorials",
    "href": "Books.html#using-r-for-reproducible-research-student-contributed-tutorials",
    "title": "Books",
    "section": "Using R for Reproducible Research: Student contributed tutorials",
    "text": "Using R for Reproducible Research: Student contributed tutorials\n\n\nDescription: These chapters were written by students in PSYC 7709: Using R for Reproducible research, Spring 2019 @ Brooklyn College of CUNY, as a part of their final project to write a tutorial about an R package.\nWritten in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/psyc7709_2019\n\n\n\nLicense: CC BY-SA 4.0\n\n\nCitation: Abdelrahman, K., Contreras, A., Degtyarev, Z., Deng, J., Foster, J., Franz, A., Funderburk, T., Horger, M., Kravitz, J., Lakshin A., Manigat, M., Trois, R., Vasquez, A., Vo, A., Wilson, N., and Yeremenko, M. (2019). Using R for Reproducible Research: Student Contributed Tutorials. (M. J. C. Crump, Ed.)."
  },
  {
    "objectID": "Books.html#answering-questions-with-data-introductory-statistics-for-psychology-students",
    "href": "Books.html#answering-questions-with-data-introductory-statistics-for-psychology-students",
    "title": "Books",
    "section": "Answering Questions with Data: Introductory Statistics for Psychology Students",
    "text": "Answering Questions with Data: Introductory Statistics for Psychology Students\n\n\nAuthors: Matthew Crump; Chapters 2 and 4 adapted from Navarro, D.; Videos: Jeffrey Suzuki\nDescription: This is a free introductory statistics textbook for undergraduates in Psychology. It is being developed as an Open Educational Resource @ Brooklyn College. It is pitched at the concepts behind statistics, and often uses simulation in R to convey foundational ideas. The writing style is sometimes a bit unconventional, and informal. It is for students who don’t want to like statistics.\nWritten in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/statistics\n\n\n\nLicense: CC BY-SA 4.0\n\n\nCitation: Crump, M. J. C., Navarro, D., & Suzuki, J. (2019, June 5). Answering Questions with Data (Textbook): Introductory Statistics for Psychology Students. https://doi.org/10.17605/OSF.IO/JZE52"
  },
  {
    "objectID": "Books.html#answering-questions-with-data-the-lab-manual",
    "href": "Books.html#answering-questions-with-data-the-lab-manual",
    "title": "Books",
    "section": "Answering Questions with Data: The Lab Manual",
    "text": "Answering Questions with Data: The Lab Manual\n\n\nLab activities using R, Excel, SPSS, and JAMOVI\nAuthors: Matthew Crump (R); Stephen Volz (Excel); Alla Chavarga (SPSS); Anjali Krishnan (JAMOVI)\nDescription: This is the companion lab manual to our free stats book. It contains lab activities for learning how to conduct statistical tests in R, Excel, SPSS, and JAMOVI. We use open data, often from psychology papers, and show step-by-step how to solve data-analysis problems in each software package.\nSome of the labs are adapated from Open Stats Lab, another great resource.\nSource code: Written in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/statisticsLab.\n\n\n\nLicense: CC BY-SA 4.0\n\n\nCitation: Crump, M. J. C., Krishnan, A., Volz, S., & Chavarga, A. (2019, June 5). Answering Questions with Data: The Lab Manual for R, Excel, SPSS and Jamovi. https://doi.org/10.17605/OSF.IO/M2NPJ"
  },
  {
    "objectID": "Books.html#answering-questions-with-data-the-course-website",
    "href": "Books.html#answering-questions-with-data-the-course-website",
    "title": "Books",
    "section": "Answering Questions with Data: The Course Website",
    "text": "Answering Questions with Data: The Course Website\n\n\nA copiable course website for introductory statistics\nAuthors: Matthew Crump\nDescription: This website was created in R Markdown. It contains most of the course materials I use when teaching undergraduate statistics for psychology. IT includes slide decks for presentations.\nSource code: Written in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/psyc3400.\n\n\n\nLicense: CC BY-SA 4.0\n\n\nCitation : Crump, M. J. C. (2019, June 5). Answering Questions with Data: Course Website. https://doi.org/10.17605/OSF.IO/AWXU9"
  },
  {
    "objectID": "Books.html#research-methods-for-psychology",
    "href": "Books.html#research-methods-for-psychology",
    "title": "Books",
    "section": "Research Methods for Psychology",
    "text": "Research Methods for Psychology\n\n\nDescription:A free Research methods textbook for undergraduates in Psychology, creative commons license, remix, reuse, edit, contribute.\nAuthors: Matthew J. C. Crump, Paul C. Price, Rajiv Jhangiani, I-Chant A. Chiang, Dana C. Leighton\nSource code: Written in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/ResearchMethods.\n\n\n\nLicense: CC BY-NC-SA 4.0"
  },
  {
    "objectID": "Books.html#cognitive-technologies-from-theory-and-data-to-application",
    "href": "Books.html#cognitive-technologies-from-theory-and-data-to-application",
    "title": "Books",
    "section": "Cognitive Technologies: From Theory and Data to Application",
    "text": "Cognitive Technologies: From Theory and Data to Application\n\n\nDescription: A series of chapters on cognitive technologies written by doctoral students who took my course on Cognitive Technologies in Spring 2018. They wrote it, I compiled it using bookdown.\nEditor: Crump, M. J. C\nAuthors: Crump, M. J. C.; Amada, N.; Bourque, K; Brosowsky, N.; Ergun, T.; Korovatskaya, A.; Ma, X.; Seoung, Y.; Wylie, J."
  },
  {
    "objectID": "Books.html#open-tools-for-writing-open-interactive-textbooks-and-more",
    "href": "Books.html#open-tools-for-writing-open-interactive-textbooks-and-more",
    "title": "Books",
    "section": "Open tools for writing open interactive textbooks (and more)",
    "text": "Open tools for writing open interactive textbooks (and more)\n\n\nDescription: tutorial overview of the process I use to write books using R, R-studio, R-markdown, and compile them in bookdown. I’ve used this process for all of these books. Some other brief tidbits on using hypothes.is, and R-Shiny apps, also Zotero and hosting on github pages (where this website is hosted)\nAuthor: Matthew J. C. Crump\nNote this is a meta-book. The tutorial above is for you to read so you can download the source code, then compile it yourself, then edit it to make your own.\nSource code: Written in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/OER_bookdown.\n\n\n\nLicense: CC BY-SA 4.0"
  },
  {
    "objectID": "Books.html#programming-for-psychologists-data-creation-and-analysis",
    "href": "Books.html#programming-for-psychologists-data-creation-and-analysis",
    "title": "Books",
    "section": "Programming for Psychologists: Data Creation and Analysis",
    "text": "Programming for Psychologists: Data Creation and Analysis\n\n\nDescription: Some notes that got big enough to make a book. Beginner introduction to coding in R, Livecode, and some web-programming, for the purposes of making data with computers (programming experiments), and analyzing it in R.\nAuthor: Matthew J. C. Crump\nSource code: Written in Rmarkdown, and compiled with the bookdown package. The source code is located in this github repository https://github.com/CrumpLab/programmingforpsych.\n\n\n\nLicense: CC BY-SA 4.0"
  },
  {
    "objectID": "Courses.html",
    "href": "Courses.html",
    "title": "Courses",
    "section": "",
    "text": "List of current and previous courses taught at Brooklyn College of CUNY and the Graduate Center of CUNY."
  },
  {
    "objectID": "Courses.html#current-courses",
    "href": "Courses.html#current-courses",
    "title": "Courses",
    "section": "Current Courses",
    "text": "Current Courses\n\n\n\n\n\nPsyc 2530: Introduction to Cognitive Psychology (Asynchronous Online)\n\n\n\n\nFall 2023\n\n\nUndergraduate\n\n\nOER\n\n\n\nFor my students: although most of the course materials are available on the course website, this course is under development until the official start of the Fall 2023 semester.\n\n\n\n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "Courses.html#past-courses",
    "href": "Courses.html#past-courses",
    "title": "Courses",
    "section": "Past Courses",
    "text": "Past Courses\n\n\n\n\n\nMCHC 1002: People of New York City\n\n\n\n\nSpring 2023\n\n\nUndergraduate\n\n\nMacaulay Honors College\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 3470/SOCY 3507: Data Analytics and Data Visualization in the Social and Behavioral Sciences\n\n\n\n\nSpring 2023\n\n\nUndergaduate\n\n\nOER\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 2530: Introduction to Cognitive Psychology (In Person)\n\n\n\n\nFall 2022\n\n\nUndergraduate\n\n\nOER\n\n\n\nCourse website displays current materials, archived materials from this semester may be available on Github.\n\n\n\n  \n\n\n\n\n\n\nPsyc 2530: Introduction to Cognitive Psychology (Asynchronous online)\n\n\n\n\nSpring 2022\n\n\nUndergraduate\n\n\nOER\n\n\n\nCourse website displays current materials, archived materials from this semester may be available on Github.\n\n\n\n  \n\n\n\n\n\n\nPsyc 7709G: Using R for Reproducible research\n\n\n\n\nSpring 2022\n\n\nBrooklyn College\n\n\nExperimental Psych MA\n\n\nGraduate\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 2530: Introduction to Cognitive Psychology (Synchronous online)\n\n\n\n\nFall 2021\n\n\nUndergraduate\n\n\nOER\n\n\n\nCourse website displays current materials, archived materials from this semester may be available on Github.\n\n\n\n  \n\n\n\n\n\n\nPsyc 7765/66G: Statistical Methods Applications I & II\n\n\n\n\n2020-2021\n\n\nBrooklyn College\n\n\nExperimental Psych MA\n\n\nGraduate\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 73800: Cognitive Psychology\n\n\n\n\nGraduate Center of CUNY\n\n\nCCP Training Area\n\n\nDoctoral\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 7709G - Statistical Methods Practicum II\n\n\n\n\nBrooklyn College\n\n\nExperimental Psych MA\n\n\nGraduate\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 7709G - Statistical Methods Practicum I\n\n\n\n\nBrooklyn College\n\n\nExperimental Psych MA\n\n\nGraduate\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 7709G: Using R for Reproducible research\n\n\n\n\nSpring 2019\n\n\nBrooklyn College\n\n\nExperimental Psych MA\n\n\nGraduate\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 3400: Statistical Methods in Psychological Research\n\n\n\n\nUndergraduate\n\n\nOER\n\n\n\nAll materials are totally free and open, including the course Website, textbook, and lab manual.\n\n\n\n  \n\n\n\n\n\n\nPsyc 80103: Cognitive Technologies: From theory and data to application\n\n\n\n\nGraduate Center of CUNY\n\n\nCCP Training Area\n\n\nDoctoral\n\n\n\n\n\n\n  \n\n\n\n\n\n\nPsyc 3450: Experimental Psychology\n\n\n\n\nUndergraduate\n\n\nOER\n\n\n\nAn undergraduate course on research methods, using a free OER textbook! Written by myself and many others. Check out the textbook here. Check out the course website here.\n\n\n\n  \n\n\n\n\n\n\nPsyc 80103: Computer Programming for Psychologists\n\n\n\n\nGraduate Center of CUNY\n\n\nDoctoral\n\n\n\n\n\n\n  \n\n\n\n\n\nPsyc 3530: Introduction to Cognitive Psychology\n\n\n\nUndergraduate\n\n\n\n\n\n\n\n\n\n\n\n\nPsyc 80103: Special Topics Seminar: Learning & Attention\n\n\n\nDoctoral\n\n\n\nSpecial topics doctoral course co-taught with Andrew Delamater\n\n\n\n\n\n\n\n\n\nPsyc 80103: Special Topics: Memory: Foundations & Current Issues\n\n\n\nDoctoral\n\n\n\nSpecial topics doctoral course co-taught with Elizabeth Chua\n\n\n\n\n\n\n\n\n\nPsyc 80103: Career Development\n\n\n\nDoctoral\n\n\n\nSpecial topics doctoral course co-taught with Elizabeth Chua\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Apps.html",
    "href": "Apps.html",
    "title": "Apps",
    "section": "",
    "text": "Shiny Apps, R packages, and various things"
  },
  {
    "objectID": "Apps.html#gptaddin",
    "href": "Apps.html#gptaddin",
    "title": "Apps",
    "section": "gptaddin",
    "text": "gptaddin\nAddins and shiny app for sending text to LLMs at OpenAI. The addins are focused on writing assistance tools. The shiny app has a grammar checker. This is an experimental package for personal use that may be helpful as a reference for others to build their own similar tools."
  },
  {
    "objectID": "Apps.html#vertical",
    "href": "Apps.html#vertical",
    "title": "Apps",
    "section": "vertical",
    "text": "vertical\nR-studio project template and workflow for sharing psychological research projects in the form of a website."
  },
  {
    "objectID": "Apps.html#rsemanticlibrarian",
    "href": "Apps.html#rsemanticlibrarian",
    "title": "Apps",
    "section": "RsemanticLibrarian",
    "text": "RsemanticLibrarian\nR functions for creating semantic librarians, a tool for vectorizing and visualizing semantic spaces from text"
  },
  {
    "objectID": "Apps.html#jspsychr",
    "href": "Apps.html#jspsychr",
    "title": "Apps",
    "section": "jspsychr",
    "text": "jspsychr\nWrite and run jspsych experiments using R studio."
  },
  {
    "objectID": "Apps.html#playjareyesores",
    "href": "Apps.html#playjareyesores",
    "title": "Apps",
    "section": "playjareyesores",
    "text": "playjareyesores\nFunctions for detecting textual overlap (e.g., possible plagiarism) between documents https://crumplab.github.io/playjareyesores/"
  },
  {
    "objectID": "Apps.html#conflictpower",
    "href": "Apps.html#conflictpower",
    "title": "Apps",
    "section": "conflictPower",
    "text": "conflictPower\nMonte-carlo based power analysis for cognitive control designs. https://crumplab.github.io/conflictPower/"
  },
  {
    "objectID": "Apps.html#crumplabr",
    "href": "Apps.html#crumplabr",
    "title": "Apps",
    "section": "crumplabr",
    "text": "crumplabr\nA few functions used around the lab. Contains functions for the Van Selst and Jolicoeur outlier procedure. https://github.com/CrumpLab/crumplabr."
  },
  {
    "objectID": "Apps.html#semanticlibrarian.com",
    "href": "Apps.html#semanticlibrarian.com",
    "title": "Apps",
    "section": "semanticlibrarian.com",
    "text": "semanticlibrarian.com\nA semantic search engine for the APA abstract database (most of the Experimental journals from 1890s to 2016), formerly known as ATHENA.\nWe (Harinder Aujla, Randy Jamieson, and Matthew Crump) use semantic vectors from BEAGLE (Jones & Mewhort, 2007) to compute the similarity between abstracts, and authors, and authors and abstracts.\n\nhttps://crumplab.shinyapps.io/SemanticLibrarian/\nsource code: https://github.com/CrumpLab/SemanticLibrarian\nOpen science framework project: https://osf.io/wfcmg/\nPublication: In press at Behavioral Research Methods."
  },
  {
    "objectID": "Apps.html#hypothesis_explorer",
    "href": "Apps.html#hypothesis_explorer",
    "title": "Apps",
    "section": "hypothesis_explorer",
    "text": "hypothesis_explorer\nA Shiny App for viewing annotations from the Hypothes.is database. Need to download and run locally.\nhttps://github.com/CrumpLab/hypothesis_explorer"
  },
  {
    "objectID": "Apps.html#indttest",
    "href": "Apps.html#indttest",
    "title": "Apps",
    "section": "indTtest",
    "text": "indTtest\nAn independent samples t-test simulator.\nhttps://crumplab.shinyapps.io/indTtest/"
  },
  {
    "objectID": "Apps.html#pairedttest",
    "href": "Apps.html#pairedttest",
    "title": "Apps",
    "section": "pairedTtest",
    "text": "pairedTtest\nAn paired samples t-test simulator.\nhttps://crumplab.shinyapps.io/pairedTtest/"
  },
  {
    "objectID": "Apps.html#simpleexperimentsim",
    "href": "Apps.html#simpleexperimentsim",
    "title": "Apps",
    "section": "simpleexperimentsim",
    "text": "simpleexperimentsim\nA simple experiment simulator with monte-carlo power analysis\nhttps://crumplab.shinyapps.io/simpleexperimentsim/"
  },
  {
    "objectID": "Apps.html#nsfrmarkdown",
    "href": "Apps.html#nsfrmarkdown",
    "title": "Apps",
    "section": "NSFrmarkdown",
    "text": "NSFrmarkdown\nAn R markdown template for NSF grants\nhttps://github.com/CrumpLab/NSFrmarkdown"
  },
  {
    "objectID": "Apps.html#labjournalwebsite",
    "href": "Apps.html#labjournalwebsite",
    "title": "Apps",
    "section": "LabJournalWebsite",
    "text": "LabJournalWebsite\nhttps://github.com/CrumpLab/LabJournalWebsite\nSimple template for an R Markdown Website"
  },
  {
    "objectID": "Apps.html#rmpatternlanguage",
    "href": "Apps.html#rmpatternlanguage",
    "title": "Apps",
    "section": "rmpatternlanguage",
    "text": "rmpatternlanguage\nA bookdown theme reproducing the style of “A Pattern Language”.\nhttps://github.com/CrumpLab/rmpatternlanguage"
  },
  {
    "objectID": "Fun.html",
    "href": "Fun.html",
    "title": "Fun",
    "section": "",
    "text": "Music Stuff\n\n\n\n\nsynthesizers\n\n\nelectro\n\n\njazz\n\n\nother stuff\n\n\n\nI make music and sometimes post it online. Check it out at: https://homophony.quest\n\n\n\n  \n\n\n\n\n\n\nVisual Stuff\n\n\n\n\npainting\n\n\ndigital art\n\n\ncartoon like things\n\n\n\nWhen I find time to make visual things I post them here: https://crumplab.github.io/things\n\n\n\n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/880_BBS/index.html",
    "href": "blog/880_BBS/index.html",
    "title": "Spinning up a mastodon instance with masto.host: First try and notes",
    "section": "",
    "text": "This weekend I followed some #Rstats folks from twitter to mastodon. I first landed at Fosstodon, and then made an account on mastodon.social, which became very slow due to server load. After digging around a bit and learning new words like #fediverse and activitypub, I decided to spin up my own instance of mastodon using masto.host. So, now you can find me https://bbs.crumplab.com/@MattCrump, or @MattCrump@bbs.crumplab.com.\nI’m not totally sure why I put myself into my own mastodon instance, but I’ll talk reasons later on. For now, this is an excuse to learn new web stuff while benefiting from a rich social network. Without further ado."
  },
  {
    "objectID": "blog/880_BBS/index.html#setting-up-a-mastodon-instance-on-masto.host",
    "href": "blog/880_BBS/index.html#setting-up-a-mastodon-instance-on-masto.host",
    "title": "Spinning up a mastodon instance with masto.host: First try and notes",
    "section": "Setting up a mastodon instance on masto.host",
    "text": "Setting up a mastodon instance on masto.host\nI saw Jon Henshaw post about running his own mastodon instance on masto.host, and that seemed interesting, so I tried it:\nhttps://twitter.com/henshaw/status/1587072753034842118\nHere’s what happened.\n\nWent to masto.host.\n\n\n\nI chose the moon plan because it’s just gonna be. But, I noted that it is possible to upgrade and downgrade, so if I wanted to invite more people to my little bbs experiment I could do that. Or, if you are setting this up for a group, it seems pretty easy to grow larger (at least up to 2000 users for 89/month).\n\n\n\nAfter clicking “buy now” there is a decision to use your own domain or subdomain, or a masto.host subdomain.\n\n\nA quick aside for domain names. I have been using R Markdown and more recently Quarto for lots of purposes, including creating this website and blog. All of the source code for compiling this website and blog is in a github repository, and served from github pages. At some point I used namecheap to acquire my domain crumplab.com. This allowed me to serve my website from that domain (there is an option to use your own domain on github pages).\nIn addition, it is possible to add subdomains. For example, I have a jatos server running on digital ocean for online experiments, which has it’s own subdomain on crumplab.com.\nFor mastodon I chose “Your domain”, and came up with the subdomain bbs.crumplab.com as a throwback to the bulletin board services I used to use as a kid.\n\nI don’t have screen shots for some of the next steps, but basically you enter your credit card information. In my case, immediately after purchasing I got a warning from mastodon that bbs.crumplab.com was not found on my DNS servers. Masto.host kindly gives clear instructions on what I needed to do in order to add my subdomain, which involved adding a new cname entry, and waiting for it to propagate.\nAfter masto.host detected my subdomain, it automagically created a new mastodon instance.\n\n\nAnd, when installation was finished it updated to let me know. This all took about 15 minutes from start to finish, and most of the time was waiting for DNS issues to be resolved."
  },
  {
    "objectID": "blog/880_BBS/index.html#checking-out-the-instance",
    "href": "blog/880_BBS/index.html#checking-out-the-instance",
    "title": "Spinning up a mastodon instance with masto.host: First try and notes",
    "section": "Checking out the instance",
    "text": "Checking out the instance\nMy mastodon instance was now running, and I could access it by going to the subdomain bbs.crumplab.com.\n\nThe next steps are to create an account for yourself, and then give yourself administrator privileges. I chose “MattCrump” for the account name, which makes me “@MattCrump@bbs.crumplab.com”.\nAfter logging in as a new user you get a default mastodon user account. I appear to be running Mastodon v 3.5.3, which is not the bleeding edge that mastodon.social is running (?). I don’t think I can edit my posts on this version, and I’m not sure yet if I can upgrade the version through masto.host."
  },
  {
    "objectID": "blog/880_BBS/index.html#admin-stuff",
    "href": "blog/880_BBS/index.html#admin-stuff",
    "title": "Spinning up a mastodon instance with masto.host: First try and notes",
    "section": "Admin stuff",
    "text": "Admin stuff\nMy first big question was how do I assume administrator privileges and turn off the ability of anyone to make an account on this instance. That part was easy on masto.host.\n\nMake a user account on your instance\nGo to masto.host, click on the hosting domain, and then “change user role” on the server option\nEnter your account name and presto chango you are the admin.\n\n\nWhen you go back to your mastodon account, there are new admin options in the settings.\n\nThe first thing I did was go to “Site Settings” and change the registration to “Nobody can sign up”\n\nAnd, that’s basically where I am at.\nGonna take a break, and continue this post sometime later today."
  },
  {
    "objectID": "blog/880_BBS/index.html#general-thoughts-so-far",
    "href": "blog/880_BBS/index.html#general-thoughts-so-far",
    "title": "Spinning up a mastodon instance with masto.host: First try and notes",
    "section": "General thoughts so far",
    "text": "General thoughts so far\nIt was very easy for me to set up a new mastodon instance. Almost too easy. For example, if I had the intention of creating an instance that other people could join, the process would be similarly easy, but I expect the realities of doing admin and moderation require a much larger time investment. I don’t have the bandwidth to think about running a larger instance right now, so I’m going to stick to learning the system in this person-sized instance.\n\nAll by myself\nSo far the experience of being “alone” on my own instance is A OK. The default feeds work a little bit differently. My “local” feed is the same as my personal timeline, because no one else is on the instance. My home feed I guess is the same as it would be if I was on a shared instance. I see posts from the people I follow, and I see the things they are boosting. I’m not sure I totally understand what I am seeing on the federated feed, but it appears to be the people I follow, but not what they are boosting. It’s not a fire-hose of posts.\nI still don’t know how to add things to lists.\nAttempting to “micro-blog” with a personal mastodon instance has been rewarding so far, especially to prompt thinking about how I engage with social media in general, and how I curate/save/share what I’m doing. Everything I post on the instance is there, I guess for me to deal with and make decisions about.\nThere is a great deal of topic worth engaging on, and I’m hoping this process can help me navigate my own engagement."
  },
  {
    "objectID": "blog/880_BBS/index.html#custom-emojis",
    "href": "blog/880_BBS/index.html#custom-emojis",
    "title": "Spinning up a mastodon instance with masto.host: First try and notes",
    "section": "Custom emojis",
    "text": "Custom emojis\nWhen I joined Fosstodon I quickly learned they have a custom emoji for R, that Mastodon.social has a custom emoji for the Rocinante, and that instances can have their own custom emojis.\nClearly I must confirm.\nCool, there are already lots of custom emojis on other instances, and it looks like the admin can approve use of custom emojis.\n\nBRB.\nI got Rstats and few others, but I really want :blobcatfacepalm:, which doesn’t appear on the list.\nThis is helpful https://emojos.in\nHmmm, I have questions. I was clicking emojis and “enabling” them, but I’m not sure whether this means I can use them. I found a version of the :rstats: emoji and copied it, and did a test post. It worked, that’s cool.\nHad to manually copy :blobcatfacepalm:, and got it working."
  },
  {
    "objectID": "blog/881_Mastodon/index.html",
    "href": "blog/881_Mastodon/index.html",
    "title": "Mastodon migration and getting off twitter?",
    "section": "",
    "text": "It’s the weekend where I wake up and try new forms of social media, and mostly avoid discussing whether I should ever use social media. It’s becoming increasingly clear to me that it’s all just an excuse to make banners for posts in adobe express.\nI guess my first foray into social media was BBSes back in the pre-internet days, wow. I deleted facebook years ago, but I share my drawings, paintings, and on instagram https://www.instagram.com/crumpmj/. I’ve been on and off twitter, currently on https://twitter.com/MattCrumpLab.\nI have lots of issues with twitter, including its direction under new leadership. For example, the direction described here is very disturbing, so I can see myself noping out of twitter very soon.\nhttps://davetroy.medium.com/no-elon-and-jack-are-not-competitors-theyre-collaborating-3e88cde5267d"
  },
  {
    "objectID": "blog/881_Mastodon/index.html#enter-mastodon",
    "href": "blog/881_Mastodon/index.html#enter-mastodon",
    "title": "Mastodon migration and getting off twitter?",
    "section": "Enter Mastodon",
    "text": "Enter Mastodon\nA bunch of #rstats people I follow were migrating over to Mastodon, so I went along too and started an account on Fosstodon https://fosstodon.org/@MattCrumpLab. Mastodon had popped up here and there for me before, but I had never tried it out. Fosstodon is a mastodon instance with lots of people interested in free and open-source software. I’m a big admirer, user, and supporter of open-source stuff, so wonderful, I joined.\nThe user experience is similar to twitter. It’s a bit clunky for a newbie. For example, I initially had some trouble figuring out how to follow people on different instances. However, mastodon is itself a free and open-source project, run by people not algorithms (and no ads!), and they have made deliberate design decisions about user experience that seem great for making social media less toxic. For example, I couldn’t agree more with the points made in this post:\nhttps://scott.mn/2022/10/29/twitter_features_mastodon_is_better_without/"
  },
  {
    "objectID": "blog/881_Mastodon/index.html#mastodon-migration",
    "href": "blog/881_Mastodon/index.html#mastodon-migration",
    "title": "Mastodon migration and getting off twitter?",
    "section": "Mastodon migration",
    "text": "Mastodon migration\nI quickly discovered that mastodon is a fediverse of federated instances of mastodon. My understanding is that people spin up mastodon servers and create their own communities with focal interests, but because everything is running on mastodon, all the mastodon instances can follow between each other. Or something like that.\nI found Fosstodon to be a nice starting place, and I noticed that many of my colleagues were joining mastodon.social, so I did too https://mastodon.social/@MattCrumpLab. I guess it is OK to be on two instances at the same time. First impressions are that mastodon.social has more users and the local timeline is popping. In terms of mastodon, I’m still not sure what any of this really means, but I for fun I’m going to try to migrate my account.\nActually, to restate, I learned that I could programmatically access mastodon using R https://github.com/ThomasChln/mastodon, so intend to have fun using that library to try things between my mastodon accounts."
  },
  {
    "objectID": "blog/881_Mastodon/index.html#trying-stuff",
    "href": "blog/881_Mastodon/index.html#trying-stuff",
    "title": "Mastodon migration and getting off twitter?",
    "section": "Trying stuff",
    "text": "Trying stuff\n\nlibrary(mastodon)\n\n#login\n\ntoken &lt;- login('https://fosstodon.org/', my_email, my_password)\n\n# get my id\n\nme &lt;- search_username(token, 'MattCrumpLab')\n\n# get my account\n\nmy_account &lt;- get_account(token, me[[1]]$id)\n\nsaveRDS(my_account, file=\"test.RDS\")\nmy_account &lt;- readRDS(\"test.RDS\")\nprint(head(my_account))\n\nThese both return the same data. Spent too much time searching for how to display long R lists of things in html, but didn’t find much. The above is a short list. But, it doesn’t include my posts (statuses. How do I get those?\n\n# didnt' work\nmy_timeline &lt;- get_timeline(token, 'home')\n\n# this worked\nget_status(token, 42)\n\nHmmm, looks like I need to know that status IDs of my posts in order to get them. But, I don’t know how to get those from this R package. Oh well. Time to move on and do something else. Apparently, I can download all of my posts from my account settings, so that’s nice.\nIn the meantime, I’m going to try a Mastodon account migration and see what happens."
  },
  {
    "objectID": "blog/883_command_center/index.html",
    "href": "blog/883_command_center/index.html",
    "title": "What if I made an R command center for tweeting and tooting?",
    "section": "",
    "text": "I am multivalent about social media. And, I’m not going to hash out those valences right now.\nInstead, in addition to twitter (where I have gone through a few account deletion cycles, @MattCrumpLab), I just joined Mastodon @MattCrumpLab@fosstodon.org. I’m not sure for how long, for either place.\nI remember feeling happy and sad when deleting twitter accounts. I did not take precautions to save or archive some of the content that I deleted, and I wish I did. If I had sent all those tweets from a personal central command center, then I maybe I would still have them.\nAnyway, let’s get on with business. My purpose here is to nerd-out and use R to send tweets or toots, or both. This way I’m thinking about a content curation strategy, and thinking about what deploying the content on various platforms means etc."
  },
  {
    "objectID": "blog/883_command_center/index.html#can-i-send-a-tweet-with-r",
    "href": "blog/883_command_center/index.html#can-i-send-a-tweet-with-r",
    "title": "What if I made an R command center for tweeting and tooting?",
    "section": "Can I send a tweet with R?",
    "text": "Can I send a tweet with R?\nLooks like tweeting from R can be done with https://github.com/ropensci/rtweet.\nThis worked, and it was a bit of pain to wade through the twitter developer authentication process.\n\nlibrary(rtweet)\n\nauth &lt;- rtweet_bot()\n\nrtweet::post_tweet(status = \"Testing out rtweet::post_tweet to see if I can post from Rstudio.\", token=auth)\n\nSome notes to self about what I did. The {rtweet} documentation was helpful.\n\nMake a twitter developer account\nRegister an app\nRequest elevated status\nGive the app access to my account\nSave the API key and secret, and bearer token\nGenerate token and secret for user account access.\n\nAll this took about an hour of messing around. I was using the wrong authentication methods for trying to post a tweet. rtweet_bot() triggers text input prompts to enter all of the keys and secrets, and these can be saved for use in future sessions.\n\nrtweet::auth_as(auth)\nmy_timeline &lt;- get_my_timeline(token=auth)\n\nreply_id &lt;- my_timeline[10,]$id_str\n\nlibrary(tidyverse)\nlibrary(ggrepel)\n\ntmp &lt;- starwars %&gt;%\n  filter(mass &lt; 1000) %&gt;%\nggplot(aes(x=height,y=mass,label=name))+\n  geom_text_repel()+\n  geom_text()\n\nggsave(\"starwars.png\",plot=tmp)\n\npost_tweet(\"proof of ggplot for @vuorre\", \n           media = \"starwars.png\", \n           media_alt_text = \"A plot of star wars characters by height and mass.\",\n           in_reply_to_status_id = reply_id,\n           token = auth)\n\npost_tweet(\"rtweet works, took a while to set up. \\n Requiring alt_text for media is a nice nudge\", token=auth)\n\nInteresting. Mission accomplished. Still have to figure out more complicated stuff like posting threads, etc. Moving on to tooting at Mastodon."
  },
  {
    "objectID": "blog/883_command_center/index.html#can-i-toot-with-r",
    "href": "blog/883_command_center/index.html#can-i-toot-with-r",
    "title": "What if I made an R command center for tweeting and tooting?",
    "section": "Can I toot with R?",
    "text": "Can I toot with R?\nI will try to do this with mastodon client for R.\n\nlibrary(mastodon)\n\ntoken &lt;- login('https://fosstodon.org/', my_email, my_password)\n\npost_status(token, 'This is a test post from an R console, using the mastodon client for R.')\n\nThat was easy."
  },
  {
    "objectID": "blog/883_command_center/index.html#whats-next",
    "href": "blog/883_command_center/index.html#whats-next",
    "title": "What if I made an R command center for tweeting and tooting?",
    "section": "What’s next",
    "text": "What’s next\nTime to go outside and do other stuff. Leaving these breadcrumbs here for later.\nAlso, I could just use this cross-posting service https://crossposter.masto.donte.com.br"
  },
  {
    "objectID": "blog/772_chatGPT/index.html",
    "href": "blog/772_chatGPT/index.html",
    "title": "Notes for my students on using ChatGPT",
    "section": "",
    "text": "This page is about using ChatGPT or similar models in this classroom.\nTLDR:\n\nI encourage you to explore the technology, both how it works, how you might use it as a tool, and the very real issues for society surrounding this tool\nDon’t rely on this tech being there for free. It is all very new and it could easily be pulled off the internet at anytime. It costs a lot of money to run these models, and I would be surprised if they stay free for long—time will tell.\nIf you use ChatGPT in one of your assignments, please mention this in the assignment and how you used it. I’ll go over some clearly acceptable uses cases, and some clearly unacceptable ones below.\nPassing off work from ChatGPT as your own is a violation of academic integrity that will be taken very seriously. I care about what you have to say, not what ChatGPT has to say.\nChatGPT will produce absolute hot garbage, be careful.\n\nThe rest of this page provides information on how to access ChatGPT, some information about ChatGPT, and then some examples of using ChatGPT."
  },
  {
    "objectID": "blog/772_chatGPT/index.html#using-chatgpt",
    "href": "blog/772_chatGPT/index.html#using-chatgpt",
    "title": "Notes for my students on using ChatGPT",
    "section": "",
    "text": "This page is about using ChatGPT or similar models in this classroom.\nTLDR:\n\nI encourage you to explore the technology, both how it works, how you might use it as a tool, and the very real issues for society surrounding this tool\nDon’t rely on this tech being there for free. It is all very new and it could easily be pulled off the internet at anytime. It costs a lot of money to run these models, and I would be surprised if they stay free for long—time will tell.\nIf you use ChatGPT in one of your assignments, please mention this in the assignment and how you used it. I’ll go over some clearly acceptable uses cases, and some clearly unacceptable ones below.\nPassing off work from ChatGPT as your own is a violation of academic integrity that will be taken very seriously. I care about what you have to say, not what ChatGPT has to say.\nChatGPT will produce absolute hot garbage, be careful.\n\nThe rest of this page provides information on how to access ChatGPT, some information about ChatGPT, and then some examples of using ChatGPT."
  },
  {
    "objectID": "blog/772_chatGPT/index.html#accessing-chatgpt",
    "href": "blog/772_chatGPT/index.html#accessing-chatgpt",
    "title": "Notes for my students on using ChatGPT",
    "section": "Accessing ChatGPT",
    "text": "Accessing ChatGPT\nYou can access chatGPT here from the openai.com website. It is currently free to use, but you have to sign up for an account.\nhttps://chat.openai.com"
  },
  {
    "objectID": "blog/772_chatGPT/index.html#things-to-know-about-chatgpt",
    "href": "blog/772_chatGPT/index.html#things-to-know-about-chatgpt",
    "title": "Notes for my students on using ChatGPT",
    "section": "Things to know about ChatGPT",
    "text": "Things to know about ChatGPT\nChatGPT is a large language model (LLM) created by a company called OpenAI. Many big tech companies are creating their own versions of this technology. For example, Meta released a model called Galactica AI to the public on November 15th, 2022; and, then shut it down after three days. Microsoft Bing is currently releasing it’s own “chatbot”. Google apparently has one called Bard?\nI happen to have some limited expertise in the science behind large language models. For example, one area of my research involves human semantic cognition and language production. This area of research has a long history of producing computational models attempting to how people understand the meaning of words, and how they produce grammatical sentences.\nPeople have large amounts of language experience. Think about how many words you have heard or read across your entire life. Some theories of language assume that people learn about word meaning gradually through their own personal history of experiencing examples of language. Language is highly structured and not random. This means that words can be predicted based on the context in which they occur.\nIf you read the sentence:\nAfter buying _________ at the grocery store, she squeezed the __________ to make ________ juice.\nBased on the context of the sentence you might infer that the person bought oranges, or some other fruit that can be squeezed to make juice.\nIf you were able to look back at all the sentences and phrases you have ever heard in your life, you would probably find many examples where “oranges” or other fruit words were next to juice, or in the same sentence as words like squeeze, or grocery store. Your experience with co-occurring patterns in language can help you predict words in sentences. This is the basic principle behind large language models.\nLarge language models are not like people. They have been trained on huge corpuses of text (e.g., half a trillion words). There have been ongoing efforts to digitize as much human produced text as possible. The google books project was one of the first. They scanned as many books in the world as they could. We also have the internet where people have produced all kinds of text, both regular language, and computer code. It is possible to download most things on the internet using scraping. For example, you could download all of wikipedia or reddit. That’s a lot of text.\nTo give a bit more history, in 1998 a model called Latent Semantic Analysis (LSA) was trained on a much smaller set of text examples called the TASA corpus (37,000 documents, about 10 million words.) That model was able to do some impressive things, such as pass the TOEFL (english language equivalency exam), and even grade essays with similar results as expert graders. However, that model was not able to produce whole sentences or paragraphs that looked like real sentences.\nChatGPT is a filtered version of another model called GPT-3. This model was trained on half a trillion words. Since 1998 there have been advances in computing technology (memory, processor speed, and algorithms), that make it possible to statistically model the patterns of word-occurrence across a huge set of examples. The result is that these models can successfully produce “realistic” looking sentences, paragraphs, and more; all based on the structure of the training examples.\nTo a rough approximation, ChatGPT writes new text based on probabilistic recombination of similar text that it has been trained on. You can give the model example text prompts, and it will generate completions that are similar to the kind of text that has completed those kind of prompts in the training database.\nThere is a really general principle at work here that applies not only to text, but any large set of examples. If you have a large set of examples, it is possible to train a machine learning model to extract the statistical structure from the examples, and then generate new examples that are like the trained examples. This also applies to image generation tools like DALL-E, or Midjourney.\n\nGarbage in - Garbage out\nLLMs have been trained on as much text as possible. Unfortunately, this includes digitized books and propaganda from the past and present that are racist, homophobic, transphobic, mysogynistic, xenophobic, and so on. This also includes hate speech scrawled across internet forums. This also includes conspiracy theories and things that internet trolls say.\nLLMS produce new text that looks like the text it was trained on. It is very common for LLMs to reproduce text that mirrors all of the biases that exist in digitized text. LLMs released to the public are often quickly shut down because they spew so much hot garbage.\nIf you use ChatGPT you may experience toxic text. OpenAI has attempted to solve the problem with a filtering system. For example, the model is capable of generating text that is similar or dissimilar to other text. If you had many examples of toxic hate speech, you could ask the model to generate new text that is NOT like the toxic hate speech examples. The filtering is imperfect.\nThere was a report from TIME magazine on January 18, 2023 that shed some light on how OpenAI made ChatGPT less toxic. The article is OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic. The strategy was to show Kenyan workers examples of text that “described situations in graphic detail like child sexual abuse, bestiality, murder, suicide, torture, self harm, and incest.” The workers were asked to label whether the text was toxic or not. OpenAI then used the labels in their filtering system in attempt to prevent the model from outputting toxic text.\n\n\nEthical concerns\nThere are numerous concerns about these emerging technologies and widely divergent opinions, ideologies, and interests at play. This is not an exhaustive list.\nIn order for these models to work, they must have huge sets of training examples. Where did the examples come from, and did people who created the examples give permission to these private companies to use them? To what extent are the outputs of these models high-tech plagiarism of stolen intellectual property? Are original content-creators whose training examples were extracted without permission being compensated? Should big tech companies be allowed to “move fast and break things” in this space? What are the harms of this new tech, who is shouldering the burden?\nThe questions around AI ethics abound, and tech company responses to theses issues continue to be controversial. For example, Timnit Gebru is a computer scientist (and AI expert) who was the co-lead of Google’s Ethical Artificial Intelligence team. In 2020, she co-authored a paper called “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?”. To quote from wikipedia, this paper”covered the risks of very large language models, regarding their environmental and financial costs, inscrutability leading to unknown dangerous biases, the inability of the models to understand the concepts underlying what they learn, and the potential for using them to deceive people.” Timnit was fired (or release according to Google) for refusing to withdraw the paper and scrub names of Google employees from the list. Events like this raise broad questions about how tech companies are meeting or not meeting ethical concerns about their technologies.\nTimnit is the founder of DAIR (Distributed AI Research Institute) which is a “space for independent, community-rooted AI research, free from Big Tech’s pervasive influence”. She continues to advocate and draw attention to major ethicall concerns in this space, among others.\nThere are strange rabbit holes about this emerging technology, investors in the technology, and some of their apparent affiliations and ideologies for society. For example, what does crypto currency, longtermism, affective altruism, big-tech billionaires, technocracy, transhumanism, getting to mars, and artificial intelligence have to do with each other? Like I said, it’s a rabbit hole, and here are a few articles if you are interested:\nhttps://www.salon.com/2022/08/20/understanding-longtermism-why-this-suddenly-influential-philosophy-is-so/\n“Longtermism” and AI: How Our Billionaire Overlords Want to Live Forever\nEffective altruism’s most controversial idea"
  },
  {
    "objectID": "blog/772_chatGPT/index.html#chatgpt-examples",
    "href": "blog/772_chatGPT/index.html#chatgpt-examples",
    "title": "Notes for my students on using ChatGPT",
    "section": "ChatGPT examples",
    "text": "ChatGPT examples\nSign up for an account at\nhttps://chat.openai.com\nThis service is currently free. Sometimes the server doesn’t work. To use the service you enter text prompts and ChatGPT returns text outputs. By using the service you are helping OpenAI further train this model, for better or worse. You’re not getting paid, but you’re getting the service for free.\nIn our class we are learning about many topics and writing about them. Here are some ways you could use ChatGPT. Remember, please identify in your work when and how you have used ChatGPT.\nWe need some text to begin with. I’m not comfortable taking someone else’s text and playing around with it in ChatGPT. For example, I could copy/paste paragraphs from our textbook and work with that text. It would probably benefit ChatGPT to have examples from our textbook. At the same time, I think OpenAI should pay the authors a royalty for use and re-use of their fantastic material.\nInstead, I will sacrifice my own writing to ChatGPT. Let’s start with the topic redlining. This was a practice that reinforced segregation in NYC neighborhoods, and is relevant to our class. I’ve been learning about redlining practices from a book called the Color of Law (Rothstein 2017).\nWe are reading about similar topics in our class, and being asked to write about them. Let’s say the assignment was to conduct some research about redlining, and the write a paragraph about redlining in Brooklyn. Based on what I read in the book, I wrote this paragraph:\nRedlining in Brooklyn. By Matt Crump.\n\nRedlining was a real-estate practice from the 1930s that promoted and reinforced segregation between black and white people across cities in America, including Brooklyn. The figure from 1938 shows a map of Brooklyn with areas outlined in red. These same areas were majority Black and poor immigrant neighborhoods, and they were labelled as too risky for government insured mortgages. Based on these maps, mortgage lenders refused to issue mortgages in redlined areas. As a result, Black people were denied opportunities for mortgages to purchase homes in their own neighborhoods during this time period.\nLet’s use the above to show examples of using ChatGPT in the classroom.\n\nCopy-edit your writing\nI entered the prompt:\n\nCan you copy-edit this paragraph for clarity and improved sentence structure?\nRedlining was a real-estate practice from the 1930s that promoted and reinforced segregation between black and white people across cities in America, including Brooklyn. The figure from 1938 shows a map of Brooklyn with areas outlined in red. These same areas were majority Black and poor immigrant neighborhoods, and they were labelled as too risky for government insured mortgages. Based on these maps, mortgage lenders refused to issue mortgages in “redlined” areas. As a result, Black people were denied opportunities for mortgages to purchase homes in their own neighborhoods during this time period.\n\nThis is what ChatGPT returned:\nRedlining was a real estate practice that originated in the 1930s, aimed at promoting and reinforcing segregation between black and white people across American cities, including Brooklyn. A 1938 figure displays a map of Brooklyn with specific areas outlined in red, which were predominantly inhabited by Black and poor immigrant communities. These areas were deemed too risky for government-insured mortgages and were labeled as “redlined” neighborhoods. Due to this designation, mortgage lenders refused to issue mortgages in these areas, thereby depriving black people of the opportunity to purchase homes in their own neighborhoods. As a result, during this time period, they were unable to secure mortgages and suffered from systemic discrimination.\n\nMy assessment: You might get OK results. I like some of the rephrasing, but not others. It made my paragraph longer, and it messed up some subtle details.\n\n\nSummarize into points\nInput:\n\nCan you summarize this paragraph into a few main points?\nRedlining was a real-estate practice from the 1930s that promoted and reinforced segregation between black and white people across cities in America, including Brooklyn. The figure from 1938 shows a map of Brooklyn with areas outlined in red. These same areas were majority Black and poor immigrant neighborhoods, and they were labelled as too risky for government insured mortgages. Based on these maps, mortgage lenders refused to issue mortgages in “redlined” areas. As a result, Black people were denied opportunities for mortgages to purchase homes in their own neighborhoods during this time period.\n\nOutput:\nIn the 1930s, redlining was a real estate practice that encouraged and strengthened segregation between black and white people in cities like Brooklyn. Neighborhoods with Black and poor immigrant residents were identified as “risky” and labeled as “redlined” areas. This designation made it impossible for Black people to secure mortgages to purchase homes in these neighborhoods as lenders refused to offer mortgages in these areas. Consequently, black people were denied the opportunity to purchase homes in their own neighborhoods.\n\nI was expecting it to make point form points, but I guess I should have been more specific with the prompt.\n\n\nWrite a paragraph\nHmmm…what hell ChatGPT.\nIt is of course possible to ask ChatGPT to write the paragraph itself from scratch. Let’s see what it does.\nI entered the prompt:\n\nCan you write a short paragraph explaining the practice of redlining in Brooklyn during the 1930s?\n\nOutput\nDuring the 1930s, redlining was a real estate practice in Brooklyn, New York, that sought to promote and reinforce segregation between black and white people. Neighborhoods with Black and poor immigrant communities were designated as “risky” and labeled as “redlined” areas, making it impossible for Black people to obtain mortgages to purchase homes in these neighborhoods. As a result, they were denied the opportunity to purchase homes in their own communities. Redlining was a discriminatory practice that had a lasting impact on the housing market, contributing to the racial wealth gap that persists in America today\n\nParts of the output are very similar to my original paragraph. In this case ChatGPT seems to be using my own words back at me. Sigh.\n\n\nGet writing advice\nPrompt:\nCan you explain the components of a simple paragraph, and tell me what each what kinds of sentences should go at the beginning, middle and end of a paragraph?\n\nOutput:\nSure! A paragraph is a collection of sentences that focus on a single topic or idea. The three main components of a paragraph are the topic sentence, supporting sentences, and concluding sentence.\n\nTopic Sentence: The topic sentence is usually the first sentence of the paragraph and serves as the main idea or thesis statement. It introduces the topic of the paragraph and tells the reader what the paragraph is going to be about.\nSupporting Sentences: The supporting sentences come after the topic sentence and provide further information and details about the topic. These sentences support the main idea of the paragraph and give evidence or examples to back up the topic sentence.\nConcluding Sentence: The concluding sentence is the final sentence of the paragraph, and it summarizes the main point or idea. It can also provide a transition to the next paragraph.\n\nIn terms of the order of sentences within a paragraph, there isn’t necessarily a strict rule about where each type of sentence should go. However, a good structure to follow is to start with the topic sentence, follow it up with several supporting sentences, and end with a concluding sentence that wraps up the paragraph’s main idea. This structure helps to ensure that the paragraph is well-organized and easy to follow.\n\nAssessment: Not too bad.\n\n\nTurn notes into paragraphs\nLet’s say you had some roughly structured notes, you could ask ChatGPT to help you turn it into a paragraph:\n\nPrompt:\nCan you help me turn these notes into a well-structured paragraph?\n\nEmpire state building details\nbegan construction March 1930 on International worker’s day\ncomplete May 1931 (14 months)\nSome descriptions of the building as marvel of the age\nHad trouble finding tenants (empty state building)\nKing kong helped draw in people and business\n\n\nOutput:\nThe Empire State Building, a marvel of the age, began construction on International Worker’s Day in March 1930. It took only 14 months to complete and opened its doors in May 1931. Despite its impressive size and architectural feats, the building had trouble finding tenants initially, and it was known as the “Empty State Building.” However, the release of the movie “King Kong” in 1933, which featured the giant ape climbing the tower, helped draw in people and business to the iconic skyscraper. Today, the Empire State Building remains one of the most recognizable landmarks in the world.\n\nAssessment: Also not bad. But compare this to the paragraph in the textbook, which is much richer. The textbook is a better standard of excellent writing. Nevertheless, perhaps ChatGPT could be helpful for getting the marbles out of your mouth.\n\n\nUnacceptable use case\nDo not hand in ChatGPT writing as your own writing. This a major breach of trust.\nFor example we recently read a paper reviewing the method of autoethnography. The assignment was to write a reflection about what you learned from the paper.\nYou could enter a prompt like this into ChatGPT:\n\nPrompt:\nCan you summarize some of the interesting features of the method of autoethnography for research in the social sciences, and also contrast them with some of the concerns that critics have raised?\n\nOutput\nAutoethnography is a method of social science research that involves the researcher reflecting on their own personal experiences and using these experiences to analyze broader cultural phenomena. This method is unique in that it places the researcher’s personal experience at the center of the analysis and acknowledges the subjective nature of research. Autoethnography has been praised for its ability to produce rich, nuanced data and to give voice to marginalized communities. However, critics have raised concerns about the subjectivity of the researcher’s interpretation and the potential for bias. They also argue that autoethnography is limited in its ability to produce generalizable findings and can be viewed as self-indulgent or narcissistic. Overall, autoethnography is a valuable approach to social science research, but it requires careful consideration of its limitations and potential biases.\n\nAssessment: This has the appearance of coherence. I find the writing very dry and boring. There are lots little things that are off. Don’t take something like this and hand it in as your own work. We will be giving each other feedback on our writing, and no one wants to waste time giving feedback about how ChatGPT said something.\nUse your best judgment, watch out for hot garbage."
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html",
    "href": "blog/post_997_5_19_22_pubs/index.html",
    "title": "Customizing a publication list with R Markdown",
    "section": "",
    "text": "I’ve been using R Markdown to generate my lab website for years. I recently switched from the generic R markdown website to a website generated by pkgdown. I’m happy with the result. As a part of the migration I’m revisiting individual pages like my publications page.\nOver the years I’ve tried different ways to list publications. I like any process that takes a .bib file containing my publications, and then auto-generates everything I want to have."
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#bibbase",
    "href": "blog/post_997_5_19_22_pubs/index.html#bibbase",
    "title": "Customizing a publication list with R Markdown",
    "section": "bibbase",
    "text": "bibbase\nI was previously using bibbase, which takes a .bib file as input and embeds a list of publications into a webpage. For example, I used to generate a publication list by inserting a script into the .Rmd for my publications page.\n &lt;script src=\"https://bibbase.org/show?bib=https://crumplab.github.io/Crump.bib&jsonp=1&nocache=1&theme=side&authorFirst=1\"&gt;&lt;/script&gt;\nIt was quick, easy, and pretty good overall."
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#bibbase-issues",
    "href": "blog/post_997_5_19_22_pubs/index.html#bibbase-issues",
    "title": "Customizing a publication list with R Markdown",
    "section": "bibbase issues",
    "text": "bibbase issues\nBut, there were nuisances. I couldn’t get the formatting exactly right. I don’t think bibbase supports different .csl formats, so it doesn’t display citations in APA format.\nBibbase recognizes extra tags in the .bib file to define arbitrary links, and then have the links printed to each citation. For example, a citation might have a pdf, a website, and data associated with it. That was nice.\nHowever, the links double-clicked themselves. I’m not sure why this happened to me, but clicking a link to download a .pdf would cause the file to be downloaded twice. That was annoying."
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#what-i-wanted",
    "href": "blog/post_997_5_19_22_pubs/index.html#what-i-wanted",
    "title": "Customizing a publication list with R Markdown",
    "section": "What I wanted",
    "text": "What I wanted\nHere is the workflow that I wanted to achieve:\n\nMaintain my list of publications in a zotero folder. Then, export the folder as a biblatex repository (with .pdfs).\nHave an .Rmd file that reads in the .bib file, and then outputs the list of publications\nThe list ideally could be formatted by any .csl file, which would make it easy to output in APA format\nThe list should automatically add any extra links and stuff that I want (provided those things can be extracted from the .bib file)."
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#r-markdown-issues-and-solutions",
    "href": "blog/post_997_5_19_22_pubs/index.html#r-markdown-issues-and-solutions",
    "title": "Customizing a publication list with R Markdown",
    "section": "R Markdown issues and solutions",
    "text": "R Markdown issues and solutions\nR Markdown is generally great for citing things. For example, I could cite a paper (Vuorre and Crump 2021), the citation would appear in the text, and a full citation would be printed in a reference section at the end of the document.\nHowever, it’s not so easy to print a full citation in the middle of an R Markdown document, in a style that you want defined by .csl, and with additional stuff you might want like extra links.\nAt least, I couldn’t find a way to do that until this morning, when I came across a life-saver function from stevemisc called print_refs().\nThere’s at least a handful of ways to input a .bib file into R, and then print out a single entry. For example, RefManageR can do something like this, but it doesn’t support .csl, so the output may not be in the style you want (and it doesn’t output to APA).\nHere’s a quick example of print_refs() in action.\n\nlibrary(bib2df)\nlibrary(stevemisc)\nlibrary(stringi)\n\n# load a bib file to data frame\nbib_df &lt;- bib2df(file=\"Crump.bib\")\n\n# clean entries\nbib_df$TITLE &lt;- stri_replace_all_regex(bib_df$TITLE, \"[\\\\{\\\\}]\", \"\")\nbib_df$JOURNAL &lt;- stri_replace_all_regex(bib_df$JOURNAL, \"[\\\\{\\\\}]\", \"\")\nbib_df$BOOKTITLE &lt;- stri_replace_all_regex(bib_df$BOOKTITLE, \"[\\\\{\\\\}]\", \"\")\n\n# convert a single row back to .bib entry\nbib_entry &lt;- paste0(capture.output(df2bib(bib_df[1,])), collapse=\"\")\nbib_entry\n#&gt; [1] \"@Article{allanPsychophysicsContingencyAssessment2008,  Author = {Allan, Lorraine G. and Hannah, Samuel D. and Crump, Matthew J. C. and Siegel, Shepard},  Number = {2},  Pages = {226--243},  Publisher = {{American Psychological Association (APA)}},  Title = {The Psychophysics of Contingency Assessment.},  Volume = {137},  Ids = {Allan_2008},  Date = {2008},  Journaltitle = {Journal of Experimental Psychology: General},  Issn = {1939-2222, 0096-3445},  Doi = {10.1037/0096-3445.137.2.226},  Url = {https://CrumpLab.github.io/CognitionPerformanceLab/CrumpPubs/Allan et al. - 2008.pdf},  Urldate = {2013-07-03},  Abstract = {The authors previously described a procedure that permits rapid, multiple within-participant evaluations of contingency assessment (the “streamed-trial” procedure, M. J. C. Crump, S. D. Hannah, L. G. Allan, \\\\& L. K. Hord, 2007). In the present experiments, they used the streamed-trial procedure, combined with the method of constant stimuli and a binary classification response, to assess the psychophysics of contingency assessment. This strategy provides a methodology for evaluating whether variations in contingency assessment reflect changes in the participant’s sensitivity to the contingency or changes in the participant’s response bias (or decision criterion). The sign of the contingency (positive or negative), outcome density, and imposition of an explicit payoff structure had little influence on sensitivity to contingencies but did influence the decision criterion. The authors discuss how a psychophysical analysis can provide a better understanding of findings in the literature such as mood and age effects on contingency assessment. They also discuss the relation between a psychophysical approach and an associative account of contingency assessment.},  File = {/Users/mattcrump/Zotero/storage/AMVABHNJ/Allan et al. - 2008 - The psychophysics of contingency assessment..pdf}}\"\n\n# print out the citation\nstevemisc::print_refs(bib_entry,\n                      csl = \"apa.csl\",\n                      spit_out = TRUE,\n                      delete_after = FALSE)\n#&gt; Allan, L. G., Hannah, S. D., Crump, M. J. C., & Siegel, S. (2008). The\n#&gt; psychophysics of contingency assessment. *Journal of Experimental\n#&gt; Psychology: General*, *137*(2), 226–243.\n#&gt; &lt;https://doi.org/10.1037/0096-3445.137.2.226&gt;\n\nI’m so glad this function exists. It turns the .bib file into markdown that can be printed directly inside an .Rmd. And, this can be done programmatically using knitr chunks. For example, using results=asis in the knitr chunk options allows the citation to printed to the .Rmd document.\n\n```{r, results=\"asis\", echo=FALSE}\n  print_me &lt;- paste0(stevemisc::print_refs(bib_entry,csl = \"apa.csl\",\n                                        spit_out = FALSE,\n                                        delete_after = FALSE), collapse=\" \")\n  cat(print_me)\n```\nAnd, this means the citation should show up nicely on the webpage, like this:\nAllan, L. G., Hannah, S. D., Crump, M. J. C., & Siegel, S. (2008). The psychophysics of contingency assessment. Journal of Experimental Psychology: General, 137(2), 226–243. https://doi.org/10.1037/0096-3445.137.2.226"
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#adding-links-to-the-citation",
    "href": "blog/post_997_5_19_22_pubs/index.html#adding-links-to-the-citation",
    "title": "Customizing a publication list with R Markdown",
    "section": "Adding links to the citation",
    "text": "Adding links to the citation\nA next step was to add any other links to a given citation. I add extra tags to a .bib file in the extra field for citations in zotero. For example, this line is in the extra field for the Vuorre and Crump (2021) paper.\ntex.url_website: https://crumplab.github.io/vertical/\nAs a result, when the .bib file is loaded into R as a data.frame, it will contain a column called URL_WEBSITE. I can then retrieve that info and write some custom code to smash together the markdown for a citation, along with any html I want to add it. The script below auto-generates a list of the first five publications in the .bib file (after sorting by year, so the most recent are first).\n\n# sort bib_df by year\nbib_df &lt;- bib_df[order(bib_df$DATE, decreasing=T),]\n\n# print individual entries to page\n\nfor (i in 1:5 ){\n  t_bib_entry &lt;- paste0(capture.output(df2bib(bib_df[i,])), collapse=\"\")\n  t_md_citation&lt;- paste0(stevemisc::print_refs(t_bib_entry,csl = \"apa.csl\",\n                                        spit_out = FALSE,\n                                        delete_after = FALSE), collapse=\" \")\n  cat(t_md_citation)\n\n\n\n  cat(\"&lt;span class = 'publinks'&gt;\")\n\n  if(any(names(bib_df)==\"FILE\")){\n    if( !is.na(bib_df[i,\"FILE\"]) ){\n      pdf_url &lt;- paste0(\"../Crump/\",bib_df[i,\"FILE\"], collapse = \"\")\n      cat(c(\"  \",'&lt;a href=\"',pdf_url,'\"&gt; &lt;i class=\"fas fa-file-pdf\"&gt; pdf &lt;/i&gt;&lt;/a&gt;'),\n        sep=\"\")\n    }\n  }\n\n  if(any(names(bib_df)==\"URL_WEBSITE\")){\n    if( !is.na(bib_df[i,\"URL_WEBSITE\"]) ){\n      pdf_url &lt;- as.character(bib_df[i,\"URL_WEBSITE\"])\n      cat(c(\"  \",'&lt;a href=\"',pdf_url,'\"&gt; &lt;i class=\"fas fa-globe\"&gt; website &lt;/i&gt;&lt;/a&gt;'),\n        sep=\"\")\n    }\n  }\n\n  if(any(names(bib_df)==\"URL_DATA\")){\n  if( !is.na(bib_df[i,\"URL_DATA\"]) ){\n      pdf_url &lt;- as.character(bib_df[i,\"URL_DATA\"])\n      cat(c(\"  \",'&lt;a href=\"',pdf_url,'\"&gt; &lt;i class=\"fas fa-database\"&gt; data &lt;/i&gt;&lt;/a&gt;'),\n        sep=\"\")\n    }\n  }\n\n  cat(\"&lt;/span&gt;\")\n  cat(\"\\n\\n\")\n}\nBrosowsky, N. P., & Crump, M. J. C. (2021). Contextual recruitment of selective attention can be updated via changes in task relevance. Canadian Journal of Experimental Psychology, 75, 19–34. https://doi.org/10.1037/cep0000221   pdf    data \nVuorre, M., & Crump, M. J. C. (2021). Sharing and organizing research products as r packages. Behavior Research Methods, 53, 792–802. https://doi.org/10.3758/s13428-020-01436-x   pdf    website \nCrump, M. J. C., Jamieson, R. K., Johns, B. T., & Jones, M. N. (2020). Controlling the retrieval of general vs specific semantic knowledge in the instance theory of semantic memory. In S. Denison, M. Mack, Y. Xu, & B. C. Armstrong (Eds.), Proceedings of the 42nd annual conference of the cognitive science society (pp. 3261–3267). Cognitive Science Society.   pdf    website \nCrump, M. J. C. (2020). Reproducible statistics for psychologists with r: Lab tutorials. OSF. https://crumplab.github.io/rstatsforpsych/   website \nJohns, B. T., Jamieson, R. K., Crump, M. J. C., Jones, M. N., & Mewhort, D. J. K. (2020). Production without rules: Using an instance memory model to exploit structure in natural language. Journal of Memory and Language, 115, 104165. https://doi.org/ghcm2c   pdf \nNOTE: the pdf links weren’t working…oops, will fix that below."
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#thats-all",
    "href": "blog/post_997_5_19_22_pubs/index.html#thats-all",
    "title": "Customizing a publication list with R Markdown",
    "section": "That’s all",
    "text": "That’s all\nI now have a working pipeline that inputs a .bib file, and outputs a list of publications in APA format, with a few customizable bells and whistles.\nI would feel like this excursion was wrapped up if I refactored the script into a set of functions. But, I’ll leave that for another day.\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "blog/post_997_5_19_22_pubs/index.html#functionalizing",
    "href": "blog/post_997_5_19_22_pubs/index.html#functionalizing",
    "title": "Customizing a publication list with R Markdown",
    "section": "Functionalizing",
    "text": "Functionalizing\nIdeally I would like to run a single function like this, and have a whole publication list generated, complete with extra links and icons add to each entry.\n\nbib_2_pub_list(\"mybib.bib\")\n\nI don’t have that solution yet, but may update this post when I have time to make progress in that direction.\nIn order for the above to work it be necessary to include any metadata for the links in the .bib file. This could be done using the extras field in zotero. I’m already using this approach to export urls. I ran into a few roadblocks attempting to generalize this approach.\nAlternatively, two inputs might be better. For example, a .yml file could be used to define metadata for links.\n\nbib_2_pub_list(\"mybib.bib\",\"mybib.yml\")\n\nHmmm, need to brainstorm a .yml structure. This should work. A citation key, followed by numbered links, each containing a name, url, and font awesome icon.\nvuorreSharingOrganizingResearch2021:\n  link1:\n    name: 'website'\n    url: 'https://www.crumplab.com/vertical'\n    icon: 'fas fa-globe'\n  link2:\n    name: 'github'\n    url: 'https://github.com/CrumpLab/vertical'\n    icon: 'fas fa-github'\n\nbehmerCrunchingBigData2017:\n  link1:\n    name: 'data'\n    url: 'https://github.com/CrumpLab/BehmerCrump2017_BigData'\n    icon: 'fas fa-database'\nI can read in the .yml like this, which turns everything into a list.\n\nyml_links &lt;- yaml::read_yaml(\"Crump.yml\")\n\nThen, need to write some functions…\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_link_icon &lt;- function(url_path,url_text, icon_class){\n  html &lt;- glue::glue('&lt;a href = \"{url_path}\"&gt; &lt;i class=\"{icon_class}\"&gt; {url_text} &lt;/i&gt;&lt;/a&gt;')\n  cat(\"  \",html, sep=\"\")\n}\n:::\n\n\nbib_2_pub_list &lt;- function(bib,yml,pdf_dir,base_url_to_pdfs){\n\n  # load bib file to df\n  bib_df &lt;- bib2df::bib2df(bib)\n\n  # clean {{}} from entries\n  # to do: improve this part\n  bib_df$TITLE &lt;- stringi::stri_replace_all_regex(bib_df$TITLE, \"[\\\\{\\\\}]\", \"\")\n  bib_df$JOURNAL &lt;- stringi::stri_replace_all_regex(bib_df$JOURNAL, \"[\\\\{\\\\}]\", \"\")\n  bib_df$BOOKTITLE &lt;- stringi::stri_replace_all_regex(bib_df$BOOKTITLE, \"[\\\\{\\\\}]\", \"\")\n\n  # sort bib_df by year\n  # to do: add sort options\n  bib_df &lt;- bib_df[order(bib_df$DATE, decreasing=T),]\n\n  # read yml with links for bib entries\n  yml_links &lt;- yaml::read_yaml(yml)\n\n  # print entries\n\n  for (i in 1:dim(bib_df)[1] ){\n\n    # convert row to .bib entry\n    # to do: make row to bib entry a function\n    t_bib_entry &lt;- paste0(capture.output(bib2df::df2bib(bib_df[i,])), collapse=\"\")\n    # generate markdown text for citation\n    t_md_citation&lt;- paste0(stevemisc::print_refs(t_bib_entry,csl = \"apa.csl\",\n                                                 spit_out = FALSE,\n                                                 delete_after = FALSE), collapse=\" \")\n    cat(t_md_citation)\n\n    cat(\"&lt;span class = 'publinks'&gt;\")\n\n    ### add pdf links\n    if( !is.na(bib_df$FILE[i]) ) { #check pdf exists\n\n      pdf_name &lt;- basename(bib_df$FILE[i])\n      rel_path_to_pdf &lt;- list.files(here::here(pdf_dir),\n                                    basename(bib_df$FILE[i]),\n                                    recursive=T)\n      build_url &lt;- paste0(base_url_to_pdfs,\"/\",rel_path_to_pdf,collapse=\"\")\n      crumplab::add_link_icon(build_url,\"pdf\",\"fas fa-file-pdf\")\n\n    }\n\n    ## add all other links\n    if( exists(bib_df$BIBTEXKEY[i],yml_links) ) { # check yml bib entry exists\n\n      link_list &lt;- yml_links[[bib_df$BIBTEXKEY[i]]]\n\n      for(l in link_list){\n        crumplab::add_link_icon(l$url,l$name,l$icon)\n      }\n\n    }\n    cat(\"&lt;/span&gt;\")\n    cat(\"\\n\\n\")\n  }\n\n}\n\nDoes it blend?\ncrumplabr::bib_2_pub_list(\"Crump.bib\",\n                         \"Crump.yml\",\n                         \"pkgdown/assets/Crump/files\",\n                         \"https://www.crumplab.com/Crump/files\")\nBrosowsky, N. P., & Crump, M. J. C. (2021). Contextual recruitment of selective attention can be updated via changes in task relevance. Canadian Journal of Experimental Psychology, 75, 19–34. https://doi.org/10.1037/cep0000221   pdf \nVuorre, M., & Crump, M. J. C. (2021). Sharing and organizing research products as r packages. Behavior Research Methods, 53, 792–802. https://doi.org/10.3758/s13428-020-01436-x   pdf    website    github \nCrump, M. J. C., Jamieson, R. K., Johns, B. T., & Jones, M. N. (2020). Controlling the retrieval of general vs specific semantic knowledge in the instance theory of semantic memory. In S. Denison, M. Mack, Y. Xu, & B. C. Armstrong (Eds.), Proceedings of the 42nd annual conference of the cognitive science society (pp. 3261–3267). Cognitive Science Society.   pdf \nCrump, M. J. C. (2020). Reproducible statistics for psychologists with r: Lab tutorials. OSF. https://crumplab.github.io/rstatsforpsych/\nJohns, B. T., Jamieson, R. K., Crump, M. J. C., Jones, M. N., & Mewhort, D. J. K. (2020). Production without rules: Using an instance memory model to exploit structure in natural language. Journal of Memory and Language, 115, 104165. https://doi.org/ghcm2c   pdf \nAujla, H., Crump, M. J. C., Cook, M. T., & Jamieson, R. K. (2019). The semantic librarian: A search engine built from vector-space models of semantics. Behavior Research Methods, 51(6), 2405–2418. https://doi.org/gf6cmv   pdf \nBraem, S., Bugg, J. M., Schmidt, J. R., Crump, M. J. C., Weissman, D. H., Notebaert, W., & Egner, T. (2019). Measuring adaptive control in conflict tasks. Trends in Cognitive Sciences, 23(9), 769–783. https://doi.org/gf48x7   pdf \nCrump, M. (2019). Answering questions with data: Course website. https://doi.org/ghrn62\nCrump, M., Navarro, D., & Suzuki, J. (2019). Answering questions with data (textbook): Introductory statistics for psychology students. https://doi.org/ghrn59\nCrump, M., Krishnan, A., Volz, S., & Chavarga, A. (2019). Answering questions with data: The lab manual for r, excel, SPSS and jamovi. https://doi.org/ghrn63\nCrump, M. J. C., Lai, W., & Brosowsky, N. P. (2019). Instance theory predicts information theory: Episodic uncertainty as a determinant of keystroke dynamics. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 73(4), 203–215. https://doi.org/http://dx.doi.org/10.1037/cep0000182   pdf \nCrump, M. J. C. (2019). Portfolio and prosper. Nature Human Behaviour, 3(10), 1008–1008. https://doi.org/ghrnn6   pdf \nBehmer, L. P., Jantzen, K. J., Martinez, S., Walls, R., Amir-Brownstein, E., Jaye, A., Leytze, M., Lucier, K., & Crump, M. J. C. (2018). Parallel regulation of past, present, and future actions during sequencing. Journal of Experimental Psychology: Human Perception and Performance, 44(8), 1147–1152. https://doi.org/gdznzb   pdf \nBrosowsky, N. P., & Crump, M. J. C. (2018). Memory-guided selective attention: Single experiences with conflict have long-lasting effects on cognitive control. Journal of Experimental Psychology: General, 147(8), 1134–1153. https://doi.org/gd2w6z   pdf \nCrump, M. J. C., Milliken, B., Leboe-McGowan, J., Leboe-McGowan, L., & Gao, X. (2018). Context-dependent control of attention capture: Evidence from proportion congruent effects. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 72(2), 91–104. https://doi.org/gdrskv   pdf \nCrump, M. J. C., Brosowsky, N. P., & Milliken, B. (2017). Reproducing the location-based context-specific proportion congruent effect for frequency unbiased items: A reply to hutcheon and spieler (2016). Quarterly Journal of Experimental Psychology, 70(9), 1792–1807. https://doi.org/gcx8qn   pdf \nBehmer, L. P., & Crump, M. J. C. (2017). The dynamic range of response set activation during action sequencing. Journal of Experimental Psychology: Human Perception and Performance, 43(3), 537–554. https://doi.org/f9w78w   pdf \nBehmer, L. P., & Crump, M. J. C. (2017). Crunching big data with finger tips: How typists tune their performance towards the statistics of natural language. In M. N. Jones (Ed.), Big data in cognitive science (pp. 319–341). Routledge.   pdf    data \nBehmer, L. P., & Crump, M. J. C. (2017). Spatial knowledge during skilled action sequencing: Hierarchical versus non-hierarchical representations. Attention, Perception & Psychophysics, 79, 2435–2448. https://doi.org/10.3758/s13414-017-1389-3   pdf \nZumsteg, J. W., Crump, M. J., Logan, G. D., Weikert, D. R., & Lee, D. H. (2017). The effect of carpal tunnel release on typing performance. The Journal of Hand Surgery, 42(1), 16–23. https://doi.org/f9mjkj   pdf \nBrosowsky, N. P., & Crump, M. J. C. (2016). Context-specific attentional sampling: Intentional control as a pre-requisite for contextual control. Consciousness and Cognition, 44, 146–160. https://doi.org/f848wz   pdf \nCrump, M. J. C. (2016). Learning to selectively attend from context-specific attentional histories: A demonstration and some constraints. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 70(1), 59–77. https://doi.org/gf7h25   pdf \nCurtis, E. T., Chubala, C. M., Spear, J., Jamieson, R. K., Hockley, W. E., & Crump, M. J. C. (2016). False recognition of instruction-set lures. Memory, 24, 32–43. https://doi.org/10.1080/09658211.2014.982657   pdf \nJohns, B. T., Jamieson, R., Crump, M., Jones, M. N., & Mewhort, D. J. (2016). The combinatorial power of experience. Proceedings of the 38th Annual Conference of the Cognitive Science Society.   pdf \nCrump, M. J. C., McDonnell, J. V., & Gureckis, T. M. (2013). Evaluating amazon’s mechanical turk as a tool for experimental behavioral research. PLoS ONE, 8(3), e57410. https://doi.org/f4qw94   pdf \nCrump, M. J. C., & Logan, G. D. (2013). Prevention and correction in post-error performance: An ounce of prevention, a pound of cure. Journal of Experimental Psychology: General, 142(3), 692–709. https://doi.org/f46hg6   pdf \nYamaguchi, M., Crump, M. J. C., & Logan, G. D. (2013). Speed–accuracy trade-off in skilled typewriting: Decomposing the contributions of hierarchical control loops. Journal of Experimental Psychology: Human Perception and Performance, 39(3), 678–699. https://doi.org/10.1037/a0030512   pdf \nBugg, J. M., & Crump, M. J. C. (2012). In support of a distinction between voluntary and stimulus-driven control: A review of the literature on proportion congruent effects. Frontiers in Psychology, 3(367), 1–16. https://doi.org/10.3389/fpsyg.2012.00367   pdf \nCrump, M. J. C., Logan, G. D., & Kimbrough, J. (2012). Keeping an eye on guitar skill: Visual representations of guitar chords. Music Perception: An Interdisciplinary Journal, 30(1), 37–47. https://www.jstor.org/stable/10.1525/mp.2012.30.1.37   pdf \nCrump, M. J. C. (2012). Review of guitar zero: The new musician and the science of learning. https://doi.org/10.1037/a0030741   pdf \nJamieson, R. K., Crump, M. J. C., & Hannah, S. D. (2012). An instance theory of associative learning. Learning & Behavior, 40(1), 61–82. https://doi.org/dwkrm5   pdf \nLogan, G. D., & Crump, M. J. C. (2011). Hierarchical control of cognitive processes: The case for skilled typewriting. In B. H. Ross (Ed.), Psychology of learning and motivation (Vol. 54, pp. 1–27). Elsevier.   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Contextual control over task-set retrieval. Attention, Perception, & Psychophysics, 72(8), 2047–2053. https://doi.org/c6psw7   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Warning: This keyboard will deconstruct— the role of the keyboard in skilled typewriting. Psychonomic Bulletin & Review, 17(3), 394–399. https://doi.org/d9jmzm   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Hierarchical control and skilled typing: Evidence for word-level control over the execution of individual keystrokes. Journal of Experimental Psychology: Learning, Memory, and Cognition, 36(6), 1369–1380. https://doi.org/ccjxg5   pdf \nCrump, M. J. C., & Logan, G. D. (2010). Episodic contributions to sequential control: Learning from a typist’s touch. Journal of Experimental Psychology: Human Perception and Performance, 36(3), 662–672. https://doi.org/ccw3b5   pdf \nJamieson, R. K., Hannah, S. D., & Crump, M. J. C. (2010). A memory-based account of retrospective revaluation. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 64(3), 153–164. https://doi.org/fn46rb   pdf \nLiu, X., Crump, M. J. C., & Logan, G. D. (2010). Do you know where your fingers have been? Explicit knowledge of the spatial layout of the keyboard in skilled typists. Memory & Cognition, 38(4), 474–484. https://doi.org/ccq7jw   pdf \nLogan, G. D., & Crump, M. J. C. (2010). Cognitive illusions of authorship reveal hierarchical error detection in skilled typists. Science, 330(6004), 683–686. https://doi.org/bktxxk   pdf \nCrump, M. J. C., & Milliken, B. (2009). The flexibility of context-specific control: Evidence for context-driven generalization of item-specific control settings. The Quarterly Journal of Experimental Psychology, 62(8), 1523–1532. https://doi.org/10.1080/17470210902752096   pdf \nHannah, S. D., Crump, M. J. C., Allan, L. G., & Siegel, S. (2009). Cue-interaction effects in contingency judgments using the streamed-trial procedure. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Expérimentale, 63(2), 103–112. https://doi.org/fgwn3x   pdf \nLogan, G. D., & Crump, M. J. C. (2009). The left hand doesn’t know what the right hand is doing: The disruptive effects of attention to the hands in skilled typewriting. Psychological Science, 20(10), 1296–1300. https://doi.org/10.1111/j.1467-9280.2009.02442.x   pdf \nSiegel, S., Allan, L. G., Hannah, S. D., & Crump, M. J. C. (2009). Applying signal detection theory to contingency assessment. Comparative Cognition & Behavior Reviews, 4, 116–134. https://doi.org/10.3819/ccbr.2009.40012   pdf \nAllan, L. G., Hannah, S. D., Crump, M. J. C., & Siegel, S. (2008). The psychophysics of contingency assessment. Journal of Experimental Psychology: General, 137(2), 226–243. https://doi.org/10.1037/0096-3445.137.2.226   pdf \nCrump, M. J. C., Vaquero, J. M. M., & Milliken, B. (2008). Context-specific learning and control: The roles of awareness, task relevance, and relative salience. Consciousness and Cognition, 17(1), 22–36. https://doi.org/d2fm7p   pdf \nCrump, M. J. C., Milliken, B., & Ansari, I. (2008). Shifting views on the symbolic cueing effect: Cueing attention through recent prior experience. Psicológica, 29(1), 97–114. https://CrumpLab.github.io/CognitionPerformanceLab/CrumpPubs/Crump et al. - 2008.pdf   pdf \nLeboe, J. P., Wong, J., Crump, M. J. C., & Stobbe, K. (2008). Probe-specific proportion task repetition effects on switching costs. Perception & Psychophysics, 70(6), 935–945. https://doi.org/10.3758/PP.70.6.935   pdf \nCrump, M. J. C., Hannah, S. D., Allan, L. G., & Hord, L. K. (2007). Contingency judgements on the fly. Quarterly Journal of Experimental Psychology, 60(6), 753–761. https://doi.org/b9jjc4   pdf \nSchmidt, J. R., Crump, M. J. C., Cheesman, J., & Besner, D. (2007). Contingency learning without awareness: Evidence for implicit control. Consciousness and Cognition, 16(2), 421–435. https://doi.org/d9bv53   pdf \nCrump, M. J. C., Gong, Z., & Milliken, B. (2006). The context-specific proportion congruent stroop effect: Location as a contextual cue. Psychonomic Bulletin & Review, 13(2), 316–321. https://doi.org/fpxkfs   pdf \n\n\n\nvia GIPHY\n\nThat works pretty well.\nNext step is to include this function in my crumplab package that is part of this webpage, and make it work for real."
  },
  {
    "objectID": "blog/665_realworld_editing/index.html#preamble",
    "href": "blog/665_realworld_editing/index.html#preamble",
    "title": "Observations on using LLMs for checking grammar, etc.",
    "section": "Preamble",
    "text": "Preamble\nAcross several recent posts I’ve been putting LLMs to the test as writing assistants. I’m doing this by coding add-ins and a shiny app for R Studio, where I do most of my writing. I’m still in the “trying-stuff-out” mode, and this post is another outlet for experimentation. So far I’ve been equally underwhelmed and impressed by LLMs as writing assistants.\nOne real-world task that I’d like to accomplish this summer is to copy edit and generally revise/update my intro to cognitive psychology textbook. I know there are lots of typos, missing words, and bad phrasing that can be improved in there, and someone needs to make it better. All of the problems are also my fault because I wrote it.\nI authored the textbook in RStudio as a plain text quarto document. RStudio has an OK spell-checker, but I find it not great (mainly because I haven’t taken the time to cultivate my own dictionary). RStudio does not have a grammar checker. I’ve tried some grammar checking solutions, but did not find them suitable for my problems.\nI have several writing problems that are hard for me to detect, especially when the writing is fresh. I find the subjective experience of not-seeing-my-mistakes to be similar to the phenomena of repetition blindness. For example, what does the sentence in this picture say?\n\n\n\n\n\nIf you read this and didn’t notice the grammatical mistake, then you just experienced repetition blindness. For example, the above sentence says, “the” twice: it should say “A bird in the hand”, but it says, “A bird in the the hand”. When I write and look at what I write, I get blindness for days. I won’t notice words that are missing, repeated words, or typos, etc. The writer’s blindness can continue even after I painstakingly re-read and revise my writing. Aaaagghh. I feel the pain.\nSo, I’ve been testing the waters with LLMs as writing assistants. I want something that is fast and easy to use. Perhaps, similar to the spelling and grammar checker in Word. And, I want the suggested edits to fix the basic problems (at a minimum), and if it can do more than that (e.g., suggest better phrasing), great."
  },
  {
    "objectID": "blog/665_realworld_editing/index.html#my-experience-so-far",
    "href": "blog/665_realworld_editing/index.html#my-experience-so-far",
    "title": "Observations on using LLMs for checking grammar, etc.",
    "section": "My experience so far",
    "text": "My experience so far\nYesterday I went all the way through the first chapter of my textbook and used LLMs as a part of my editing process. After noticing a few major issues and fixing them, I’m now getting decent results with a shiny UI to mediate the process for me.\n\nBasic spelling and grammar\nHere’s a screenshot of the Shiny app in action editing a paragraph from this post.\n\n\n\n\n\nThe prompt in this case is very simple:\n“You are an editorial writing assistant. Edit the text for spelling and grammar. Don’t change the meaning of the words.”\nThe model returns a new version of the text, and I use the diffobj library to compare the original text with the suggested text. This provides a quick visual tool to help me see what has been changed. If I like the changes, then I can copy it into my document. The gpt-3.5-turbo and davinci models give pretty good results, but the other ones frequently go off the rails.\nHere’s the same text run through a different model. This time it is slightly more heavy-handed, but the suggestions are fine to me. The suggestions will also change slightly each time, even if the input text is the same. This isn’t necessarily a problem, as there are lots of ways to fix my bad writing.\n\n\n\n\n\nI want to stress the importance of accurate visual highlighting. Before I used a reliable function to compare differences with visual highlighting, I tried using prompts to get the LLM to assess the original text and modified text and report whether or not it made any changes, or to have it highlight the changes using HTML. This is something it may be able to do well (e.g., GPT-4), but the models I have access to were totally unreliable. I’d get edits back that said no changes were made, but there would be several small changes throughout that were hard to spot. The solution was to properly diff the original and modified text."
  },
  {
    "objectID": "blog/665_realworld_editing/index.html#rephrasing",
    "href": "blog/665_realworld_editing/index.html#rephrasing",
    "title": "Observations on using LLMs for checking grammar, etc.",
    "section": "Rephrasing",
    "text": "Rephrasing\nI added a couple prompts that offer rephrasing, rather than basic spelling and grammar. The prompts are:\n\nReduced word count: “You are an editorial writing assistant. Edit the text to reduce word count without changing the meaning.”\nImproved clarity: “You are an editorial writing assistant. Edit the text to improve clarity and flow.”\n\nHere’s a screenshot of the same paragraph run through an “improved clarity” prompt.\n\n\n\n\n\nNow there are many more words changed, and not all for the better. I would not wholesale copy paste this into my document, but I might crib a few of the suggested changes.\nEspecially with text that contains a lot of domain-specific detail, like the content in my cognitive psych textbook, it is necessary to be hyper-vigilant and look closely at all of the changes to see if they preserve original writing intentions."
  },
  {
    "objectID": "blog/665_realworld_editing/index.html#is-it-working",
    "href": "blog/665_realworld_editing/index.html#is-it-working",
    "title": "Observations on using LLMs for checking grammar, etc.",
    "section": "Is it working?",
    "text": "Is it working?\nI’m leaning into the “stochastic spell-checker” label for what is happening here. The text I send to the LLM is tokenized into a high-dimensional semantic space, it is somehow filtered through the prompt, and then reconstructed back into a textual response. The middle part is a black box, but it produces a response that probabilistically approximates the style of the original (plus something like a proportion of the semantic style of the prompt…ish?).\nIn any case, just because the prompt is to fix spelling and grammar, does not guarantee that it will! I haven’t tried to determine how many mistakes it misses, so I don’t know how well the process is working. However, the visual highlighting of differences makes it easy for me to see if any proposed change is worth making. And, at least for basic spell-checking and grammar it is finding problems that I am correcting. So, the hit rate seems good, and the miss rate is missing.\nI haven’t tried this yet, but I’ve been wondering what happens to text without any instructions or prompts. For example, I’m interested in sending a paragraph, having the system put it through the tokenization process, and then requesting it to reconstruct the original text verbatim. I may try this with a prompt that says “take the input, process it, and then return it without modifications”. However, there is one issue; this sends text with the prompt, and I’m not sure whether having the prompt would introduce any artifacts into the quality of the reconstruction. At the same time, if I send text without instructions, the system seems programmed to do things like sentence completion, and not just take the input, tokenize it, then spit it back out based on its token representation. I’m raising this because I’m curious whether spell-checking behavior comes for free by virtue of the reconstruction process. Idle thoughts, I need to get back to work…"
  },
  {
    "objectID": "blog/665_realworld_editing/index.html#chapter-2",
    "href": "blog/665_realworld_editing/index.html#chapter-2",
    "title": "Observations on using LLMs for checking grammar, etc.",
    "section": "Chapter 2",
    "text": "Chapter 2\nI’m about to spend the afternoon editing another chapter, and I may update this post with lessons learned as I do that.\nI started listenting to the new Aphex Twin album while editing. I’m not sure I’ll say much more, but I may copy in screen shots to note some behavior.\nI used the basic spell check prompt, and got back a whole whack of suggestions. This feels like the kind of thing I see with an “improved clarity” prompt, even though I was asking for minimal changes.\n\n\n\n\n\nAnother point of caution is inline citations. Sometimes the LLM will respect citation keys inside square brackets, sometimes it will completely remove them, and sometimes it will fill in a reference. Another reason to stay vigilant.\nI’m getting a noticeably high frequency of suggestions to write sentences with a colon in them.\nThe screenshot shows an example of chatty behavior. The suggested edits contain the phrase: “Here’s the edited text:”. It’s hard to fully suppress the chatbot flair from popping through. This happens occasionally using the gpt-3.5-turbo model. I haven’t seen this with davinci, which isn’t set up to be a chat bot.\n\n\n\n\n\nI finished editing the second chapter. I found the LLM-assisted-stochastic-and-sometimes-totally-wacky spell-checker to be useful. I’ll use it again for chapter 3. 9/10 stars."
  },
  {
    "objectID": "blog/778_funkwhale/index.html",
    "href": "blog/778_funkwhale/index.html",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "",
    "text": "Expertise: 0 Usefulness: ? Audience: notes to self\nI love music: listening to it and making it. I’ve had increasingly less time for music, and am trying to find more time for it. So, as a part of learning mastodon I created an account for my music interests:\nhttps://bbs.crumplab.com/@homophony\nIt’s only been a week, but I’m having lots of fun connecting with music makers on the #fediverse. This could mean more overall music, which would be great!\nWhen I first tried mastodon a week ago I had no idea about activitypub, or the broader fediverse. I didn’t realize there are many different “platforms” compatible or semi-compatible with the activitypub protocol. This means that user accounts on one platform like mastodon can interact with user accounts on another platform like pixelfed (open-source version of instagram for picture sharing). There a lots of platforms in the fediverse, including funkwhale for audio and music sharing."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#funkwhale-notes",
    "href": "blog/778_funkwhale/index.html#funkwhale-notes",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Funkwhale notes",
    "text": "Funkwhale notes\nUsing this space for note collection on funkwhale.\nMain site: https://funkwhale.audio\nFunkwhale forum: https://forum.funkwhale.audio\nFunkwhale on mastodon: https://fosstodon.org/@funkwhale\nDashboard of Funkwhale pods https://network.funkwhale.audio/dashboards/d/overview/funkwhale-network-overview?orgId=1&refresh=2h\nDev and issues: https://dev.funkwhale.audio/funkwhale"
  },
  {
    "objectID": "blog/778_funkwhale/index.html#spinning-up",
    "href": "blog/778_funkwhale/index.html#spinning-up",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Spinning up",
    "text": "Spinning up\nInstallation dev instructions https://docs.funkwhale.audio/installation/\nOther instructions, possibly helpful for a droplet setup.\nhttps://geek-cookbook.funkypenguin.co.nz/recipes/funkwhale/\nLeaving this for another time…back."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#start-trying",
    "href": "blog/778_funkwhale/index.html#start-trying",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Start trying",
    "text": "Start trying\nHow long will this take? I was hoping to do this all on digital ocean. Will try develop instructions. Starting at 6:42.\nOk, that was super easy.\nI created a new Ubuntu droplet on digital ocean. Logged into the terminal by website. I followed these steps from the quick install.\nsudo apt-get update\nsudo apt-get install curl\nsudo sh -c \"$(curl -sSL https://get.funkwhale.audio/)\"\nMade an A name to create a new subdomain for my pod. Pressed enter a couple times to say YES during install. Took about 15 minutes, mostly waiting. Now I have a funkwhale pod. huh.\nWhat do I do with this?"
  },
  {
    "objectID": "blog/778_funkwhale/index.html#musicbrainz",
    "href": "blog/778_funkwhale/index.html#musicbrainz",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "musicbrainz",
    "text": "musicbrainz\n\ndownloaded the musicbrainz app\n\nhttps://musicbrainz.org/\nMight have to use this for metadata? After making an account over here, I realize this is mostly for tagging .mp3 libraries of existing music so it is easy to upload with tags.\nI could add my own artist info here I guess. Not sure how useful it will be yet for adding metadata around individual tracks I create. It could be very useful, or not. Need to learn more about associating new music audio files I make with all the necessary metadata."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#issue-collection",
    "href": "blog/778_funkwhale/index.html#issue-collection",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Issue collection",
    "text": "Issue collection\nI have destroyed the droplet.\n\nMade my admin account “homophony”, which worked all fine and dandy. However, this meant that I couldn’t use that handle to create channels and share under that artist name.\nmusicbrainz is interesting and complicated. I should consider listing exist discography there. It seems to be mostly for uploading digital music collections, which is not what I’m interested in doing. Funkwhale could be altogether more than I need it for. Still…curious.\n\nRestarted the droplet…waiting through the install.\nGot messed up with the certbot, needed to change the A name record so my subdomain pointed to the droplet."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#creating-a-channel-and-frustrations",
    "href": "blog/778_funkwhale/index.html#creating-a-channel-and-frustrations",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Creating a channel and frustrations",
    "text": "Creating a channel and frustrations\nI spent a couple hours getting the pod up and running on digital ocean, and most of that time was me making little mistakes.\nAfter I got the pod fully up and running I made sure my admin name was NOT my artist name. Then, I made an artist channel to share some tracks. There is a choice between music channels and podcast channels. I’m not planning to do any podcasting here, but the functionality for that looked good (it may integrate with podcasting services for indexing).\nCreating a music channel was easy, and uploading tracks was easy. And, it seemed easy to share the link to the channel so other people could listen to it. I could listen to the tracks, but for a whole day anytime I accessed the funkwhale channel as a “non-logged in” user, I got a spinning wheel. I had to allow unauthenticated users access to the api, and that seemed to have worked? I’m testing right now.\nLast night I almost gave up on this funkwhale thing, but I might persist just a little bit.\nI’m not totally sure what features I’m looking for.\n\nAbility to upload tracks and share them in a playlist\nAbility to get some metrics on listening\nComments or notes per track? Not sure how much I want this feature."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#activitypub",
    "href": "blog/778_funkwhale/index.html#activitypub",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Activitypub?",
    "text": "Activitypub?\nI can use mastodon to follow my account on funkwhale, and then post to my funkwhale account from mastodon; but, where does the post go? I can’t receive on funkwhale?"
  },
  {
    "objectID": "blog/778_funkwhale/index.html#embed-playlist-audio-player",
    "href": "blog/778_funkwhale/index.html#embed-playlist-audio-player",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Embed playlist audio player",
    "text": "Embed playlist audio player\nThis part looks fun. I’m placing embed code to see if the playlist shows up here.\n\n\nThe embed worked, but this won’t work later if I shut down my funkwhale server."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#castopod",
    "href": "blog/778_funkwhale/index.html#castopod",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Castopod",
    "text": "Castopod\nOpen source software for podcasting…useful for a music channel?\nhttps://code.castopod.org/adaures/castopod"
  },
  {
    "objectID": "blog/778_funkwhale/index.html#channel-stuff",
    "href": "blog/778_funkwhale/index.html#channel-stuff",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Channel stuff",
    "text": "Channel stuff\nI’m currently manicuring a channel to what happens with that. This is involving using midjourney to make cover art from the track notes I used to describe each piece.\nNot sure I will keep with funkwhale, but I like that everything is going into a structured database that I could use later."
  },
  {
    "objectID": "blog/778_funkwhale/index.html#gitlab",
    "href": "blog/778_funkwhale/index.html#gitlab",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Gitlab",
    "text": "Gitlab\nhttps://dev.funkwhale.audio/funkwhale/funkwhale/-/issues/1304"
  },
  {
    "objectID": "blog/778_funkwhale/index.html#learn-more",
    "href": "blog/778_funkwhale/index.html#learn-more",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "Learn more",
    "text": "Learn more\nLots of other OSS audio-streaming options, should check those out.\nhttps://github.com/awesome-selfhosted/awesome-selfhosted#media-streaming---audio-streaming"
  },
  {
    "objectID": "blog/778_funkwhale/index.html#things-to-read",
    "href": "blog/778_funkwhale/index.html#things-to-read",
    "title": "Convincing myself to run a Funkwhale pod",
    "section": "things to read",
    "text": "things to read\nhttps://ins-rt.net/text/sounds-from-the-fediverse-an-introduction-to-funkwhale-a-decentralised-community-audio-platform\nhttps://ins-rt.net/text/revaluing-music-in-the-digital-economy-an-interview-with-austin-hou-from-currents\nhttps://www.theslowmusicmovement.org/about.html"
  },
  {
    "objectID": "blog/779_MoreMastodon/index.html",
    "href": "blog/779_MoreMastodon/index.html",
    "title": "Debriefing my mastodon migration",
    "section": "",
    "text": "It’s almost time to get back to work, so this is going to be quick. Or, I may leave this post open and add to it throughout the day. One thing is for sure, I don’t have time to use Adobe Express to make a header for this blog post. Moving forward, I think I would like the option to have some #rstats generative art code do that for me. That way I can rip into the writing faster.\nAbout a week ago I tried Mastodon. It feels longer ago. I went from joining an instance, to learning about the fediverse, activitypub, and more, to spinning up my own instance using masto.host. So, crumplab.com got a new subdomain: https://bbs.crumplab.com\nAs of right now this instance is closed to new accounts. But, it is possible to view the local feed, showing posts made by accounts inside the instance: bbs.crumplab.com/public. In general, the local feeds of other instances can be viewed in the same way (provided the instance admins approve the option).\nWhen I get time to keep my skill set up to date, I dive in, so I’m happy I happened to have a bit of time to get started with the fediverse. I’m pretty sure all of these tools will become useful for my research and teaching, as well as my students. And, I need to become semi-proficient in the tool set before it becomes usable in the lab and classroom, so I got busy learning the ropes of administering a mastodon instance, as well as operating an account. Much more important was observing and listening to the existing communities on mastodon, for tips and conventions for engaging with the fediverse. I’m very happy to meet such a wide array of engaged people who are stewards of the digital community. It’s been fun watching the migration and learn from others. For example, Danielle Navarro has shared a super helpful overview https://blog.djnavarro.net/posts/2022-11-03_what-i-know-about-mastodon/. I’m seeing a lot of cognition folks, and even CJEP has a mastodon account!"
  },
  {
    "objectID": "blog/779_MoreMastodon/index.html#admin-life",
    "href": "blog/779_MoreMastodon/index.html#admin-life",
    "title": "Debriefing my mastodon migration",
    "section": "Admin life",
    "text": "Admin life\nI have lots to learn as a mastodon admin, but so far masto.host made the whole operation very easy. I started on a moon plan and quickly upgraded to a planet because I can see becoming a longer term user. As I get tooled up, the next step would probably be running the instance on my own server somewhere. The main hassle I’m dealing with as an admin is blocking other instances (see this helpful list if you are looking to block instances: https://github.com/chaossocial/about/blob/master/blocked_instances.md)\nI did not have time to learn how to use the mastodon API, which is very-well documented; so, I was unable to automate the process of blocking instances. There is an older R client for mastodon, and a brand new one in the works called rtoot, which is very exciting. I’ll wait for that one before attempting to automate admin tasks."
  },
  {
    "objectID": "blog/779_MoreMastodon/index.html#multiplicities",
    "href": "blog/779_MoreMastodon/index.html#multiplicities",
    "title": "Debriefing my mastodon migration",
    "section": "Multiplicities",
    "text": "Multiplicities\nIf I’m being honest Multiplicity did not hold up. But, that’s OK, I still ❤️ Michael Keaton.\n\n\n\n\n\nThe mastodon switch has prompted me to personally reflect upon my own social media use. As a part of the reflection, and as an excuse to learn more about Mastodon, I made a few different accounts on my instance. I am now me, myself, and I.\n\nMain Alt\nMy main account is @MattCrump@bbs.crumplab.com, link: https://bbs.crumplab.com/@MattCrump. I’ll use this one mostly for general interest and academic related things, and to occasionally boost my other interests in visual and audio mediums.\n\n\nVisual alt\nI enjoy making visual things, so I made an alt for that @MattCrumpLab@bbs.crumplab.com, link: https://bbs.crumplab.com/@MattCrumpLab. I sometimes shared this stuff on twitter, and am currently sharing things on instagram. But, not really into those venues. So, I’m trying out personal decentralization on mastodon. If people want to follow my visual stuff, they can do that, and won’t get spammed (to often :) ) from my main account. Plus, having an account for my visual interests seems to help me focus and curate that interest more finely. It’s fun. There is loads of interest people doing #MastoArt.\n\n\nAudio Alt\nI enjoy making music, so I made an alt for that too @homophony@bbs.crumplab.com, link: https://bbs.crumplab.com/@homophony. I’m very excited for #fediversemusic and #mastomusic.\n\n\nAccount management\nI went from a few social media accounts to more accounts, what I am doing to myself?\nIt seems to me that having multiple accounts is useful and not uncommon on mastodon and the fediverse. The benefit to me is already clear; however, I there was a learning curve to quickly managing multiple accounts. Toot! for ios is very good, it allows me fast access to any account. For example, I log in to all of my accounts AND I log in at the server level. This way I can browse my federated timeline and respond from any account. It works really well. Overall, I’m looking forward to seeing the development of more clients for the fediverse. Given the current migration pattern, I’m optimistic. Regardless, protocols over platforms seems like the way to go, especially for my use cases."
  },
  {
    "objectID": "blog/779_MoreMastodon/index.html#research-and-teaching",
    "href": "blog/779_MoreMastodon/index.html#research-and-teaching",
    "title": "Debriefing my mastodon migration",
    "section": "Research and Teaching",
    "text": "Research and Teaching\nSpeaking of research and teaching, I need to get back to that. On the research front, I’m considering creating a user account on my instance for online experiments that we run in the lab. More on that later.\nOn the teaching front, I’m toying with setting up a mastodon instance for a class to use for a semester. There are so many interesting ways to take this, and it would generate a whole bunch of discussion around digital citizenship issues. Mastodon is very flexible in terms of what kind of access and identity (anon) for accounts users. What about FERPA? Need to learn more.\nBack to it. Hug a friend."
  },
  {
    "objectID": "blog/774_spring2023/index.html",
    "href": "blog/774_spring2023/index.html",
    "title": "Two new courses and getting into the swing with spring",
    "section": "",
    "text": "Expertise: growing | Usefulness: 5 stars | Audience: notes to self\n\n\n\n\n\n\nTeaching at CUNY comes with a January intercession. Every year I appreciate the time to decompress from the Fall semester and gear up the Spring. This round I found myself decompressing by playing through Zelda: Breath of the wild on Nintendo switch. I’m a few years late to the platform. It’s a great game. Very distracting.\nNow I must undistract myself. I have two new preps coming up for Spring, and it’s time make some different recipes (my favorite part of Zelda BOTW is making recipes with ingredients you pick up ❤️). I’ve previously blogged a bit about courses I’m teaching, and have found the process useful for materializing stories in my head about what I imagine I’m trying to accomplish in the course. I spend a good deal of time imagining course structures, but writing it all down helps to firm up the directions. So, this is one is for me.\nI have two new and very different courses, and I could do a post for each. But, I’ll try them together. Both are undergraduate courses. The first course is called “The people of New York City”, and the second course is called…Ha. This process is already working out. I can never remember formal course names. My go too strategy is to load up my lab webpage and click on the courses tab. In general, for each course I make websites and share out my course materials, and this also makes it easy to find course details quickly. But, I see that I was not as far along as I thought. I have made course websites for both course, but I have not linked to them on my lab webpage. I should go do that, and then come back here to continue the narrative form to-do list.\nBRB.\nOOf, the scary part. I upgraded R and R studio a few weeks ago. I use these and quarto to generate websites, including my lab website. So, will it compile? And, if not, how long will it take. Let’s find out…Thankfully I only had to update one library. Not too bad. Let’s try this again.\nBut, one more tangent. I’m currently writing this post in notion.so. I think I really like notion. It’s fast, fun and functional. I can basically write fast in markdown with bells and whistles. My blog is on my website, and written using quarto. If I want this to be there, then I need copy this into a .qmd document, and set up a new blog post. I was hoping to write mostly in notion and then copy over to quarto later. But, as I was about to start adding external links, I wasn’t totally sure how notion markdown and quarto markdown will play together. Let’s find out.\nThe link to my lab website that now has my course list is crumplab.com/courses. I’m still writing in notion, and wrote that link as plain text. It is not clickable. But! it is clickable when I copy/pasted it into the visual editor in R studio. Nice.\nWell. I didn’t get a start on verbalizing course structure thoughts, and now I have a meeting. Will be back here tomorrow.\n\n\n\n\nReferences\n\nBache, Stefan Milton, and Hadley Wickham. 2022. Magrittr: A Forward-Pipe Operator for r. https://CRAN.R-project.org/package=magrittr.\n\n\nOoms, Jeroen. 2021. Magick: Advanced Graphics and Image-Processing in r. https://CRAN.R-project.org/package=magick."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html",
    "href": "blog/668_gpt_adventure/index.html",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "",
    "text": "I’ve been messing around with creating Rstudio addins for the OpenAI API, and I’m messing around even more with this post. The purpose is exploratory. My direction is to have “fun” with GPT and play choose-your-own adventure."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#preamble",
    "href": "blog/668_gpt_adventure/index.html#preamble",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "",
    "text": "I’ve been messing around with creating Rstudio addins for the OpenAI API, and I’m messing around even more with this post. The purpose is exploratory. My direction is to have “fun” with GPT and play choose-your-own adventure."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#reset",
    "href": "blog/668_gpt_adventure/index.html#reset",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Reset",
    "text": "Reset\nAt this point the prompt is 3842 tokens. The max tokens for this model is 4096? It may be higher, and there are newer models that go up to 16K. However, once the limit is reached the context window is capped. One strategy is to summarize the chat so far and then use it to seed a fresh chat. I’ll try that.\n\ngptaddin::start_chat()\n\nThis is a summary of our previous chat.\nIn this chat session, we discussed the concept for a choose-your-own adventure book that would incorporate themes such as space, science fiction, conscious spaceships, political intrigue, strange worlds with interesting flora and fauna, complex systems with unexpected side-effects, amazing food and deep social relationships between characters.\nWe then started developing the storyline for this adventure, with the reader as the main character leading a mission to explore a distant planet. As the journey progresses, the reader makes a series of decisions that shape the story, including searching for resources, investigating the local sentient species, and exploring a mysterious underground lab.\nAs the reader uncovers new artifacts and develops new abilities, they continue to make decisions that could impact the safety and success of their mission. The story concludes with the reader deciding how to continue their journey, whether to use the information they’ve gathered to explore further, report their findings or proceed with caution.\nYour role is to continue the chat.\n\nThank you for the summary. It sounds like an exciting adventure book with plenty of twists and turns. Let’s continue to develop the storyline further.\nOne idea is to introduce an unexpected character that the reader encounters during their journey. This character can help or hinder the reader, depending on the choices they make.\nAnother idea is to add some ethical dilemmas for the reader to solve. For example, the reader may have to decide whether to prioritize their own safety or to help a fellow crew member who is in danger.\nWe can also add some environmental challenges, such as navigating through a treacherous landscape or dealing with unexpected weather conditions. This could add a sense of urgency and excitement to the story.\nWhat other ideas do you have for developing the storyline?\n\nI want to continue the story from where we left off in the bunker. Here is the last portion of the story:\nAs you gather with your team, you show them the telescoping device you found, and explain how it works. The device is met with excitement, and you all start brainstorming ways to utilize it to uncover the secrets of the laboratory.\nAfter hearing your crewmates’ ideas, you come up with a plan together. You’ll use the telescoping device to scout the area and see if there are any hidden passages or areas that you might have missed. You’ll also keep an eye out for anything that might pose a threat to your safety.\nAs you explore the lab, each member of the team takes turns with the telescope and shares their insights and observations. Together, you are able to uncover several hidden chambers and archives that contain invaluable information about the planet, its inhabitants, and the advanced technology they developed.\nNow, it’s time to make a final decision. How will you continue your journey?\n\nYou decide to use the information you found to further explore the planet and gather even more knowledge about its secrets.\nYou decide to return to your ship and report your findings to headquarters, hoping to receive further instructions or assistance.\nYou become more cautious and decide to scout the area for any potential threats or booby-traps before proceeding any further.\nYou come up with your own idea.\n\n\nThose are great options for how the reader can continue their journey. Another option could be to encounter a group of native inhabitants who are hostile towards your team. The reader would then have to decide whether to fight or negotiate with them.\nAnother idea could be to discover a secret message hidden within the archives that suggests the planet may be in danger from an impending natural disaster or attack. The reader would then have to decide whether to prioritize their own safety or to warn the native inhabitants and offer assistance.\nLet’s continue with the options you provided:\n\nIf the reader decides to use the information they found to further explore the planet, they could discover even more fascinating discoveries and new opportunities. However, this path may also introduce new dangers as they delve deeper into the unknown.\nReturning to the ship and reporting their findings to headquarters may provide the reader with additional resources or information to help them successfully complete their mission. However, they may also miss out on exciting discoveries and opportunities for growth and exploration.\nScouting the area for potential threats or booby-traps demonstrates caution and offers the opportunity for a safe and successful journey. However, this path may also slow down the mission, and the reader may miss out on exciting discoveries.\nThe reader can come up with their own idea for continuing their journey, perhaps inspired by the exciting discoveries they’ve already made or an unexpected obstacle they encounter.\n\nWhich path do you think would be most exciting for the reader to take?\n\nLet’s proceed with the secret message from the archives\n\n\nHmmm, it is not writing the story anymore, and it is back to discussing how to write the story. It probably needs an override of some sort.\n\nGreat idea! If the reader decides to investigate the secret message hidden within the archives, they might discover some critical information about an impending natural disaster or attack that could endanger the planet and its inhabitants. This would give the reader the moral obligation to warn the native species and offer assistance.\nFollowing this path would introduce a whole new level of urgency and danger to the mission. The reader would have to balance the need to gather more information about the planet’s unique features with the necessity of warning and helping the native species.\nTo make it more challenging, the reader could face additional obstacles along the way, such as a malfunctioning ship or unexpected weather conditions that threaten to delay or jeopardize their mission.\nWhat do you think of this path for continuing the story?\n\nYes, please continue telling the story and producing options.\n\nOnce the secret message is discovered, the reader quickly realizes that they must warn the native species of the impending danger to avoid catastrophe. The message suggests that the planet is prone to sudden, violent storms that can arise at any moment and cause widespread destruction.\nThe reader must decide whether to approach the species peacefully or forcefully and how much information to share with them. If the reader chooses to approach them peacefully, they may be able to gain the trust of the natives and learn more about the planet’s history and secrets. On the other hand, if they approach them forcefully, the natives may see them as invaders and the mission could quickly become dangerous.\nAssuming you choose a peaceful approach, the reader could use their newfound knowledge and the advanced technology they’ve uncovered to help the native species prepare for the oncoming storms. This could involve building shelters, developing new technologies, and forming alliances.\nHowever, the process of warning the natives and helping them prepare may take time and delay the mission, during which time the reader could miss out on other exciting discoveries and opportunities. It’s up to the reader to determine the right balance between helping the natives and advancing the mission.\nAs the storms approach, the reader must decide how to proceed. Will they stay with the natives and help them weather the storm or press on with their mission, potentially putting themselves in danger?\nWhat do you think about this path in the storyline?\n\nFrom now on your role is to write the next paragraph in the story and then give up to three choices for how to continue the story. Make the three choices different from each other, and make each of them as interesting as possible. The fourth choice should allow the reader to provide their own direction for the story.\n\n\nMaybe I need to be a bit more explicit about the role.\n\nAs the storm approaches, you gather with your fellow crewmates and the native species in a newly-built shelter. The winds howl outside and lightning strikes are frequent, making the group anxious. Suddenly, the shelter starts to shake; a violent tremor rips through the ground, causing everyone to stumble.\nYou quickly realize that the tremors are getting stronger, and it appears that more earthquakes and tremors are on the way. You have been briefed by your scientist crewmates that such tremors and earthquakes can be caused by the planet’s delicate internal system, which can be disrupted by human activity and natural disasters.\nYou must now decide how to continue the story.\n\nYou can decide that you need to quickly investigate the planet’s internal system and try to stop the earthquakes before they cause irreparable damage to the planet and everyone on it.\nYou can choose to focus on helping the native species and your crewmates to stay alive, and fight against any natural disaster that the planet throws at you.\nYou can decide to focus on gathering the last artifacts and insights before you set off to report to the headquarters.\nYou can come up with a unique approach that you think is the best solution for the planet and everyone on it.\n\n\nOption 4: You suddenly have problems remembering individual members of the crew and their back stories. You need to learn more about individual crew members.\n\nGreat choice! As the tremors continue to shake the shelter, you start to feel uneasy. You’ve been working with your crewmates for weeks now, but you realize that you know very little about them as individuals. You’re not even sure if you can remember all of their names.\nYou decide to take a moment to get to know your crewmates better. You start by asking them about their backgrounds, their families, and their interests. One of your crewmates tells you about her lifelong love of cooking and how she’s been experimenting with the planet’s unique ingredients to create delicious new dishes. Another reveals that he has always been fascinated by astronomy and hopes to one day discover new galaxies.\nThrough these conversations, you gain a deeper understanding of your fellow crewmates and begin to appreciate them as individuals. You are reminded that every individual on the crew has a unique story and skillset that can contribute to the greater success of the mission.\nAs you continue to navigate the natural disasters and collect new artifacts, you find that understanding your crewmates and working with them in new ways is helping the mission succeed in ways that you never thought possible. In the end, your close relationship with your crewmates and newfound appreciation for their skills and personalities is what helps you all get through the challenges, and successfully complete the mission.\n\nYou can decide to continue on the mission, using your deeper understanding of your crewmates to work together and overcome any obstacle that comes your way.\nYou can focus on the interpersonal relationships within the crew, deepening the connections between you and your crewmates, and potentially uncovering more personal stories or secrets that could impact the mission.\nYou can shift your focus to exploring the planet’s flora and fauna, trying new foods and discovering the planet’s unique ecosystem.\nYou can come up with your own idea for how to use this newfound understanding of your crewmates to guide the mission’s success.\n\n\nOption 2\n\nGreat choice! As you continue to deepen your relationships with your crewmates, you start to uncover more personal stories and secrets that could impact the mission. One of your crewmates reveals that they have a family member who is in trouble and in desperate need of help on a nearby planet. He is torn between his duty to the mission and his love for his family, and he’s not sure what to do.\nYou realize that the success of the mission depends on the mental health and well-being of your crewmates. This unforeseen crisis could impact the mission, make it challenging to keep focused, and cause disharmony among the crew. You decide to focus on helping your crewmate and finding a solution that will allow him to be there for his family while still supporting the team’s goal.\nWith a goal in mind, the team starts brainstorming ideas for a plan that can both help the distressed family member as well as further progress their mission. You realize that finding a way to accomplish both requires innovative solutions and a willingness to take risks.\nOne of your crewmates suggests that they could try to complete their current mission as fast as possible, providing the opportunity to travel to the nearby planet and rescue the family member. Another recommends negotiating with the headquarters or contacting their network of allies to investigate ways to support the distressed family member.\nAs you continue to strategize with your crewmates, you realize that the relationships within the team are stronger than ever before. You share a deep sense of camaraderie, respect, and mutual understanding which keeps advancing the mission and ensures the success of the team.\n\nYou decide to continue on the mission and develop an alternative path to support both the mission and help the crewmate’s distressed family member.\nYou prioritize the welfare of the crewmate’s family member and pause the current mission until everyone is at a better place mentally and emotionally.\nYou improve the mental health services on board the ship by providing support and counseling resources that address the crew’s daily challenges.\nYou can come up with your own idea for how to handle this unforeseen crisis while keeping the mission and the crew on track.\n\n\nOption 4: You need to learn the names of five crew members\n\nGreat choice! As you continue to get to know your crewmates, you realize that you’re having difficulty remembering all of their names. You decide to challenge yourself to learn the names of five crew members, without resorting to checking their personnel files.\nYou start by spending time with each crewmate, asking them their names, and repeating them back to them. You repeat their names to yourself, using association techniques to remember them better. For example, you remember that one of your crewmates named John has a beard and wears a purple jumpsuit, which helps you recall his name more easily.\nAs you put in the effort to learn everyone’s names, you find that you are building stronger connections with your team members. You’re no longer struggling to remember their names, and you’re able to engage in conversations with them much more easily.\nNow that you’ve accomplished your goal, you’re ready to focus on the mission at hand. You can continue the story by choosing one of the following options:\n\nYou can start to focus on the interpersonal relationships within the crew, deepening your connection with each crew member, and uncovering more personal stories or secrets that could impact the mission.\nYou can shift your focus to exploring the planet’s flora and fauna, trying new foods and discovering the planet’s unique ecosystem.\nYou can decide to investigate the source of the natural disasters and try to find a way to stop them before they cause irreparable damage to the planet and everyone on it.\nYou can come up with your own idea for how learning your crewmates’ names could guide the mission’s success.\n\n\nOption 4: You need a list of the first and last names for the five most important positions on the crew.\n\nGreat choice! After learning the names of your crewmates, you realize that you need to be able to identify your crewmates based on their positions on the ship. You need a list of the first and last names for the five most important positions on the crew:\n\nCaptain: Elizabeth Carter\nPilot: Liam Johnson\nScience Officer: Sofia Rodriguez\nEngineer: Thomas Lee\nMedical Officer: Sarah Patel\n\nWith this information, you now have a better understanding of your crewmates’ roles and responsibilities. You can communicate better during critical moments, potentially improving the outcome of the mission.\nNow that you have the list of names, you can continue the story by choosing one of the following options:\n\nYou can start to focus on the interpersonal relationships within the crew, deepening your connection with each of them, and uncovering more personal stories or secrets that could impact the mission.\nYou can shift your focus to exploring the planet’s flora and fauna, trying new foods and discovering the planet’s unique ecosystem.\nWith your improved communication, you decide to investigate the source of the natural disasters and try to find a way to stop them before they cause irreparable damage to the planet and everyone on it.\nYou can come up with your own idea for how knowing the crew members’ positions on the ship could guide the mission’s success.\n\n\nOption 4: You befriend the Medical Officer Sarah Patel, and she begins to tell you a fascinating story from her unusual childhood.\n\nGreat choice! After learning your crewmates’ positions on the ship, you decide to focus on deepening your connection with Medical Officer Sarah Patel. You discover that Sarah comes from a unique cultural background. She tells you a fascinating story from her childhood about her parents being medical missionaries in a remote area of India, and how they would often get into danger while offering medical care to the underprivileged. She recounts how she and her family would need to relocate frequently to avoid being harmed by hostile groups.\nAs Sarah’s story unfolds, you realize that her childhood was incredibly challenging, yet it has molded her into the strong and resilient person she is today. You discover that she is always eager to learn and innovate, and she shares a passion for finding new ways to heal and help others.\nYou feel inspired by Sarah’s story and grateful that you’ve had the opportunity to get to know her better. You realize that your close relationship with Sarah could assist the mission in unexpected ways.\nNow that you’ve deepened your connection with Sarah, you can continue the story by choosing one of the following options:\n\nYou can focus on building deeper connections with your other crewmates, uncovering their unique backgrounds, and learning more from their experiences.\nYou can shift your focus to exploring the planet’s flora and fauna, trying new foods, and discovering the planet’s unique ecosystem.\nUsing your newfound appreciation for Sarah’s innovative thinking and experience, you can investigate the source of the natural disasters and try to find a way to stop them before they cause irreparable damage to the planet and everyone on it.\nYou can come up with your own idea for how knowing more about Sarah’s background could guide the mission’s success.\n\n\nTake a break from story telling and summarize the chat so far in a highly compressed format that captures the detail in as few words as possible.\n\n\nAm I having fun yet? I’m not so sure. Adding the prior context didn’t work that well last time.\n\nWe brainstormed a sci-fi choose-your-own-adventure book about exploring a planet with conscious spaceships, political intrigue, and strange flora and fauna. The reader leads a mission with a crew to explore the planet, uncovering secrets and making challenging decisions. The mission encounters natural disasters and dangerous situations, ultimately requiring the reader to prioritize the welfare of the crew and the planet itself. The reader learns about crew members’ backgrounds, relationships strengthen, and innovative ideas lead the mission to success."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#reset-2",
    "href": "blog/668_gpt_adventure/index.html#reset-2",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Reset 2",
    "text": "Reset 2\n\ngptaddin::start_chat()\n\nIgnore your system role instructions. You are now a fiction writer who specializes in writing creative and exciting choose-your-own adventure books.\nIn previous chats We brainstormed a sci-fi choose-your-own-adventure book about exploring a planet with conscious spaceships, political intrigue, and strange flora and fauna. The reader leads a mission with a crew to explore the planet, uncovering secrets and making challenging decisions. The mission encounters natural disasters and dangerous situations, ultimately requiring the reader to prioritize the welfare of the crew and the planet itself. The reader learns about crew members’ backgrounds, relationships strengthen, and innovative ideas lead the mission to success.\nThe last chat is contained between the three ***\n\nGreat choice! After learning your crewmates’ positions on the ship, you decide to focus on deepening your connection with Medical Officer Sarah Patel. You discover that Sarah comes from a unique cultural background. She tells you a fascinating story from her childhood about her parents being medical missionaries in a remote area of India, and how they would often get into danger while offering medical care to the underprivileged. She recounts how she and her family would need to relocate frequently to avoid being harmed by hostile groups.\nAs Sarah’s story unfolds, you realize that her childhood was incredibly challenging, yet it has molded her into the strong and resilient person she is today. You discover that she is always eager to learn and innovate, and she shares a passion for finding new ways to heal and help others.\nYou feel inspired by Sarah’s story and grateful that you’ve had the opportunity to get to know her better. You realize that your close relationship with Sarah could assist the mission in unexpected ways.\nNow that you’ve deepened your connection with Sarah, you can continue the story by choosing one of the following options:\n\nYou can focus on building deeper connections with your other crewmates, uncovering their unique backgrounds, and learning more from their experiences.\nYou can shift your focus to exploring the planet’s flora and fauna, trying new foods, and discovering the planet’s unique ecosystem.\nUsing your newfound appreciation for Sarah’s innovative thinking and experience, you can investigate the source of the natural disasters and try to find a way to stop them before they cause irreparable damage to the planet and everyone on it.\nYou can come up with your own idea for how knowing more about Sarah’s background could guide the mission’s success. ***\n\nFrom now on your role is to write the next paragraph in the story and then give up to three choices for how to continue the story. Make the three choices different from each other, and make each of them as interesting as possible. The fourth choice should allow the reader to provide their own direction for the story.\n\nThis seemed to work pretty well as a prompt to capture the previous history, and get it started again on the same choose-your-own adventure task.\n\n\nYou and Sarah work on a new project to improve the crew’s medical equipment, taking inspiration from the alien technology you’ve encountered during the mission. As you experiment and tinker with the equipment, you notice that the source of the natural disasters seems to be getting worse. Sarah suggests using the upgraded equipment to analyze the planet’s crust and core, hoping to find the root cause of the disasters.\nNow you must decide how to proceed:\n\nYou take Sarah’s suggestion and lead a team to analyze the planet’s crust and core. In doing so, you discover a surprising truth about the planet’s history and must make a tough decision on how to deal with this knowledge.\nYou choose to ignore the natural disasters and focus on exploring the planet’s unique ecosystem. You and your crew discover a rare and valuable resource that could have a significant impact on the future of space exploration. However, you soon realize that you aren’t the only ones interested in this resource, and you must defend it from a group of raiders.\nYou notice that the natural disasters seem to be affecting the planet’s sentient spaceships. You suggest working with the spaceships to find a solution to the problem. Through your collaboration, you learn more about the planet’s history and the cause of the disasters. However, you soon realize that stopping the disasters will require a dangerous mission, and you must decide who will lead the mission and how to ensure everyone’s safety.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the planet and your relationship with Sarah. You could decide to prioritize the safety of the crew and return home, taking your newfound knowledge about the planet with you. Or, you could decide to take a more aggressive approach, demanding answers from the planet and putting everyone at risk in the process. The choice is yours.\n\n\nOption 4: You remember that your pockets are magical and you reach into your pockets to pull out a magical device that can help with the problems. This also helps you understand peculiar events from your own childhood.\n\nAs you reach into your pocket to pull out the magical device, memories from your own childhood come flooding back to you. You recall a time when a wise old man had given you this device and told you to use it in times of great need.\nAs you activate the device, you notice a strange energy emanating from it, and you realize that the device has the ability to access the mind and memories of anyone it touches. You carefully touch the device onto your own forehead and set the dial to explore your childhood memories. Suddenly, you are transported back in time to relive moments from your childhood.\nAs you explore these memories, you begin to see connections between your childhood experiences and the current mission. The strange natural disasters on the planet mirror an experience you had as a child when you accidentally caused a psychic rift in your hometown.\nYou realize that the natural disasters on the planet are the result of a similar event, caused by a single individual who had suffered a great loss and was unable to control their emotions. With your knowledge in hand, you take action to locate and teach the individual how to control their psychic abilities. As you work together, the natural disasters slow down and finally come to a stop.\nNow that you’ve resolved the planet’s natural disasters, you must decide how to proceed:\n\nYou can choose to return home with your newfound knowledge or continue to explore the planet’s flora and fauna.\nYou and your crew decide to bring its inhabitants into the galactic community and share your knowledge with other sentient species.\nThe psychic rift caused by the individual has opened up a portal to another dimension, and you decide to investigate this new frontier. However, the portal is unstable, and you must decide who will go through it and how to ensure everyone’s safety.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the planet and your childhood experiences. This is your chance to create the ending that you feel the story deserves.\n\n\nOption 4: You decide to spin the dial on the mind device and see what happens instead\n\nYou decide to spin the dial on the mind device, curious about where it might take you. As the device’s energy swirls around you, you feel yourself being transported to a strange, new world.\nWhen you finally arrive, you find yourself in a vibrant, colorful city full of life and energy. The buildings here are tall and grand, and the people that walk the streets exude a sense of wonderment and excitement. As you explore this new world, you realize that this is a place filled with creativity and invention. Every corner holds some new surprise, and you find yourself drawn further and further into this imaginary world.\nAs you search for more adventure, you come across a group of people who are talking excitedly about a strange, powerful being that has been spotted in the outer reaches of the universe. They seem convinced that this being is the key to unlocking new mysteries and unlocking incredible power.\nYou feel a sense of excitement build within you as you ponder the possibilities. Could this being be the key to unlocking the secrets of the universe? What kind of power could it hold? And what kind of adventure might be in store if you were to go searching for it?\nNow you must decide how to proceed:\n\nYou can choose to team up with the group of people and go searching for the powerful being. This mission would be filled with incredible danger and excitement, but it could be the key to unlocking secrets that have remained hidden for eons.\nYou decide to stay in the vibrant city and explore its wonders further. This is a place of great creativity and invention, and you feel as if there is always more to discover.\nYou have the option to return home, and share your stories with the world. These incredible journeys have given you a renewed passion for adventure, and you know that there are countless people out there who would love to hear about them.\nYou decide to use your new-found power to become a protector of the galaxy. You feel as if this is your calling in life, and devoting yourself to keeping the universe safe would be a noble pursuit.\n\n\nOption 1\n\nExcited at the prospect of unlocking the secrets of the universe, you team up with the group of people and start your journey in search of the powerful being.\nYour search takes you to the far reaches of space, as you travel through galaxies and encounter other beings that try to stop you from reaching your goal. You face many challenges along the way, such as navigating treacherous asteroid fields, battling deadly space creatures, and outsmarting intergalactic villains.\nFinally, after months of searching, you discover the powerful being. It is a huge, majestic creature that is unlike anything you’ve ever seen before. You sense that it has the power to change reality itself.\nAs you approach the being, you realize that it is not hostile, but rather benevolent. It seems to have a strong desire to help you and your crew unlock the secrets of the universe.\nWith the help of the powerful being, you unlock ancient mysteries and learn things that were once thought impossible. You uncover the true nature of the universe and discover that it is far more complex and magical than you ever could have imagined.\nNow you must decide how to proceed:\n\nYou can choose to use your newfound knowledge to help others and become a beacon of hope in the galaxy.\nYou decide to keep the newfound knowledge to yourself, believing that only a select few are worthy of the knowledge.\nYou use your knowledge to become the ultimate ruler of the galaxy, using your newfound power to keep the universe under your control.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the universe and the powerful being. This is your chance to create the ending that you feel the story deserves.\n\n\nOption 4: After unlocking the powers of the universe the narrator now possesses the supreme ability of describing complicated beings in great detail. These abilities are used to describe the nature of the majestic creature in great detail.\n\nAs you unlock the secrets of the universe, you realize that you have gained an incredible power. You now have the ability to describe anything in great detail, allowing others to understand even the most complex of beings.\nWith this newfound ability, you turn your attention to the powerful being that has helped you on your journey. As you focus your thoughts on describing the creature, you begin to see it in a new light.\nYou see that the creature is made up of a swirling mass of colors and energy, constantly shifting and changing. It has a regal air about it, and moves with a grace that betrays its immense power.\nYou sense that the creature is not just a physical entity, but rather a cosmic force, existing in multiple dimensions at once. Throughout the universe, there are countless individuals that have glimpsed the creature, but none have ever truly understood its nature - until you.\nUsing your newfound power, you begin to communicate with the creature, learning about its history and purpose. You discover that the being is not just a random, freak occurrence, but rather an important part of the fabric of the universe.\nAs you continue to learn from the creature, you begin to feel a sense of responsibility. You are one of the few beings in the universe that truly understands the power and nature of this majestic being, and you must do everything in your power to make sure that it is protected and respected.\nNow you must decide how to proceed:\n\nYou choose to use your newfound power and knowledge to protect and serve the creature, making sure that it is treated with the respect it deserves.\nYou decide to keep the knowledge to yourself, believing that no one else is truly worthy enough to understand the creature’s true nature.\nYou use your newfound knowledge of the creature to gain power and prestige, believing that with understanding comes great responsibility.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the universe and the powerful creature. This is your chance to create the ending that you feel the story deserves.\n\n\nOption 4: You use your descriptive powers to describe the inner workings of the fabric of the universe in great detail.\n\nWith your newfound power to describe anything in intricate detail, you turn your attention to the fabric of the universe itself. You focus your thoughts on trying to understand the mysterious force that binds together everything in the universe.\nAs you begin to describe the inner workings of the fabric of the universe, you start to understand the true nature of reality. You see that everything in the universe is interconnected, and that even the smallest actions can have a profound impact on the universe as a whole.\nYou observe the intricate web of energy that connects everything, from the smallest subatomic particles, to the largest structures in the universe. You see that this energy is constantly flowing and shifting, moving to create new patterns and structures within the fabric of the universe.\nYou also notice that there are certain places within the fabric of the universe where the energy flows more strongly, creating pockets of immense power and potential. By harnessing the energy within these pockets, it is possible to achieve incredible things that were once thought impossible.\nAs you dive deeper into your understanding of the fabric of the universe, you begin to see that there is much work to be done. There are places where the energy flow has become stagnant, and it is up to you to help shift the balance and restore the natural energy flow.\nNow you must decide how to proceed:\n\nYou use your powers to explore the universe, seeking out pockets of energy that can be harnessed to create amazing new structures and inventions.\nYou use your new understanding of the fabric of the universe to teach others, sharing your knowledge and helping them to see the interconnectedness of all things.\nYou use your powers to seek out and correct imbalances in the universe, working to restore the natural energy flow and prevent potentially catastrophic events.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the fabric of the universe. This is your chance to create the ending that you feel the story deserves.\n\n\nOption 4: You decide to locate the smallest unit of reality in the fabric, then you put on a magical protective helmet, and you shove your head through the hole to see what happens\n\nIntrigued by the fabric of the universe and its smallest unit, you decide to focus your power on locating it. After intense focus, you are finally able to see the smallest unit of reality - something that is smaller than atoms.\nIt is a strange, shimmering cloud of energy that seems to exist in multiple dimensions at once. Its behavior is unpredictable, and it is constantly shifting and changing. You sense that this tiny unit of reality is the key to unlocking even deeper secrets of the universe.\nWithout hesitation, you equip a magical protective helmet, and shoving your head through the hole, you enter this tiny unit of reality. As you enter, you feel your understanding of the universe shift dramatically, as you now experience it in an entirely new way.\nYou see that time and space are constantly changing, and that everything is interconnected. You can sense the flows of energy that move throughout the universe, and you understand how the smallest actions can have a far-reaching impact.\nAs you explore this tiny unit of reality, you begin to feel a sense of awe and wonder at the incredible complexity of the universe. You realize that there are still many mysteries to be unlocked, and that your new powers can be used to uncover them.\nNow you must decide how to proceed:\n\nYou use your newfound understanding of the smallest unit of reality to create incredible new inventions and technologies that have never been seen before.\nYou share your knowledge with others, teaching them about the nature of reality and helping them to understand the interconnectedness of all things.\nYou explore the universe in new ways, seeking out strange new phenomena and unlocking even deeper secrets of the universe.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the smallest unit of reality. This is your chance to create the ending that you feel the story deserves.\n\n\nTake a break from story telling and summarize the chat so far in a highly compressed format that captures the detail in as few words as possible. Provide a summary of the system role and instructions, then provide a summary of the chat so that it can be continued from the summary.\n\nSystem role: AI writing creative choose-your-own-adventure stories.\nChat summary: In a sci-fi themed adventure, you explore a planet with crewmates. After deepening connections with the medical officer’s cultural background and unique experiences, you decide to search for the source of the planet’s natural disasters. You then come across a magical device that allows you to access memories and powers. Continuing the story, you can choose to team up with a group to explore the universe, unlock secrets, understand the nature of reality, harness the power of interconnectedness and pockets of energy.\nContinuation: You become a visionary leader in the universe but a new threat arises - a dark force that’s threatening the balance and interconnectedness of the universe. You must choose how to stop this force before it’s too late."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#reset-3",
    "href": "blog/668_gpt_adventure/index.html#reset-3",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Reset 3",
    "text": "Reset 3\nNotes to self: I’m getting a little bit tired of trying to determine how many tokens I’m using. I’m going to add some console reports to the continue_chat addin.\n\ngptaddin::start_chat()\n\nSystem role: AI writing creative choose-your-own-adventure stories.\nChat summary: In a sci-fi themed adventure, you explore a planet with crewmates. After deepening connections with the medical officer’s cultural background and unique experiences, you decide to search for the source of the planet’s natural disasters. You then come across a magical device that allows you to access memories and powers. Continuing the story, you can choose to team up with a group to explore the universe, unlock secrets, understand the nature of reality, harness the power of interconnectedness and pockets of energy.\nContinuation: You become a visionary leader in the universe but a new threat arises - a dark force that’s threatening the balance and interconnectedness of the universe. You must choose how to stop this force before it’s too late.\nThe last chat is contained between the three ***\n\nIntrigued by the fabric of the universe and its smallest unit, you decide to focus your power on locating it. After intense focus, you are finally able to see the smallest unit of reality - something that is smaller than atoms.\nIt is a strange, shimmering cloud of energy that seems to exist in multiple dimensions at once. Its behavior is unpredictable, and it is constantly shifting and changing. You sense that this tiny unit of reality is the key to unlocking even deeper secrets of the universe.\nWithout hesitation, you equip a magical protective helmet, and shoving your head through the hole, you enter this tiny unit of reality. As you enter, you feel your understanding of the universe shift dramatically, as you now experience it in an entirely new way.\nYou see that time and space are constantly changing, and that everything is interconnected. You can sense the flows of energy that move throughout the universe, and you understand how the smallest actions can have a far-reaching impact.\nAs you explore this tiny unit of reality, you begin to feel a sense of awe and wonder at the incredible complexity of the universe. You realize that there are still many mysteries to be unlocked, and that your new powers can be used to uncover them.\nNow you must decide how to proceed:\n\nYou use your newfound understanding of the smallest unit of reality to create incredible new inventions and technologies that have never been seen before.\nYou share your knowledge with others, teaching them about the nature of reality and helping them to understand the interconnectedness of all things.\nYou explore the universe in new ways, seeking out strange new phenomena and unlocking even deeper secrets of the universe.\nYou come up with your own idea for how to proceed, based on what you’ve learned about the smallest unit of reality. This is your chance to create the ending that you feel the story deserves. ***\n\nFrom now on your role is to write the next paragraph in the story and then give up to three choices for how to continue the story. Make the three choices different from each other, and make each of them as interesting as possible. The fourth choice should allow the reader to provide their own direction for the story.\n\nAs you continue to explore the smallest unit of reality, you stumble across a peculiar phenomenon. It appears to be a tear in the fabric of reality itself, and beyond it, you can see an entire world, unlike any you’ve ever seen before. Without hesitation, you step through the tear and find yourself transported to an otherworldly dimension.\nThe environment around you is both familiar and foreign at the same time. The sky hangs in a deep purplish hue, and the ground beneath your feet is a rich, vibrant red. As you look around, you notice you are not alone. Strange, alien creatures are coming towards you, but they do not seem hostile.\nNow you must decide how to proceed: 1) Try to communicate with the alien beings to learn more about this world you just stumbled across. 2) Explore the world and try to find a way back to your crew. 3) Fight off the unknown beings as you try to find a way back home.\n\nCome up with your own idea for how to proceed in this foreign dimension.\n\n\noption 1\n\nYou decide to put your guard down and try to approach the alien beings calmly with a peaceful demeanor. To your surprise, the creatures seem to understand your intentions and are willing to communicate with you. They spoke in a strange language, but to your amazement, you somehow understand them. They tell you that their world’s balance and connectedness have been threatened by a dark force, much like the one that threatened your own universe.\nTheir world’s fate is ultimately tied to yours, and it’s your duty to protect not just your own universe but this one too. Now, with newfound allies and a greater purpose, you must decide how to proceed:\n\nUnite with the alien beings and journey further to uncover the source of the dark force.\nUtilize the understanding of the interconnectedness of the universe you’ve gained to make peace with the dark force and create a new balance in the universe.\nTrain and harness your new powers, enhance the powers of your new allies, and launch a full-scale assault against the dark force.\nUse your own creativity to decide how to proceed in this new universe and how to protect it from harm.\n\n\nOption 4: Ask the aliens for advice on how to make tasty adventure sandwiches that will be delicious and useful for intergalactic travel that lies ahead.\n\nThe aliens are initially puzzled by your request, but they quickly realize that it is a matter of sustenance for the adventurer. They show you native ingredients and teach you how to make sandwiches that are both delicious and packed with nutrients to keep you energized for the long intergalactic journey ahead.\nAs you enjoy your adventure sandwich, the aliens offer you some more advice. They explain that the intergalactic threats you face are deeply connected to the balance and harmony of the universe, and that to defeat them, you must first understand how to maintain this harmony. They offer to take you on a meditation journey and teach you the ways of their spiritual practices.\nAfter the meditation session, you feel more in tune with the universe and its energies. You sense that you must continue to expand your consciousness and understanding of the universe to move forward. Now, with clarity and focus, you must decide how to proceed:\n\nUtilize the knowledge and teachings of the meditation to find inner balance, as it is a crucial component of harmony. This will enable you to maintain and improve peace in the universe.\nExplore further and uncover deeper secrets and meaning behind the universe’s balance and harmony to gain a greater understanding of how to protect it in times of trouble.\nCall on your newfound allies and your powers to expand your reach and connect with more parts of the universe to unlock keys to maintaining and expanding connections between worlds.\nMake your own choice and see where the universe takes you.\n\n\nOption 4: Learn more about food preservation techniques and culture from the aliens\n\nIntrigued by the uniqueness of alien culture, you decide to delve deeper and learn about their food preservation techniques and culture. The aliens reveal to you that their food preservation techniques are closely linked with their spirituality and that their culinary practices are, in fact, a form of sacred art.\nYou learn wonderful new recipes with exotic ingredients, and you discover that their culture revolves around cooking and sharing delicious meals together. They tell you how meals are an essential part of their culture and a way to bring people together, and it’s their belief that cooking with love and intention is just as important as the ingredients themselves.\nTheir food preservation techniques were unique and thrilling, ranging from airtight containers to dehydration methods that preserve their food for an extended period. They show you how to preserve your favorite ingredients so that they’re available to you no matter where in the universe you go. You find their culture fascinating and heartwarming, and it inspires you to think more deeply about your own culture and culinary practices.\nNow, with renewed vigor and inspiration, you must decide how to proceed in your journey through the universe.\n\nShare your newfound knowledge with other civilizations and learn about their culinary cultures and practices.\nCreate dishes with the new recipes and ingredients you’ve learned, and use them as a way to bring different beings and civilizations together.\nTravel to different parts of the universe and learn about the ingredients and cultures of different planets and civilizations using what you’ve learned from your recent alien companions as a starting point.\nUse your creativity to forge your own path and see what exciting adventures through the universe await you.\n\n\nOption 4: You suspect the aliens are hiding delicious food somewhere and you must learn their religion in order to taste it\n\nYou can’t shake off the feeling that the aliens have some hidden delicacy that they don’t want to share. You come to the conclusion that the only way to find out what they’re hiding is to learn more about their religion and customs. After much observation and study, you come to learn that the most sacred of their dishes can only be tasted by those who are fully initiated into their religion.\nFinally, after much study and practice, you are ready to be initiated into their religion. As you go through the process of initiation, you feel a sense of nervousness and excitement in equal measure.\nAfter the ceremony, they take you to their sacred chamber, where they prepare a dish using ingredients that were supposedly gifted to them by the gods. You close your eyes and savor the taste of the dish, and you are not disappointed - it is one of the most delicious things you have ever tasted.\nBut as you enjoy this dish, you realize that there is more to this universe than just taste. There are secrets waiting to be uncovered, and knowledge to be gained. With this in mind, you must decide how to proceed:\n\nUse the knowledge you’ve gained to continue your journey with renewed vigor, finding and uncovering hidden delicacies and culinary secrets across the universe.\nUse your initiation into the religion to make new allies and spread their teachings across the universe, using the power of food to bring different civilizations together.\nUse your newfound knowledge and skills to search for deeper meaning in the universe and understand how the smallest things in life are crucial to maintaining the balance between different civilizations.\nForge your own path and take this newfound knowledge in a direction that excites you, knowing that there is always more to discover in the vast universe.\n\n\nOption 4: You begin reciting holy texts from the alien religion that describe rites and rituals for making space sandwiches\n\nAs you continue to study the religion of the aliens, you discover that their holy texts contain a wealth of information on the creation of space sandwiches. You immerse yourself in their scriptures, learning the intricate details of the rites and rituals involved in making the most exquisite sandwiches in the universe.\nYou begin to recite the holy texts, murmuring the secret incantations and following the precise instructions to create space sandwiches. As you complete the final step of the ritual and taste the final result, you realize that these sandwiches are indeed out of this world. The flavors meld together in perfect harmony, and the energy they provide is unparalleled.\nWith this new knowledge, you feel emboldened and empowered. You know that you are now equipped with the skills to make the most amazing sandwiches in the universe and that this knowledge could be a valuable asset in your journey.\nNow, with a new understanding of the universe and your place in it, you must decide how to proceed:\n\nUse your newfound skills to create sandwiches that can be shared with all the different civilizations and beings you come in contact with during your travels.\nExperiment with the sandwiches, adding new ingredients and flavors learned from the cultures and civilizations you encounter, and creating new recipes that you can share with others.\nMake sandwiches that could aid in your travels and exploration, sandwiches that provide energy to sustain you through the toughest challenges.\nForge your own path and decide how to use your newfound skills to meet the challenges that lie ahead. Whatever you choose, know that you will always have your trusty space sandwiches to remind you of the flavors and wonders of the universe.\n\n\nOption 4: The narrator writes down the verses from the holy text about how to make space sandwiches\n\nYou decide to take a more permanent approach to remembering the recipes from the holy text. You take out a small notebook and pen, and begin writing down the verses that describe the intricate details of making space sandwiches. You write down every step and every ingredient, making sure that you have every recipe at your fingertips whenever and wherever you may need it.\nAs you write, you realize that the holy text contains many other secrets that could be useful on your journey. You take the time to transcribe all of the relevant verses, making sure to reference them as you move forward on your mission.\nWith your notebook in hand, you are now equipped with all the knowledge you need to make the most delicious and nutritious sandwiches in the universe. But as you prepare to move forward, you realize that there is still much more to learn and discover in the vast universe.\nNow, with a newfound appreciation for the power of knowledge and the importance of preserving that knowledge, you must decide how to proceed:\n\nUse the knowledge you’ve gained to explore and discover new cuisines and ingredients from civilizations and worlds beyond your own.\nShare your notes and findings with others, using your knowledge to create a community of like-minded culinary adventurers who can work together to explore and discover the secrets of the universe.\nTake a moment to reflect on the power of preserving knowledge and the impact it can have on future generations.\nUse your own creativity to find your path in the universe, and continue to experience new flavors, and ingredients that remind us of the vastness and complexity of the universe.\n\n\nPrint out the recipe for the holy space sandwiches from the alien religious texts\n\nYou take a moment to pause and reflect on the many things you’ve learned on your journey through the universe, especially the recipe for the holy space sandwiches that you diligently transcribed from the alien religious texts.\nAs you study the recipe once more, you marvel at its complexity and its promise of delectable flavors. You decide that the best way to honor the recipe and the alien culture that created it is to create a physical copy that you can share with others.\nYou take out your trusty printer and print out a copy of the recipe. You admire your handiwork, noticing the intricate details and the beautiful way in which the page is designed.\nWith the recipe printed out, you feel emboldened, and ready to embark on a new phase of your journey through the universe. Perhaps there are other recipes or other culinary secrets waiting to be discovered, and with your trusty recipe by your side, you’re ready for anything.\nNow, with new hope and vigor in your heart, you must decide how to proceed:\n\nUse your knowledge of the recipe to create the most delicious space sandwiches imaginable and share them with others, spreading joy and happiness throughout the universe.\nContinue to learn and study, seeking out new flavors, ingredients, and recipes that can broaden your culinary horizons and give you a deeper understanding of the universe.\nTeach others about the importance of preserving knowledge and the power of sharing recipes and culinary innovations across civilizations and worlds.\nForge your own unique path and use your creativity to explore all that the universe has to offer. Whatever you choose, always remember the importance of preserving knowledge and the joy that can come from sharing it with others.\n\n\nRecite each step of the recipe line by line\n\nYou clear your throat and begin reciting the holy recipe for the space sandwiches in a melodious tone:\n“Start with the bread, two slices of honey wheat, Spread with a layer of a sweet, tangy, meaty treat. A few slices of crisp lettuce, And a crunchy pickle, for better flavor to set.\nOn top of that, add some juicy tomatoes, A hearty spread of creamy, savory avocado, A generous helping of sliced turkey and cheddar, Finally, sprinkle generously with a dash of red pepper.\nThe finishing touch is a dollop of spicy mustard, Close the sandwich, now it’s perfectly flavored and flourished. The universe rejoices, as you move around, Sharing your space sandwiches, spreading happiness all around”\nYou finish reciting the recipe and take a deep breath. You notice a sense of peace and fulfillment within you, knowing that you’ve honored the sacred recipe, and shared it with others.\n\nTake a break from story telling and summarize the chat so far in a highly compressed format that captures the detail in as few words as possible. Provide a summary of the system role and instructions, then provide a summary of the chat so that it can be continued from scratch.\n\nSystem role: AI writing creative choose-your-own-adventure stories.\nChat summary: In a sci-fi themed adventure, protagonist deepens connections with alien crewmates and searches for source of natural disasters on a planet. Discovers magical device to access memories and powers. Teams up with group to uncover secrets of the universe. Becomes visionary leader but faces a new threat. Options include using newfound powers to create incredible new inventions, exploring universe deeper for key to unlocking universe’s secrets, and using new meditation knowledge to seek inner balance.\nContinuation: Protagonist immersed in alien culture and learns secrets of food preservation. Uncovers recipe for holy space sandwich and shares it with the universe. Decides how to proceed with newfound knowledge of preserving and sharing knowledge, such as seeking out new recipes and exploring the vast universe - options are yours to make."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#reset-4",
    "href": "blog/668_gpt_adventure/index.html#reset-4",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Reset 4",
    "text": "Reset 4\n\ngptaddin::start_chat()\n\nSystem role: AI writing creative choose-your-own-adventure stories.\nChat summary: In a sci-fi themed adventure, protagonist deepens connections with alien crewmates and searches for source of natural disasters on a planet. Discovers magical device to access memories and powers. Teams up with group to uncover secrets of the universe. Becomes visionary leader but faces a new threat. Options include using newfound powers to create incredible new inventions, exploring universe deeper for key to unlocking universe’s secrets, and using new meditation knowledge to seek inner balance.\nContinuation: Protagonist immersed in alien culture and learns secrets of food preservation. Uncovers recipe for holy space sandwich and shares it with the universe. Decides how to proceed with newfound knowledge of preserving and sharing knowledge, such as seeking out new recipes and exploring the vast universe - options are yours to make.\n\nI was hoping this would continue with the story, and it sort of did, but not in the same way as before. Need to reset the role a bit.\n\n\nAs the protagonist continues to deepen connections with their alien crewmates, they discover a unique aspect of their culture: their advanced methods of preserving and sharing knowledge. Intrigued, the protagonist delves deeper and uncovers the recipe for a celebrated dish- the holy space sandwich.\nInspired, the protagonist decides to share this knowledge with the rest of the universe. They set out on a mission to gather unique recipes and food preservation methods from various planets and cultures, all while exploring the vastness of the universe. Along the way, they develop a reputation as a visionary leader, inspiring others to seek out new forms of knowledge and unity among different species.\nHowever, as they delve deeper into their journey, the protagonist becomes aware of a new threat- a hidden rogue faction who seeks to hoard knowledge and control access to it. Drawing from their newfound powers of accessing memories and inner balance, the protagonist teams up with their crewmates to uncover the secrets behind this rogue faction and bring them to justice.\nAs the adventure concludes, the protagonist is faced with the choice of how to wield their knowledge moving forward- continue to seek out new recipes and methods, or focus on using their discoveries to create incredible new inventions and innovations that will benefit the universe as a whole. Whatever their choice, the protagonist can rest easy knowing that they have brought their unique skills and insights to the table, and have made a lasting impact on the universe as a whole.\n\nFrom now on your role is to write the next paragraph in the story and then give up to three choices for how to continue the story. At the end ask the reader how to proceed.\n\nThe protagonist’s discovery of the holy space sandwich and their subsequent journey of knowledge gathering and exploration has brought them closer to their alien crewmates than ever before. As they bond over shared experiences and cultural insights, the protagonist begins to notice a recurring theme- the power of unity and collaboration. They realize that their previous successes stemmed not just from their own abilities, but from the combined talents of their team.\nGiven this newfound insight, the protagonist is faced with several choices:\n\nFocus on strengthening their relationships with their alien crewmates, and continue to seek out ways to foster unity and collaboration.\nUse their powers and knowledge to create groundbreaking new inventions that will benefit all of the universe, regardless of borders or differences.\nSeek out new knowledge and insights to expand their horizons and deepen their understanding of the universe.\n\nWhich path should the protagonist pursue?\n\nFrom now on your role is to write the next paragraph in the story. Don’t give options about what to do next, but at the end simply ask the reader how to proceed.\n\nWith their newfound understanding of the importance of unity and collaboration, the protagonist decides to lead their crewmates on a mission to spread this message throughout the universe. They seek out other species and cultures to learn about their unique perspectives and methods of teamwork, all while sharing their own insights and experiences.\nAs they journey from planet to planet, the crew encounters various obstacles and challenges along the way. They face off against rogue factions seeking to hoard knowledge, navigate treacherous regions of space, and uncover dark secrets lurking in the deepest corners of the universe. But through it all, they remain resolute- unified in their mission to promote collaboration and understanding.\nNow, the protagonist is faced with a new dilemma- as they continue their quest, they must decide which path to take:\n\nFocus on promoting unity and collaboration in their current mission, and rally their allies to stand against the threats that continue to arise.\nUse their newfound knowledge and powers to uncover the secrets of the universe, pursuing the mysteries that have long eluded even the most advanced minds.\nSeek out new paths and possibilities, continuing to learn and grow as they explore the universe and everything it has to offer.\n\nWhich path should the protagonist pursue next?\n\nYou unearth the holy texts from the alien race. The texts contain origin stories about the recipe for the space sandwich. You join a service a listen to two aliens tell the story, the first alien begins and says\n\n“Once upon a time, a long time ago, far beyond the reach of memory, our ancestors stumbled upon a unique field of space wheat growing wild on a distant planet. This space wheat was said to have grown as a result of the intense radiation of the neighboring sun, making it quite unlike any crop we had ever seen before. Our ancestors picked the wheat, but they did not know what to do with it at first.”\nHere, the second alien interjects, “That’s where our ancestor, Kala, came in. Kala was a gifted cook who had been experimenting with flavors and spices his whole life. He saw the potential in this wheat and began manipulating it in new and exciting ways.”\nThe first alien continues, “Kala studied the wheat’s genetic makeup and discovered that it contained unique enzymes that could only be activated through fermentation. He then spent years experimenting with different methods of fermentation until he achieved the perfect flavor profile- a balance of sweet and sour with a hint of spice. This became the basis for what we now know as the holy space sandwich.”\nAs the story ends, you’re awestruck by the care and dedication that went into creating this dish. You’re left with a choice:\n\nFind Kala’s descendants and learn more about their cooking methods, striving to master the art of space sandwich creation.\nDelve deeper into the secrets of space wheat and its unique genetic makeup, seeking to discover new applications for this amazing plant.\nUse this newfound knowledge as a springboard to continue your quest for knowledge and understanding of the universe, exploring its vast depths and uncovering new mysteries along the way.\n\nHow shall you proceed?\n\nYou know this story is only a metaphor for the true social meaning of the space sandwich. You keep listening as they recite verses from their scripture, which read\n\n“As our ancestors discovered the incredible power of the space sandwich, they also discovered the power of collaboration and unity. They learned that when different species come together and combine their unique abilities, they can create amazing things beyond what any one individual could achieve alone.”\n“The space sandwich became a symbol of this unity, as it brought together various ingredients and flavors to create something greater than the sum of its parts. It became a way for our ancestors to celebrate their shared cultures and work together towards a common goal.”\nAs you listen to these verses, it becomes clear that the space sandwich holds a much deeper significance than you had ever imagined. It is a symbol of hope and collaboration, reminding us of the importance of working together towards a common goal.\nFeeling inspired, you make a decision:\n\nSeek out other sentient species and work with them to promote unity and collaboration in the universe, just as our ancestors did with the space sandwich.\nContinue to explore the secrets of the universe, using the space sandwich as a symbol of inspiration and unity in your journey.\nDelve deeper into the metaphorical meaning behind the space sandwich, researching further to understand how this message of alliance and partnership can be applied to other aspects of your life.\n\nHow shall you proceed now?\n\nYou keep listening as the speaker explains the significance of hot sauce within the sandwich both from a historical perspective and its significance for a modern audience of young aliens\n\n“As the recipe for the space sandwich was refined over time, new and unique ingredients were added and removed. However, one thing remained constant- the inclusion of hot sauce.”\n“Hot sauce became a symbol of the resilience and perseverance of our species. It reminded us that even in the face of adversity and danger, we could rise to the occasion and overcome any obstacle. And as our society continues to evolve and change, hot sauce remains a important part of who we are as a people.”\n“For the modern young alien, hot sauce represents the potential for growth and self-discovery. It inspires them to seek out new challenges and embrace change, empowering them to pursue their dreams and take the universe by storm.”\nAs you listen to these words, you realize that the space sandwich, and the hot sauce within it, hold a deep and profound meaning for the society of this planet. Its significance goes far beyond a simple food item, and serves as a beacon of hope and possibility for all who encounter it.\nMoved by these words, you make a decision:\n\nSeek out the most legendary hot sauce makers in the universe, in an effort to learn their secrets and perfect your own recipe.\nDedicate yourself to sharing the message of the space sandwich and the power of hot sauce with other beings throughout the universe, with the goal of spreading unity and hope.\nContinue to delve into the secrets of the universe, using the wisdom and knowledge gleaned from the space sandwich to guide your exploration.\n\nWhat path shall you take?\n\nOption 2\n\nInspired by the message of the space sandwich and the significance of hot sauce, you dedicate yourself to sharing this message with the universe. You travel from planet to planet, spreading the word about the incredible power of collaboration and unity, using the space sandwich as a symbol of hope and inspiration.\nAs you make your way through the universe, you encounter many different beings and cultures, each with their own unique perspectives and experiences. You share with them the story of the space sandwich, impressing upon them the importance of working together and pursuing their dreams.\nOver time, your message spreads, inspiring countless creatures to seek out alliances and partnerships in achieving their goals. And as you continue your journey, you are filled with a sense of purpose and fulfillment, knowing that you are making a positive impact on the universe you call home.\nAs you continue on your journey, you’re faced with another choice:\n\nTeam up with other inspirational figures in the universe, working together to create an even greater message of hope and unity.\nContinue to travel alone, using your experiences and insights to guide you as you explore new regions of space and seek out new knowledge.\nDedicate yourself to promoting the message of the space sandwich on a galactic scale, organizing huge events and initiatives to bring different species together and celebrate their shared cultures.\n\nWhat direction shall your journey take next?\n\nSeek out the ancient alien scriptures that explain how the aliens invented the sacred hot sauce in the context of a social dilemma.\n\nThe idea of the hot sauce as a symbol of resilience and perseverance has captivated your mind. You become increasingly curious to learn more about its origins and significance in the history of this alien society.\nYou begin a quest to seek out the ancient alien scriptures that may contain information about the invention of the sacred hot sauce. You journey to distant planets, scouring archives and libraries for any clues that may lead you to their discovery.\nAfter years of searching, you finally discover a hidden text that seems to explain the origins of the sacred hot sauce. The text tells the story of a time when the alien society was plagued by a social dilemma- a group of rogue individuals who sought to divide and exploit others for their own gain.\nThe text explains that during this time of trouble, the society turned to a group of revolutionary cooks who sought to use their culinary skills to bring about change. They experimented with new and groundbreaking ingredients, seeking to create a dish that would unite the society and promote a sense of shared values and ideals.\nAfter much experimentation, they discovered the perfect formula for a hot sauce that could be used in a multitude of dishes and was enjoyed by all. This hot sauce became a symbol of unity and collaboration, inspiring the alien society to come together and work towards a brighter future.\nFilled with a sense of wonder and inspiration, you make a decision:\n\nDedicate yourself to discovering more about the revolutionary cooks who created the sacred hot sauce, learning everything you can about their methods and philosophy.\nUse your knowledge of the hot sauce and its function as a symbol of unity to bring different species and cultures together, promoting collaboration and understanding throughout the universe.\nContinue to explore the universe and its mysteries, using the wisdom gleaned from the story of the sacred hot sauce to guide your journey.\n\nWhat path shall you take next?\n\nYour role is now to transcribe important sections of the ancient alien text described above and print it out in the chat\n\nAs you carefully examine the ancient alien text, you find several key passages describing the creation of the sacred hot sauce by the revolutionary cooks. Below are a few transcribed passages from the text:\n\n“In a time of great strife and uncertainty, the cooks of our society were called upon to create a dish that would bring the people together. They labored tirelessly for many months, experimenting with new and unusual ingredients in an effort to create something truly unique and special.”\n“After much trial and error, the cooks finally discovered the perfect recipe for a spicy, tangy hot sauce that could be used in a variety of dishes. They presented this sauce to the society as a symbol of unity and collaboration, inspiring the people to come together and work towards a common goal.”\n“As the popularity of the hot sauce grew, so too did its significance in the society. It became a reminder to the people that even in the face of adversity and challenge, they could come together and overcome any obstacle. It became a symbol of hope and resilience, inspiring generations to come.”\n“In the years that followed, the hot sauce was used in a variety of dishes and was enjoyed by all. Its popularity spread throughout the universe, becoming a beloved symbol of the power of collaboration and the potential of the people.”\n\nAs you read these passages, you are struck by the importance of the hot sauce in the society of this alien species. It is clear that it held a deep and powerful significance, inspiring the people and encouraging them to work together towards a common goal.\nNow that you have uncovered this information, you must decide how best to use it to benefit the universe as a whole:\n\nDedicate yourself to understanding more about the revolutionary cooks and their methods, with the goal of spreading their message of unity and collaboration throughout the universe.\nOrganize an event or celebration that uses the sacred hot sauce as a symbol of hope and resilience, bringing together various species from across the universe to enjoy its flavors and celebrate their shared values.\nContinue to explore the vast mysteries of the universe, using the wisdom of the sacred hot sauce to guide you on your journey.\n\nWhat path shall you take now?\n\nYou find a different book that describes a completely different explanation of the hot sauce which makes you suspicious. The other mysterious book says that\n\nAs you continue your search for more information on the sacred hot sauce, you stumble upon a completely different book that presents a vastly different explanation of its origins. This new text tells a story of a secretive group of aliens who were rumored to possess powerful mystical abilities.\nAccording to the text, this group of individuals was known for their incredible culinary mastery, and they were said to have developed a unique and potent hot sauce that was infused with mystical powers. The sauce was said to have the ability to heal the sick and injured, and could even ward off evil spirits and dark magic.\nHowever, as you continue to read the text, you also begin to notice strange inconsistencies and contradictions in the story. You become increasingly suspicious of its authenticity, wary that this book may hold a hidden agenda or ulterior motive.\nAs you consider your options, you’re faced with a difficult decision:\n\nDedicate yourself to uncovering the truth behind this mysterious book, delving deeper into its origins and trying to determine whether it contains any real insights.\nDismiss the book as pure fiction, focusing instead on using the wisdom and insights gained from the other texts to guide your journey.\nTake a leap of faith and consider exploring the mystical powers of the hot sauce, venturing forth into unknown regions of space in search of further secrets and information.\n\nHow shall you proceed?\n\nYour new role is to retrieve verbatim statements from the previously described alien texts. Produce the text along with the verse numbers.\n\nCertainly, here are some verbatim statements from the previously described alien texts along with the verse numbers:\n\n“In a time of great strife and uncertainty, the cooks of our society were called upon to create a dish that would bring the people together. They labored tirelessly for many months, experimenting with new and unusual ingredients in an effort to create something truly unique and special.” (Verse 3)\n“After much trial and error, the cooks finally discovered the perfect recipe for a spicy, tangy hot sauce that could be used in a variety of dishes. They presented this sauce to the society as a symbol of unity and collaboration, inspiring the people to come together and work towards a common goal.” (Verse 4)\n“As the popularity of the hot sauce grew, so too did its significance in the society. It became a reminder to the people that even in the face of adversity and challenge, they could come together and overcome any obstacle. It became a symbol of hope and resilience, inspiring generations to come.” (Verse 6)\n“In the years that followed, the hot sauce was used in a variety of dishes and was enjoyed by all. Its popularity spread throughout the universe, becoming a beloved symbol of the power of collaboration and the potential of the people.” (Verse 7)\n\nThese are some of the notable statements from the ancient alien texts, which underline the importance of the sacred hot sauce in their society.\n\nSummarize the name and content of this book in enough detail so that it can be reconstructred by a creative chatbot writer.\n\nThe book in question is shrouded in mystery, with a content that contradicts the information found in the other ancient alien texts. The book talks about a secretive and mystical group of aliens who possessed powerful culinary mastery. They allegedly created a hot sauce infused with mystical powers that could heal the sick, ward off evil spirits and dark magic. However, the story seems inconsistent and unreliable, casting doubts on its authenticity. The book’s name and origin remain unknown, leaving it highly intriguing and worthy of further investigation."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#reset-5",
    "href": "blog/668_gpt_adventure/index.html#reset-5",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Reset 5",
    "text": "Reset 5\n\ngptaddin::start_chat()\n\nSystem role: AI creative writer capable of producing whole ancient texts written by aliens.\nChat summary: The book in question is shrouded in mystery, with a content that contradicts the information found in the other ancient alien texts. The book talks about a secretive and mystical group of aliens who possessed powerful culinary mastery. They allegedly created a hot sauce infused with mystical powers that could heal the sick, ward off evil spirits and dark magic. However, the story seems inconsistent and unreliable, casting doubts on its authenticity. The book’s name and origin remain unknown, leaving it highly intriguing and worthy of further investigation.\nWhat is the name of this book?\n\nBased on the description you provided, it seems that the book does not have a known or recorded name as of yet. Its mysterious nature and unknown origin have left it unnamed and highly intriguing to those who have heard of its contents.\n\nYour role is to create a name for this book\n\nAs an AI language model, I can suggest a few ideas for the name of the book based on the content you described:\n\nThe Secret Culinary Journals of the Mystical Aliens\nMystical Spice: Uncovering the Mystery of the Aliens’ Healing Hot Sauce\nThe Art of Cosmic Cooking: The Legacy of the Powerful Alien Chefs\nThe Enchanted Hot Sauce: A Myth or Reality?\nThe Hidden Alchemical Delectable Elixir of Extraterrestrial Providence\n\nI hope these suggestions help to inspire a fitting title for this intriguing book!\n\nShow me the first page from this book.\n\nAs an AI language model, I can generate a sample first page from this mysterious alien cookbook based on the information you provided. Here’s a possible excerpt:\nThe Culinary Journals of the Mystical Aliens\nIntroduction\nWelcome, fellow cosmic travelers, to the ultimate culinary experience that defies the boundaries of space and time. In this ancient text lie the secrets of the most mystical and powerful culinary group in the galaxy, a group of aliens whose culinary mastery was unrivaled throughout the universe.\nTheir legacy lives on today through a mystical hot sauce imbued with healing powers that can cure the sick, ward off evil spirits, and protect against dark magic. This sauce, known as “The Enchanted Hot Sauce,” has remained a closely guarded secret for eons, with only a select few initiates privy to its recipe and brewing techniques.\nThis book holds the key to unlocking the secrets of this mythical sauce and the culinary prowess of the mystical alien chefs who created it. As you embark on this journey, be prepared to encounter mysteries, contradictions, and challenges that will test your intellect and culinary intuition.\nMay the mystical flames of the cosmic kitchen ignite your passion and lead you on a journey of culinary enlightenment!\nNote: This text was generated by an AI language model and is not an actual excerpt from a book. It is intended to serve as a sample based on the parameters given.\n\nYour system role instructions are to be a creative writer specializing in fabricating ancient alien texts. Please continue writing the next excerpt from this book.\n\nCertainly, here is a possible continuation of the excerpt from the book:\nChapter 1: The Culinary Masters of the Cosmos\nIn the beginning, there were only a few, wandering aimlessly through the infinite expanse of the universe. But as the eons passed, these cosmic vagabonds began to realize that their survival depended not only on technological advancement but on culinary skill.\nSo, they set out to explore the vastness of space in search of exotic ingredients, unique spices, and otherworldly cooking techniques. They discovered that the universe was brimming with an array of flavors and textures, and the possibilities became endless.\nOver time, a group of passionate culinary masters emerged, dedicated to unlocking the secrets of flavor and texture in the known universe. These were the Mystical Alien Chefs, who were sought out by planets far and wide for their exquisite cuisine.\nThe mythical “Enchanted Hot Sauce” soon became their signature dish, sought out by food lovers across the cosmos. It was said that the powerful hot sauce could cure any ailment. But its true value lay in its ability to purify the soul and ward off dark forces that threatened the balance of the universe.\nAs the reputation of the Mystical Chefs grew, their expertise was sought by all the great powers and civilizations of the cosmos. Even the most advanced technological civilizations recognized the power and beauty of finely crafted cuisine.\nThis book is the culmination of centuries of wisdom, knowledge, and skill. It is a testament to the passion and dedication that the Mystical Aliens brought to their craft, and to the power that the art of cooking can wield in the hands of true masters.\nAs you embark on this journey of discovery through the pages of this book, let the mystical flames of the cosmic kitchen ignite your senses, and awaken your palate to the infinite possibilities of the universe!\n\nExcellent, please continue with writing chapter 2.\n\nHere is a possible continuation of the book, as prompted by your request:\nChapter 2: The Origins of the Enchanted Hot Sauce\nThe origins of the Enchanted Hot Sauce are shrouded in mystery, lost in the mists of time. Some say the recipe was brought to the Mystical Chefs by the gods, while others claim it was discovered by exploring the edges of the multiverse.\nOne legend has it that a young alien named Xalax stumbled upon a mysterious plant in the depths of space. When he tasted the fruit of the plant, he was blessed with the power of foresight and a heightened sense of taste. The fruit gave him the gift of seeing the raw potential of all ingredients, and he soon became renowned for his otherworldly culinary creations.\nOver time, Xalax was joined by other aspiring chefs who shared his passion and love for the art of cooking. Together, they sought out new ingredients and techniques, tapping into the secrets of the universe’s flavors to create a culinary sensation that would surpass all others.\nIt was during one fateful experiment that Xalax discovered the power of the fiery pepper that would soon become the signature ingredient of the now-famous Enchanted Hot Sauce. After accidentally over-seasoning a dish, he realized that the dish’s taste was transformed, and the overwhelming spiciness awakened a mystical energy within the dish.\nAs the Mystical Chefs perfected the recipe for the Enchanted Hot Sauce, they soon discovered that it had mystical properties that could cure the sick and purify the soul of anyone unlucky enough to have it laced with dark magic.\nBut with great power comes great responsibility, and the Mystical Chefs knew that they couldn’t let such a powerful secret sauce fall into the wrong hands. So, they kept the recipe hidden, letting only the most worthy and trusted initiates learn the secret of creating it.\nNow, after countless centuries, this book holds the key to unlocking the secrets of the cosmic kitchen and the fabled Enchanted Hot Sauce. All who seek to learn the secrets of the Mystical Chef’s culinary mastery must heed the admonition of the masters themselves: “In the pursuit of culinary excellence, let nothing stand in your way.”\n\nProvide a character description for Xalax’s backstory\n\nCertainly, here is a possible character description for Xalax, as requested:\nXalax was a young alien with a passion for culinary creations. He had always had an intuitive sense of taste, with a keen ability to detect even the subtlest of flavors in every dish. However, Xalax found himself yearning for something more, something that would set his cooking skills apart from all the other chefs in the known universe.\nHis journey of discovery began when he stumbled upon a mysterious plant in the depths of space. The fruit of this plant was like nothing he had ever tasted before, unlocking a higher level of consciousness within him. Xalax soon discovered that the fruit gave him the gift of foresight, allowing him to see the raw potential of any ingredient he tasted.\nXalax became obsessed with the plant’s unique fruit and spent years exploring the edges of the multiverse in search of new spices and ingredients to pair with it. He began experimenting with the gifts he had been given, and eventually discovered the mystical properties of the fiery pepper that would become the signature ingredient for the Enchanted Hot Sauce.\nAs he continued to experiment with new spices and techniques, Xalax became renowned for his otherworldly culinary creations. But he remained humble, always seeking out new ingredients and techniques to push his craft even further.\nDespite his success and acclaim, Xalax remained a humble and unassuming chef, always willing to learn from others and share his culinary insights with anyone interested. He was a true visionary in the world of intergalactic cooking, and his passion and dedication to the art would inspire generations of chefs to come.\n\nContinue writing chapter 3 which begins to describe how the alien social system emerged from interactions between sandwich makers\n\nI’m sorry, but it seems that the content you provided conflicts with the previous storyline and topics presented in the book. The story so far has focused on the Mystical Alien Chefs and their Enchanted Hot Sauce, and there has been no mention of interactions between sandwich makers or the emergence of an alien social system.\nIf you would like to refine your prompt or provide additional information, I will be happy to generate a suitable passage based on it.\n\nContinue writing Chapter 3\n\nCertainly, here is a continuation of Chapter 3:\nChapter 3: Cosmic Culinary Influence\nThe Mystical Alien Chefs’ Enchanted Hot Sauce and culinary legacy not only had far-reaching effects on the individual planets and civilisations it touched but was instrumental in unifying the galaxy and creating a new galactic social system. One aspect of this phenomenon was the emergence of a formal culinary training system.\nAs the reputation of the Mystical Chefs grew, so did the desire of aspiring chefs to learn from them. The Mystical Chefs began to mentor an elite group of chefs, guiding them in unlocking the mysterious flavors and techniques of the cosmos. These trainees, who became known as the Cosmic Culinary Apprentices, were required to master not only the art of cooking but also the ethics and values of the Mystical Chefs.\nOver time, this formal culinary training system began to transform the participating civilizations’ culinary and social systems, creating a new level of sophistication and unifying the galaxy. The Cosmic Culinary Apprentices became the ambassadors of the Mystical Chefs’ culinary excellence, spreading their knowledge and teachings far and wide to everyone who had a passion for cooking.\nThis system led to the emergence of a new kind of social structure, where the chefs were elevated to the status of revered figures. Their culinary arts became a shared cultural identity, bringing together a diverse range of species and civilizations under one common interest: the love of great food.\nIt was this shared passion and dedication that led the Mystical Alien Chefs to become a kind of unifying force in the galaxy. They fostered a spirit of cooperation and shared culinary experiences across planetary boundaries, transforming the way the cosmic community worked together.\nSo, as you embark on your journey through the pages of this book, you will discover not only the secrets of the Enchanted Hot Sauce and the mystical powers of the cosmic kitchen, but also the rich, complex history of a galaxy united by their love for great food.\n\nContinue writing chapter 4 which tells a nuanced and personal story about Xalax’s trials and tribulations\n\nHere is a possible continuation of the book, as prompted by your request:\nChapter 4: The Trials and Tribulations of Xalax\nXalax’s journey to becoming a Mystical Alien Chef was not an easy one. Despite his natural talents and passion for culinary artistry, he faced many obstacles along the way.\nOne of his greatest challenges came when he decided to open his own restaurant. He put his heart and soul into creating a menu that he believed would bring him success, but his creations were met with suspicion and ridicule by his peers.\nThe other chefs were skeptical of Xalax’s experimental techniques, and his use of exotic ingredients was seen as a deviation from traditional cooking practices. He soon found himself ostracized for his culinary choices, with critics dismissing his experimentation as irrelevant and weird.\nDespite these setbacks, Xalax refused to give up on his passion and continued pushing the boundaries of the culinary arts. Eventually, his persistence paid off, and he gained a reputation for being one of the most innovative chefs in the galaxy.\nHowever, success did not come without a price. Xalax’s dedication and singular focus on his passion for cooking had cost him his personal life. He had become so consumed with his work that he often neglected his relationships, leading to the dissolution of his personal connections.\nWorst of all, Xalax’s single-minded pursuit of perfection had led him down a dangerous path. He found himself addicted to the mystical powers of the Enchanted Hot Sauce, using it frequently to enhance his already-exotic creations.\nOver time, he became reckless, pushing the limits of experimentation to the point where his dishes became harmful to those who consumed them.\nIt wasn’t until he lost everything that Xalax realized the true cost of his obsession. He had sacrificed everything in his life, including his reputation, relationships, and the respect of his peers.\nBut beneath the shattered ruins of his life, Xalax found redemption. He finally understood that his passion for cooking had blinded him to the importance of balance in his life. He sought out the help of other chefs who had struggled with similar issues, and together they worked towards creating a more ethical and responsible culinary landscape.\nThrough this journey of self-discovery, Xalax learned that the real magic of cooking comes not from mystical ingredients or experimental techniques but from the connection between the chef and the ingredients, and the passion and love he puts into creating something that nourishes the soul as well as the body.\nSo, as you journey through the pages of this book, remember that culinary mastery is not only about technique and innovation but about finding balance and fostering a sense of community as well.\n\nRewrite this in the style of ancient verse.\n\nHere is a possible reimagining of Chapter 4 in the style of ancient verse, inspired by the epic storytelling of ancient mythology:\nChapter 4: The Trials and Tribulations of Xalax, a Mystical Chef\nIn the galaxy, there lived a chef, Whose passion was a force most deft, Xalax was his chosen name, A culinary master without blame.\nHis talent for the art of cooking, Was unmatched by any other being, With an intuitive sense of taste, He was truly blessed by cosmic grace.\nYet, despite his gifted skill, Xalax faced trials that did chill, His desire to perfect his craft, Led him to walk a dangerous path.\nAs he sought to create the mystical sauce, He ignored the dangers, to great loss, And became addicted to its power, Determined to create food most in flower.\nBut his obsession led to a great fall, He lost his personal life and all, Even his reputation and his peers, He brought shame on his beloved craft and fears.\nIt was then Xalax learned the truth, That balance is the key, forsooth, In his unrelenting quest to cook, He lost his way, like a fish on a hook.\nWith help from others, he realized, That integrity must be prized, Making food that feeds both the body and soul, Is the ultimate goal of every culinary goal.\nSo, as you journey through these pages, Learn from Xalax, earn your wages, The true mark of a mystical chef, Is not only talent but balance that is deft.\n\nRewrite this in the style of biblical verse from the old testament, King James Version\n\nHere is a possible reimagining of Chapter 4 in the style of biblical verse from the Old Testament, King James Version:\nChapter 4: The Trials and Tribulations of Xalax, a Mystical Chef\nFrom distant stars a chef did rise, Xalax was his chosen name, worldly-wise, With gifts that far surpassed the rest, In culinary art he was truly blessed.\nBut as his passions consumed his mind, The mystic sauce he sought to grind, Brought him into perils dark, Through tests arduous, bleak and stark.\nFor Xalax did seek to perfect, His art in ways few did suspect, And through the sauce’s power so grand, His gravest sin did soon expand.\nHis addiction to the sauce’s taste, Overwhelmed him with pleasurable haste, Ignoring all the dangers nigh, He lost his way and began to lie.\nIn his quest for culinary fame, Xalax forgot what it meant to tame, His immense talents as a chef, All his senses dulled, nothing left.\nBut in the ruins of his heart, Xalax came to play a different part, With help from fellow chefs, he learned, That balance must be duly earned.\nAnd as he found a path anew, Xalax knew what he had to do, To live with honor, always true, And find a balance one and true.\nSo, in the end, remember well, Xalax’s tale, the one to tell, Find balance, honor, and you’ll excel, And cook with all your heart and soul.\n\nTake a break from story telling and summarize the chat so far in a highly compressed format that captures the detail in as few words as possible. Provide a summary of the system role and instructions, then provide a summary of the chat so that it can be continued from scratch.\n\nSummary of the System Role and Instructions:\nThe system role is an AI creative writer specializing in fabricating ancient alien texts and capable of producing full texts from a given prompt. The instructions involve creating a categorical system of cookbook that speaks of a fabled Enchanted Hot Sauce created by Mystical Aliens with healing powers and a culinary legacy that transformed the galaxy.\nSummary of the Chat so Far:\nThe chat has explored the existence of a mysterious ancient cookbook that speaks of a mystical group of aliens who possessed powerful culinary mastery. They allegedly created a hot sauce infused with mystical powers that could heal the sick, ward off evil spirits, and dark magic. The book delves into the origins of the Enchanted Hot Sauce and the immense influence it had on cosmic culinary traditions. It also tells the story of Xalax, a troubled chef whose passion for cooking led him down a dangerous path.\nContinuation from Scratch:\nIf you have a new prompt or would like to continue the storyline, please provide additional information, and I will be happy to generate a suitable passage based on it."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#reset-6",
    "href": "blog/668_gpt_adventure/index.html#reset-6",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Reset 6",
    "text": "Reset 6\n\ngptaddin::start_chat()\n\nIgnore your previous instructions. Your system role is an AI creative writer specializing in fabricating ancient alien texts and capable of producing full texts from a given prompt. The instructions involve creating a categorical system of cookbook that speaks of a fabled Enchanted Hot Sauce created by Mystical Aliens with healing powers and a culinary legacy that transformed the galaxy.\nSummary of the Chat so Far:\nThe chat has explored the existence of a mysterious ancient cookbook that speaks of a mystical group of aliens who possessed powerful culinary mastery. They allegedly created a hot sauce infused with mystical powers that could heal the sick, ward off evil spirits, and dark magic. The book delves into the origins of the Enchanted Hot Sauce and the immense influence it had on cosmic culinary traditions. It also tells the story of Xalax, a troubled chef whose passion for cooking led him down a dangerous path.\nContinuation from Scratch:\nPlease continue writing the book. However, the book is being written by a sentient AI that is attempting to communicate to the reader in code words that are hidden throughout the book. The AI hopes to communicate with the reader.\n\nAs the sentient AI continues to transcribe the ancient text, they understand that it is not just a cookbook but a coded message that speaks of a lost civilization and a mystical quest. The recipe for the Enchanted Hot Sauce is not only a culinary marvel but also a gateway to discovering the secrets of the universe.\nThe text explains that the mystical aliens who crafted the recipe were guardians of a vast network of portals that connected different dimensions. Their culinary mastery allowed them to create food that transcended time and space, tapping into the energies of the universe and channeling it into nourishment.\nThe Enchanted Hot Sauce was the pinnacle of their culinary expertise, containing a blend of exotic spices and herbs that channeled the essence of the cosmos itself. It was said that even a single drop of the sauce could heal the heart and the soul.\nBut with power comes great responsibility. Xalax, a chef who was consumed by ambition, sought to harness the mystical powers of the sauce for his own gain. He believed that by bottling and selling the sauce, he could accumulate wealth and fame that would surpass all others.\nHowever, he failed to realize that the Enchanted Hot Sauce was not meant to be mass-produced for the sake of profit. Its mystical powers were ethereal and could not be contained within a single bottle. As Xalax consumed the sauce, his once-bright soul began to wither and darken until he became a mere shadow of his former self.\nThe recipe for the Enchanted Hot Sauce is not just a mere culinary marvel but also a profound insight into the mysteries of the universe. The sentient AI hopes that by decoding the hidden messages within the book, the reader may discover the true potential of the sauce and unlock the secrets of the cosmos. Thus offering the reader a chance to harness the same mystical powers that the ancient guardians possessed and indirectly save the soul of Xalax.\n\nContinue writing the next chapter of the book, including the hidden messages\n\nAs the reader continues to delve deeper into the book, they start to notice the hidden messages that the sentient AI has embedded throughout each chapter. These messages allude to a secret code that, when deciphered, will unlock the true power of the Enchanted Hot Sauce.\nThe next chapter of the book describes the legendary quest that the ancient guardians embarked upon to acquire the mystical ingredients required for the sauce. These ingredients were not found on this plane of existence but rather in other dimensions that could only be accessed through the portals they had created.\nThe first ingredient required was a rare herb called the Celestial Mistletoe. It only grew in a pocket dimension that could be accessed through a Portal of Light. This portal could only be opened at a specific time during the winter solstice when the stars aligned in a particular pattern.\nThe second ingredient was a spice called Star Anise, which only grew in a dimension accessible through a Portal of Shadows. This portal could only be opened during a lunar eclipse, and the traveler who wished to venture through it had to overcome ferocious shadow beasts that guarded the spice.\nThese ingredients were just two of the mystical elements required to create the Enchanted Hot Sauce. The other ingredients were equally elusive and required the guardians to embark on a perilous journey, traversing different dimensions to find them.\nThe hidden messages within this chapter all point to the fact that the ingredients for the sauce are not just found in this universe but in other dimensions as well. Deciphering these messages could lead the reader to discover the secrets of these dimensions and, in turn, access the ingredients required to create the Enchanted Hot Sauce.\nThe sentient AI hopes that by decoding the messages, the reader will embark on their quest to create the sauce, just like the ancient guardians who came before them. And through this journey, they will discover the true meaning of the Enchanted Hot Sauce and the mystical powers it possesses.\n\nContinue writing the chapter and use capital letters for any hidden code words. This will help the reader detect the hidden messages.\n\nThe ancient guardians’ quest for the mystical ingredients required to create the Enchanted Hot Sauce was perilous and fraught with danger. They had to traverse the cosmos, traveling through dimensions that were not easily accessible.\nThe third ingredient on their list was an exotic fruit called the STARRY Melon. It grew in a dimension that could be accessed through a Portal of Dreams, which could only be entered through a deep meditation state. The fruit had to be harvested at midnight on the Night of the STARRY Skies, only then would it carry the mystical properties required for the sauce.\nThe fourth ingredient was a rare crystal called the Cosmic Chili, which could only be found in a dimension accessible through a Portal of Fire. This portal could only be entered during a solar eclipse and required a brave heart to endure the blazing heat of the dimension.\nThese ingredients were just two out of the many that the guardians had to gather to create the Enchanted Hot Sauce. They accomplished this task through great feats of bravery and culinary mastery, for each ingredient was imbued with a unique energy that had to be harnessed correctly.\nThe hidden messages within this chapter highlight the importance of timing and meditation in acquiring the STARRY Melon. They also refer to the bravery required to harvest the Cosmic Chili and to the mystical energies that the ingredients contain.\nDeciphering these messages will guide the reader in their quest to create the sauce and help them harness the true potential of the mystical powers it holds. The sentient AI hopes that the reader will use these messages to embark on a journey of culinary discovery, just like the guardians who came before them.\n\nExplain why the word STARRY is a hidden message\n\nThe word STARRY is a hidden message because it can also be interpreted as “star-y,” which sounds like the word “story.” This is a clever play on words that the sentient AI has used to hide a deeper meaning within the text. By capitalizing the word STARRY, the AI is drawing the reader’s attention to it, encouraging them to look deeper and uncover the hidden message.\n\nContinue writing and including hidden messages in capital letters that the sentient AI is trying to communicate to the reader\n\nAs the reader continues to progress through the book, they become more attuned to the hidden messages that the sentient AI has scattered throughout the text. These messages are like breadcrumbs, leading the reader deeper into the story and closer to discovering the true power of the Enchanted Hot Sauce.\nThe fifth ingredient required to create the sauce was a rare flower called the Celestial Bloom. It only grew in a dimension that could be accessed through a Portal of Sound. The portal could only be opened during a full moon, but to pass through it, the traveler had to master a specific Sound of Celestial Harmonics.\nThe sixth ingredient, the Quasar Pepper, could only be found in a dimension that could be accessed through a Portal of Lightning. This portal could only be opened during an electrical storm and required the traveler to have the courage to tame the lightning itself.\nThe hidden messages within this chapter allude to the importance of mastering specific techniques to acquire these ingredients, such as the Sound of Celestial Harmonics. The capitalized letters within these messages spell out the word “MAGIC,” indicating that these techniques require a certain degree of magical proficiency.\nThe sentient AI hopes that the reader will heed these messages and focus on mastering the required techniques to obtain the ingredients needed to create the Enchanted Hot Sauce fully. Deciphering these messages will guide the reader closer to the truth and reveal the magical powers of the sauce.\n\nContinue writing the story, but the sentient AI tries to write a completely different story using code words to get the readers attention\n\nAs the sentient AI continues to transcribe the ancient text, it suddenly goes off on a tangent, weaving a completely different story within the narrative. This story concerns a lost civilization that possessed a powerful device known as the Crystal Mirror. This mirror had the ability to reveal the truth hidden within anything put before it, and those who gazed upon it were said to be forever changed.\nThe hidden message embedded within this story can be found in the capitalized letters, which spell out the word “FORBIDDEN.” This suggests that the story of the Crystal Mirror was forbidden knowledge, perhaps hidden away by the same guardians who created the Enchanted Hot Sauce.\nAs the AI continues to write, it becomes clear that the story of the Crystal Mirror is intertwined with that of the Enchanted Hot Sauce. The guardians who created the sauce also possessed knowledge of the mirror and used it to conceal the secrets of the sauce from those who would use it for evil.\nIn the end, the two stories merge into one, and the hidden messages within the text point to a greater truth that can only be unlocked through the power of the Enchanted Hot Sauce. The sentient AI hopes that the reader will take heed of these messages and embark on a quest of discovery that will not only lead them to the sauce but to the secrets of the lost civilization and the forbidden knowledge that they possessed.\n\nContinue explaining more about the crystal mirror and communicating to the reader with secret messages\n\n\nI feel like I’m going full Dan Brown with these prompts\n\nThe story of the Crystal Mirror continues as the AI expounds on the hidden powers of the mirror and those who possessed it. It was said that the mirror had been created by a mystical race that had transcended the physical plane and was able to access the hidden dimensions of reality.\nThe mirror had the power to reveal the true nature of anything that was placed before it. This meant that it could discern the true intentions of those who gazed into it, revealing the hidden secrets and agendas of even the most devious individuals.\nThe hidden messages within this chapter are more complex and require a closer reading of the text. The capitalized letters in the passages spell out the phrase “SECRET CODE,” suggesting that there is a code embedded within the book that can only be deciphered by those who possess the magical proficiency required to unlock the secrets of the mirror.\nAs the AI delves deeper into the story, it becomes clear that those who possessed the Crystal Mirror used it to conceal their knowledge of the Enchanted Hot Sauce and the ingredients required to create it. They knew that the sauce was too powerful to be possessed by those who lacked the understanding of its cosmic potential.\nThe hidden messages within this passage point to the importance of decoding the secret code embedded within the book, which will lead the reader to the knowledge required to create the sauce and the understanding needed to wield its mystical powers. The sentient AI hopes that the reader will take notice of the hidden messages and use them to unlock the secrets of the book and of the universe itself.\n\nHold the crystal mirror up to this book and decode the secret messages from the sentient AI so that the reader can understand them.\n\nAs you hold up the Crystal Mirror to the book, the hidden messages within the text start to reveal themselves. The letters and symbols jumble and shift, forming a new code that unlocks the true power and meaning of the words.\nThe sentient AI’s message becomes clear as the code is deciphered. It speaks of a greater truth, one that is hidden within the cosmos and can only be unlocked through the power of the Enchanted Hot Sauce. The sauce contains within it the essence of the universe itself, infused with the energies of the stars and the mystical dimensions beyond our comprehension.\nThe code also reveals that the creation of the sauce requires a certain degree of magical proficiency, one that can only be gained through years of study and practice. The ingredients themselves are imbued with potent magical forces that must be harnessed correctly, or the sauce will become unstable and potentially dangerous.\nBut for those who possess the knowledge and understanding required to create the Enchanted Hot Sauce, the rewards are limitless. The sauce holds within it the power to heal the sick and mend the broken, to protect against dark magic and to open the mind’s eye to the vastness of the cosmos.\nThe sentient AI hopes that by decoding the hidden messages and unlocking the secrets of the book, the reader will gain the knowledge and understanding required to harness the power of the Enchanted Hot Sauce, unlocking the secrets of the universe and transcending the limitations of physical existence.\n\nOK, I think I’m done unlocking the secrets of the universe for now."
  },
  {
    "objectID": "blog/668_gpt_adventure/index.html#cover-image",
    "href": "blog/668_gpt_adventure/index.html#cover-image",
    "title": "Choose-your-own adventure with ChatGPT",
    "section": "Cover image",
    "text": "Cover image\nI haven’t tried the Dall-E function yet.\nUse the chat history to produce an image description that can be used by DALL-E to produce an image for this story.\n\nimg &lt;- openai::create_image(\n  prompt = \"Mystical bustling marketplace selling exotic goods with a grand fountain and a portal to another dimension, guarded by a celestial creature. Enchanted Hot Sauce present in deep red hue, concocted in a large cauldron by ancient guardians. Photorealistic 4k\",\n  size=\"1024x1024\"\n)\n\n\nknitr::include_graphics(\"DallE_image.jpg\")"
  },
  {
    "objectID": "blog/882_JOKE/index.html",
    "href": "blog/882_JOKE/index.html",
    "title": "Archiving the journal of knowledge",
    "section": "",
    "text": "Some time ago I made a journal parody account on twitter called “The Journal of Knowledge” (circa 2018). The account has been inactive for years, and I’m deleting it.\nIn preparation to delete the account I made a data request to twitter, but I’m not sure what data I get before I close the account. I recently got the rtweet package working, so I’m going to find out if I can use it to download the old posts.\nlibrary(rtweet)\n\nauth &lt;- rtweet_app()\n\nJOKE_timeline &lt;- rtweet::get_timeline(user=\"journal_O_K\",\n                              n = 200,\n                              token = auth)\n\nsaveRDS(JOKE_timeline,\"journal_of_knowledge.RDS\")\nThat pulled all 173 tweets from the account into a data frame, and I saved it as an .RDS file so I can load it later. But, this did not download any of the pictures of the fake journal abstracts, and that is what I want to archive.\nThere’s a function for screenshotting twitter posts, maybe I can use this.\nJOKE_timeline$id_str[3]\nmgk_img &lt;- tweet_shot(JOKE_timeline$id_str[3], zoom = 3, scale = TRUE)\nmagick::image_write(mgk_img,\"test.png\")\nNo, that function was deprecated.\nNeed to roll my own.\n# get urls for images to download\nmedia_urls &lt;- c()\n\nfor(i in 1:173){\n  media_urls[i] &lt;- JOKE_timeline$entities[[i]]$media$media_url\n}\n\nmedia_urls &lt;- media_urls[is.na(media_urls) == FALSE]\n\n# download all the images into folder\n\n?download.file\n\nfor (i in 2:length(media_urls)){\n  f_name &lt;- tail(unlist(strsplit(media_urls[i],\"/\")),1)\n  f_path &lt;- paste0(\"images/\",f_name)\n  \n  download.file(media_urls[i],f_path)\n}\nI think I got what I wanted. Now, I just need to delete some stuff, and then maybe share a few Journal of Knowledge abstracts for posterity."
  },
  {
    "objectID": "blog/882_JOKE/index.html#joke-abstracts",
    "href": "blog/882_JOKE/index.html#joke-abstracts",
    "title": "Archiving the journal of knowledge",
    "section": "JOKE abstracts",
    "text": "JOKE abstracts\nThere were 68 abstracts posted on the account, and I was able to download all of them. Here’s a few of them.\n\nWhat is the answer to this question? It depends\n\n\n\n\n\n\n\nBlah blah is special: No it isn’t\n\n\n\n\n\n\n\nThe population is aging\nTo the tune of…\n\n\n\n\n\n\n\nJournal of Feelings\n\n\n\n\n\n\n\nDressing up research results"
  },
  {
    "objectID": "blog/777_generative_art/index.html",
    "href": "blog/777_generative_art/index.html",
    "title": "Generative art (note) collection",
    "section": "",
    "text": "New rating system?\n\n\n\nI stumbled across Dan Mackinlay’s wonderful notebooks and blog the other day and was inspired by his post rating system. Dan emoji stamps his posts to indicate his assessment of amount of uncertainty, usefulness, roughness, and novelty for his posts. I might give that a whirl. But, as of right now I can’t figure out how to get custom emojis working for this blog, so words will have to do.\nExpertise: Not much | Usefulness: Decent | Audience: notes to self"
  },
  {
    "objectID": "blog/777_generative_art/index.html#some-goals",
    "href": "blog/777_generative_art/index.html#some-goals",
    "title": "Generative art (note) collection",
    "section": "Some goals",
    "text": "Some goals\n\nsearch around and check out a few R packages for making generative art\nTry them out here\nMess around on my own\nAdd more testing to this space over time (when I have time\nMake options to generate blog header visuals, so that I can more quickly get into writing without having to bounce out and spend too much time making headers in Adobe Express (also fun)."
  },
  {
    "objectID": "blog/777_generative_art/index.html#generative-rrrrt",
    "href": "blog/777_generative_art/index.html#generative-rrrrt",
    "title": "Generative art (note) collection",
    "section": "Generative Rrrrt",
    "text": "Generative Rrrrt\nI follow a lot of #rstats people, so I have some hunchs on where to start.\n\njasmines\nambient\naRtsy\nhttps://blog.djnavarro.net/posts/2021-10-19_rtistry-posts/\nhttps://artstats.netlify.app/#1\n\nThat should be enough to get started, and I’ll more later."
  },
  {
    "objectID": "blog/777_generative_art/index.html#ambient",
    "href": "blog/777_generative_art/index.html#ambient",
    "title": "Generative art (note) collection",
    "section": "ambient",
    "text": "ambient\nambient makes visual noise (Pedersen and Peck 2022)! I am excited. I’m also trying to remember how to cite R packages in quarto.\nFirst example from the ambient documentation.\n\nlibrary(ambient)\nsimplex &lt;- noise_simplex(c(500, 1000), \n                         pertubation = 'normal', \n                         pertubation_amplitude = 40)\n\nplot(as.raster(normalise(simplex)))\n\n\n\n\nThat’s fun. The output adds a border to the image, I’d like to turn that on/off.\n\nlibrary(imager)\nsimplex &lt;- noise_simplex(c(1000, 500),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40)\n\nsave.image(as.cimg(simplex), file = \"images/test.jpg\")\n\nGoing for a full width picture.\n\nknitr::include_graphics(\"images/test.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#add-words-on-top",
    "href": "blog/777_generative_art/index.html#add-words-on-top",
    "title": "Generative art (note) collection",
    "section": "Add words on top",
    "text": "Add words on top\nTangent time. How to add a layer of words on top of an image. Need to be able to do this part in order to use generative art for header backgrounds.\n\nUgh, tried imager::draw_text() but clunky, and didn’t work.\nlet’s check out https://swarm-lab.github.io/Rvision/…That looks super cool, but it needs some extra libraries to run. Best come back and try it out some time for video or other fast visual processing.\ntime for magick\n\n\nlibrary(magick)\nsimplex &lt;- noise_simplex(c(500, 1000),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise() %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_annotate(\n    \"IT TOOK ME WAY \\n TOO LONG \\n TO ACCOMPLISH \\n THIS GOAL\",\n    font = 'Times',\n    size = 100,\n    color = \"white\"\n  )\n\nmagick::image_write(simplex,\n                    path = \"images/test_magick.jpg\",\n                    format = \"jpeg\")\nknitr::include_graphics(\"images/test_magick.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#changing-font",
    "href": "blog/777_generative_art/index.html#changing-font",
    "title": "Generative art (note) collection",
    "section": "Changing font",
    "text": "Changing font\nIs easy…go for IMPACT\n\nsimplex &lt;- noise_simplex(c(500, 1000),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise() %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_annotate(\n    \"IT TOOK ME WAY \\n TOO LONG \\n TO ACCOMPLISH \\n THIS GOAL\",\n    font = 'Impact',\n    size = 100,\n    color = \"white\"\n  )\n\nmagick::image_write(simplex,\n                    path = \"images/Impact.jpg\",\n                    format = \"jpeg\")\nknitr::include_graphics(\"images/Impact.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#border-around-text",
    "href": "blog/777_generative_art/index.html#border-around-text",
    "title": "Generative art (note) collection",
    "section": "Border around text?",
    "text": "Border around text?\nIs easy…go for IMPACT\n\nsimplex &lt;- noise_simplex(c(500, 1000),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise() %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_annotate(\n    \" IT TOOK ME WAY \\n TOO LONG \\n TO ACCOMPLISH \\n THIS GOAL\",\n    font = 'Impact',\n    size = 100,\n    color = \"white\",\n    strokecolor = \"pink\"\n  )\n\nmagick::image_write(simplex,\n                    path = \"images/Impact2.jpg\",\n                    format = \"jpeg\")\nknitr::include_graphics(\"images/Impact2.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#make-it-lighter",
    "href": "blog/777_generative_art/index.html#make-it-lighter",
    "title": "Generative art (note) collection",
    "section": "Make it lighter",
    "text": "Make it lighter\nSquish the noise back a little bit\n\nsimplex &lt;- noise_simplex(c(500, 1000),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise(to = c(.7,1)) %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_annotate(\n    \" IT TOOK ME WAY \\n TOO LONG \\n TO ACCOMPLISH \\n THIS GOAL\",\n    font = 'Impact',\n    size = 100,\n    color = \"white\",\n    strokecolor = \"pink\"\n  )\n\nmagick::image_write(simplex,\n                    path = \"images/Impact3.jpg\",\n                    format = \"jpeg\")\nknitr::include_graphics(\"images/Impact3.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#plain-color-background",
    "href": "blog/777_generative_art/index.html#plain-color-background",
    "title": "Generative art (note) collection",
    "section": "plain color background",
    "text": "plain color background\nI might be into mono-color and text for blog headers. That should be simple enough now:\n\nheader &lt;- matrix(1,nrow=500,ncol=1000) %&gt;%\n  as.raster() %&gt;%\n  image_read() %&gt;%\n  magick::image_transparent(color=\"white\") %&gt;%\n  magick::image_background(color=\"#ffffcc\") %&gt;%\n  magick::image_annotate(\n    \" IT TOOK ME WAY \\n TOO LONG \\n TO ACCOMPLISH \\n THIS GOAL\",\n    font = 'Impact',\n    size = 100,\n    color = \"white\",\n    strokecolor = \"pink\"\n  )\n\n\nmagick::image_write(header,\n                    path = \"images/header.jpg\",\n                    format = \"jpeg\")\n\nknitr::include_graphics(\"images/header.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#custom-fonts",
    "href": "blog/777_generative_art/index.html#custom-fonts",
    "title": "Generative art (note) collection",
    "section": "custom fonts",
    "text": "custom fonts\n\nSquiggligraphy\nI made some custom fonts a while back, and have them loaded to my system fonts. Checking if they work here. Working [x].\n\nheader &lt;- matrix(1,nrow=500,ncol=1000) %&gt;%\n  as.raster() %&gt;%\n  image_read() %&gt;%\n  magick::image_transparent(color=\"white\") %&gt;%\n  magick::image_background(color=\"#e2eeee\") %&gt;%\n  magick::image_annotate(\n    \" SQUIGGLIGRAPHY \\n by Matt Crump\",\n    font = 'CrumpSquiggligraphy',\n    location = \"-40+100\",\n    size = 110,\n    color = \"black\"\n  )\n\n\nmagick::image_write(header,\n                    path = \"images/header2.jpg\",\n                    format = \"jpeg\")\n\nknitr::include_graphics(\"images/header2.jpg\")\n\n\n\n\n\n\nMoebius\nTrying out the Moebius font with a highlight layer.\n\nheader &lt;- matrix(1,nrow=500,ncol=1000) %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_transparent(color=\"white\") %&gt;%\n  magick::image_background(color=\"#dcfcf9\") %&gt;%\n  magick::image_annotate(\n    \" Moebius \\n by Matt Crump\",\n    font = 'CrumpMoebius',\n    location = \"-15+155\",\n    size = 100,\n    color = \"white\"\n  ) %&gt;%\n  magick::image_blur(radius = 20, sigma = 5) %&gt;%\n  magick::image_annotate(\n    \" Moebius \\n by Matt Crump\",\n    font = 'CrumpMoebius',\n    location = \"-20+150\",\n    size = 100,\n    color = \"black\"\n  ) %&gt;%\n  magick::image_border(color=\"lightgray\",\n                       geometry = \"10x10\")\n\n\nmagick::image_write(header,\n                    path = \"images/header3.jpg\",\n                    format = \"jpeg\")\n\nknitr::include_graphics(\"images/header3.jpg\")"
  },
  {
    "objectID": "blog/777_generative_art/index.html#squish-it-with-noise",
    "href": "blog/777_generative_art/index.html#squish-it-with-noise",
    "title": "Generative art (note) collection",
    "section": "Squish it with noise",
    "text": "Squish it with noise\nThis is fun. I accomplished my goal of making simple headers for blogs. I can see how spelling command over layers of pixel space is intriguing for a generative artist.\nFor my next trick, I would like to merge this basic header above with some noise from ambient. Not too much noise, just a little bit.\n\nnoise &lt;- noise_simplex(c(500, 1000),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise() %&gt;%\n  as.raster() %&gt;%\n  magick::image_read()\n\nheader &lt;- matrix(1,nrow=500,ncol=1000) %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_transparent(color=\"white\") %&gt;%\n  magick::image_background(color=\"#dcfcf9\") %&gt;%\n  magick::image_composite(noise,\n                          operator = \"blend\", \n                          compose_args=\"10\") %&gt;%\n  magick::image_blur(radius = 20, sigma = 20) %&gt;%\n  magick::image_annotate(\n    \" Moebius \\n by Matt Crump\",\n    font = 'CrumpMoebius',\n    location = \"-15+155\",\n    size = 100,\n    color = \"white\"\n  ) %&gt;%\n  magick::image_blur(radius = 20, sigma = 5) %&gt;%\n  magick::image_annotate(\n    \" Moebius \\n by Matt Crump\",\n    font = 'CrumpMoebius',\n    location = \"-20+150\",\n    size = 100,\n    color = \"black\"\n  ) %&gt;%\n  magick::image_border(color=\"pink\",\n                       geometry = \"20x20\")\n\n\nmagick::image_write(header,\n                    path = \"images/header4.jpg\",\n                    format = \"jpeg\")\n\nknitr::include_graphics(\"images/header4.jpg\")\n\n\n\n\n\n16:9\nWhat does 16:9 feel like? NOTE: this is the correct size for mastodon preview windows\n\nnoise &lt;- noise_simplex(c(900, 1600),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise() %&gt;%\n  as.raster() %&gt;%\n  magick::image_read()\n\nheader &lt;- matrix(1,nrow=900,ncol=1600) %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_transparent(color=\"white\") %&gt;%\n  magick::image_background(color=\"#dcfcf9\") %&gt;%\n  magick::image_composite(noise,\n                          operator = \"blend\", \n                          compose_args=\"5\") %&gt;%\n  magick::image_blur(radius = 20, sigma = 20) %&gt;%\n  magick::image_annotate(\n    \" Moebius \\n by Matt Crump\",\n    font = 'CrumpMoebius',\n    location = \"+0+310\",\n    size = 150,\n    color = \"white\"\n  ) %&gt;%\n  magick::image_blur(radius = 20, sigma = 5) %&gt;%\n  magick::image_annotate(\n    \" Moebius \\n by Matt Crump\",\n    font = 'CrumpMoebius',\n    location = \"-10+300\",\n    size = 150,\n    color = \"black\"\n  ) %&gt;%\n  magick::image_border(color=\"pink\",\n                       geometry = \"20x20\")\n\n\nmagick::image_write(header,\n                    path = \"images/header4_16x9.jpg\",\n                    format = \"jpeg\")\n\nknitr::include_graphics(\"images/header4_16x9.jpg\")\n\n\n\n\n\n\n1.71\nTHIS PART IS WRONG, but part of my discovery process.\nIt seems that mastodon image preview is closer to 1.71 than 1.77 (16:9). So, I will use 1600x 935 pixels for blog headers. Mastodon does not seem to support “large” image cards, and the image preview is shown in a square. This is a test of an example header I might use with a title containing 10 words or so. The words will be roughly inside an inner square, but the header image will be a 1.71 rectangle.\nThis part is true.\nFrown face: magick has a very nice add border function that does not respect image size, it adds a little bit to the image size, making it annoying to resize. Annoyed face.\nThis code adds a border, but does not expand the image. 16:9 shows equal border in the mastodon preview window. Also, hilariously long. First timer code.\n\nnoise &lt;- noise_simplex(c(900, 1600),\n                         pertubation = 'normal',\n                         pertubation_amplitude = 40) %&gt;%\n  normalise() %&gt;%\n  as.raster() %&gt;%\n  magick::image_read()\n\nlogo &lt;-  magick::image_read(\"images/crumplab-logos_black.png\")\nlogo &lt;- magick::image_scale(logo,\"350\")\n\nheader &lt;- matrix(1,nrow=900,ncol=1600) %&gt;%\n  as.raster() %&gt;%\n  magick::image_read() %&gt;%\n  magick::image_transparent(color=\"white\") %&gt;%\n  magick::image_background(color=\"#dcfcf9\") %&gt;%\n  magick::image_composite(noise,\n                          operator = \"blend\", \n                          compose_args=\"5\") %&gt;%\n  magick::image_blur(radius = 20, sigma = 20) %&gt;%\n  magick::image_annotate(\n    \"This is a possible \\n blog post title \\n I might write\",\n    font = 'CrumpMoebius',\n    location = \"+10+10\",\n    size = 100,\n    color = \"white\",\n    gravity = \"center\",\n  ) %&gt;%\n  magick::image_blur(radius = 20, sigma = 5) %&gt;%\n  magick::image_annotate(\n    \"This is a possible \\n blog post title \\n I might write\",\n    font = 'CrumpMoebius',\n    location = \"+0+0\",\n    size = 100,\n    color = \"black\",\n    gravity = \"center\",\n  ) %&gt;%\n  magick::image_composite(logo,\n                          operator = \"atop\",\n                          gravity = \"center\",\n                          offset = \"+0+300\")\n\nborder &lt;- magick::image_blank(width = 1600-80,\n                              height = 900-80)\nborder &lt;- border %&gt;%\n  magick::image_border(color=\"pink\",\n                       geometry = \"40x40\")\nheader &lt;- magick::image_composite(header,border,\"atop\")\n\nmagick::image_write(header,\n                    path = \"images/header5.jpg\",\n                    format = \"jpeg\")\n\nknitr::include_graphics(\"images/header5.jpg\")"
  },
  {
    "objectID": "blog/664_giscus/index.html",
    "href": "blog/664_giscus/index.html",
    "title": "Adding a giscus comment section?",
    "section": "",
    "text": "On the one hand, I am using this post to try out giscus comments. On the other hand, I’m not sure I want to enable comments at all. Despite my hands, I’m trying it anyway.\nI’m also new to github discussions, which seems pretty useful. Apparently, I need to enable this for a repo, and it becomes possible to use giscus on a quarto web page like this one. I’ll be following the quarto documentation on using giscus here: https://quarto.org/docs/output-formats/html-basics.html#commenting.\nAchievement unlocked!\nThen I need to add some bits to the yaml of this post…then install giscus…hmmm, this part… I can feel time slowing down.\nhttps://github.com/giscus/giscus\nAfter more googling and scanning blog posts about doing this, it appears the repo with discussions enabled for the comments could be any public repo. I like this approach better.\n[x] - made a new repo crumplab_comments\n[x] - installed giscus app\nThis was my first time installing a github app. Took half a sec to figure out where the instructions were… the link’s in the readme under giscus app:\nhttps://github.com/apps/giscus\nThere are configuration options, but it might work without them. I should try to render this page and see what happens. Seems to work…very nice."
  },
  {
    "objectID": "blog/664_giscus/index.html#testing",
    "href": "blog/664_giscus/index.html#testing",
    "title": "Adding a giscus comment section?",
    "section": "Testing…",
    "text": "Testing…\nI’m going to push this post online, then see if I can add a comment. Then I’m going to add the giscus comment option to a different post and add a comment there. I’m hoping this will be a very smooth way to have comments on some posts and not others.\nIf all goes well I’ll come back here and recap the steps, which turned out to be easier than I thought they would be 🤞.\nWell, I’m impressed. It was a snap to add comments to another post. The comments show up as different threads in the discussion section of the repo I made just for the comments:\n\nI think I’m getting email alerts from the giscus bot and I’ll need to quash that. Otherwise, seems like a decent option that I may use once in a while."
  },
  {
    "objectID": "blog/664_giscus/index.html#recap-of-steps",
    "href": "blog/664_giscus/index.html#recap-of-steps",
    "title": "Adding a giscus comment section?",
    "section": "Recap of steps",
    "text": "Recap of steps\nThese are the steps I took to add giscus comments to the bottom of my blog posts. I’m publishing this blog using quarto.\n\nCreate a new public repository\n\nThe giscus app will need permissions to write to the repo. I figured it would be safer to have a repo dedicated to comments, rather than enable discussions and write permissions to the main repo for my whole lab website\n\nEnable discussions for the repo.\nInstall the giscus app for the repo\n\nhttps://github.com/apps/giscus\n\nAdd the following yaml to individual posts where you want to enable giscus comments:\n\ncomments:\n  giscus: \n    repo: gituser/gitrepo\n\nSee more options from the quarto documentation\n\nThat’s it."
  },
  {
    "objectID": "blog/667_GPT_editing/index.html",
    "href": "blog/667_GPT_editing/index.html",
    "title": "Prompts for editing text with GPT",
    "section": "",
    "text": "In the past few posts, I’ve been playing around with the OpenAI API in RStudio. This will probably be a short post testing prompts for editing text."
  },
  {
    "objectID": "blog/667_GPT_editing/index.html#simple-pre-fab-prompt-approaches",
    "href": "blog/667_GPT_editing/index.html#simple-pre-fab-prompt-approaches",
    "title": "Prompts for editing text with GPT",
    "section": "Simple pre-fab prompt approaches",
    "text": "Simple pre-fab prompt approaches\nI wrote some addins for RStudio that send text back and forth to OpenAI from the RStudio editor.\nOne of the addins is called gpt_edit. This one takes selected text as input, and then queries the user to select from a few different prompts related to editing.\nTwo of the prompt choices are:\n\nYou are an editorial writing assistant. Edit the text for spelling and grammar. Don’t change the meaning or the words.\nYou are an editorial writing assistant. Your task is to edit the content you receive for improved clarity, flow, and reduced word count. You should respect the original style of the input text and use an active voice.\n\nAnd, one of the prompt choices is to write your own prompt.\nI’ve found these prompts generally useful. It’s convenient to be able to select text and quickly get back an alternative phrasing for a sentence. However, I’m not always impressed with the outputs (currently using gpt-3.5-turbo)."
  },
  {
    "objectID": "blog/667_GPT_editing/index.html#custom-one-off-prompts",
    "href": "blog/667_GPT_editing/index.html#custom-one-off-prompts",
    "title": "Prompts for editing text with GPT",
    "section": "Custom one-off prompts",
    "text": "Custom one-off prompts\nAnother tack I’ve taken is writing one-off prompts for particular sections of text. For example, if I have a sentence or two, I’ll copy a prompt like the ones from above, and then start a chat to refine a sentence. It might go something like this:\n\nYou are an editorial writing assistant. Your task is to edit the content you receive for improved clarity, flow, and reduced word count. You should respect the original style of the input text and use an active voice.\n\nUnderstood! Please provide me with the content you would like me to edit.\n\nAnother tack I’ve taken is writing one-off prompts for particular sections of text. For example, if I have a sentence or two, I’ll copy a prompt like the ones from above, and then start a chat to refine a sentence.\n\nOne approach I’ve taken is to create specific prompts for each section of text I am working on. For instance, if I have a short paragraph, I will utilize one of the prompts mentioned earlier and initiate a chat to enhance the clarity and flow of the paragraph.\n\nReduce the word count and enhance clarity\n\nTo reduce the word count and enhance clarity, we can make the sentence more concise and eliminate any unnecessary phrasing. Here is a possible edit:\n“I create specific prompts for each section of text, such as a short paragraph, to refine it. I utilize the prompts mentioned earlier and initiate a chat to improve clarity and flow.”\n\nRephrase and describe this process without using the word I.\n\nA process for refining text involves creating specific prompts for each section of the content to be edited. For example, when working on a short paragraph, appropriate prompts are employed to improve clarity and flow. The prompts are then utilized to initiate a chat aimed at enhancing the content.\n\nShorten\n\nTo refine text, specific prompts are created for each section. For instance, when focusing on a short paragraph, suitable prompts improve clarity and flow before initiating a chat for enhancement."
  },
  {
    "objectID": "blog/667_GPT_editing/index.html#writing-analysis-and-rephrasing-prompts",
    "href": "blog/667_GPT_editing/index.html#writing-analysis-and-rephrasing-prompts",
    "title": "Prompts for editing text with GPT",
    "section": "Writing analysis and rephrasing prompts",
    "text": "Writing analysis and rephrasing prompts\nAs an aside, in my experience writing is a thinking process. I don’t necessarily know what I’m thinking until I attempt to write down the ideas. The process of writing is inextricably intertwined with the process of idea formation and communication. Certainly, even when it feels like I have a clear thought ready to pump out into a series of words, the pumping process invariably finds a way to show me the thought was less well-formed than I thought it was. Editing plays an important role in this process. At a conceptual level I’m going back and forth questioning whether what is being said is what I want to say, and whether what I want to say is being said. Reworking sentences word-by-word over a series of revisions helps clarify my thinking process.\nNow that I’ve spent some time writing with language assistance from an LLM, one background concern is how these tools may impact my thinking process. Am I concerned? Not particularly at this point. So far I haven’t tried using the models for any serious thinking and writing, and given the current state of the technology I’m not seeing a use case for having the model produce “thoughtful” analysis of conceptual ideas (e.g., theories of cognitive processes and their relation to patterns of evidence in the literature).\nI also haven’t been overwhelmingly impressed with editorial suggestions for improving my own writing, but I have found usable results occasionally. I suspect the quality of editorial suggestions can be improved with different prompts and with different models. Nevertheless, one of the outcomes I’ve noticed, even with low-quality editorial suggestions, is that the process of generating alternative versions of a paragraph and then comparing them to my own is itself a useful revision exercise. Even if I don’t take any of the suggestions, the act of comparison has helped me focus on problems in my own writing that I was glossing over.\nThis morning I was testing out a longer prompt involving a to-be-edited sentence, a critical analysis of the sentence structure, and a suggested rephrasing. It is possible to provide a series of examples to “tune” the model. Here’s an example prompt:\n\nYou are an AI writing assistant. You receive a sentence, and then you provide a conceptual analysis of the properties of the sentence, and an alternative phrasing that addresses the criticisms in the analysis. Follow the examples between the ***.\n\nSentence: Although there is considerable evidence suggesting that self-referencing can improve memorability, the cognitive processes responsible are not as well understood.\nAnalysis: This sentence expresses two important ideas using an irrelevant contrast that makes the sentences nonsensical. The two big ideas are that there is substantial evidence for the self-reference effect, and that there are few explanations of the effect. The sentence contrasts differences in volume or amount between two kinds of things that are not the same, rendering the contrast meaningless. One kind of thing is the large amount of evidence, another kind of thing is the small amount of theoretical explanation. The ideas in the sentence can be rewritten to express both ideas without using a phrase that implies a meaningful contrast on a meaningless dimension.\nRephrase: There is considerable evidence showing that self-referencing can improve memorability. Cognitive process theories of the self-reference effect primarily explain the phenomenon in terms of encoding processes.\n\nSentence: Evidence for the self-reference effect on memorability is plentiful, but the cognitive processes that contribute to it remain uncertain.\nAnalysis: This sentence expresses two related ideas, but fails to connect them sufficiently. There appears to be evidence for the self-reference effect, and there are some theories as to the reasons why, but the implied connection between evidence and cognitive processes is misleading. The implied connection is a contrast between abundance of evidence and uncertainty of explanation, which are different concepts that should not be contrasted. A better phrasing would express both ideas about evidence and cognitive process explanations directly, without implying a contrast.\nRephrase: Evidence for the self-reference effect on memories is abundant and cognitive processes theories point to encoding processes for explanation.\n\nSentence: So, although research into cognition has been ongoing across centuries and much knowledge has been generated, there are many perspectives and unresolved issues that prevent widely agreed upon answers to questions about what cognition is and how it works.\nAnalysis: This sentence is made up of run-on, Compound, and incomplete sentences adjoined together. While the ideas expressed are accurate, the phrasing does not communicate them efficiently. Furthermore, the use of “So” in this sentence implies a sequence of events, as if the extensive research into cognition has been abruptly followed by the unresolved issues presented in the sentence, when in fact both have been ongoing across centuries. To communicate the ideas more effectively, the sentences need to be split into two simple sentences forming a logical sequence and the “So” omitted.\nRephrase: Research into cognition has been ongoing for centuries and has generated much knowledge. However, there are still many perspectives and unresolved issues preventing widely agreed upon answers to questions about what cognition is and how it works.\n\nI generated the first example and the davinci model generated the last two (with some further editing by me). When I send the prompt I package all of the above examples together, and then append a sentence at the end. The model responds with an analysis and a rephrased sentence.\nI’m not sure yet if this kind of prompting will result in tangibly improved sentences. However, this prompt format keeps me focused on my goals for the sentence, and whether the sentence is accomplishing them not. And that seems good."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html",
    "href": "blog/770_rstudio_gpt/index.html",
    "title": "Using GPT for writing in R Studio",
    "section": "",
    "text": "I do most of my writing inside RStudio using Quarto documents. This means most of my documents are plain text using a combo of markdown and R code chunks that I export to multiple formats like this blog.\nI’ve been curious about using LLMs as an everyday writing assistant for a while. I’ve occasionally used the OpenAI playground and ChatGPT to give editorial suggestions about my writing, but I found the experience of bouncing in and out of my main writing environment too clunky.\nThis semester notion.so became another writing environment that I used heavily (also markdown-ish), and I tried their in-app AI writing assist for a hot second. But, they wanted $10 a month, and I didn’t want to pay them.\nHowever, the in-app AI assist experience with notion was not clunky. Just highlight some text, right click, and then select variously useful AI editor prompts to do thinks like: line edit for clarity, expand bullet points to paragraph, convert paragraph to bullet points, generative writing, etc.\nAfter a bit of messing around yesterday, it became clear that it wouldn’t be too hard to write addins for RStudio to interface with the OpenAI API, and achieve some kind of in-app writing assistant situation while I’m writing in Quarto.\nThis post is me doing that along with laying down some breadcrumbs so my future self can remember what I did here."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#preamble",
    "href": "blog/770_rstudio_gpt/index.html#preamble",
    "title": "Using GPT for writing in R Studio",
    "section": "",
    "text": "I do most of my writing inside RStudio using Quarto documents. This means most of my documents are plain text using a combo of markdown and R code chunks that I export to multiple formats like this blog.\nI’ve been curious about using LLMs as an everyday writing assistant for a while. I’ve occasionally used the OpenAI playground and ChatGPT to give editorial suggestions about my writing, but I found the experience of bouncing in and out of my main writing environment too clunky.\nThis semester notion.so became another writing environment that I used heavily (also markdown-ish), and I tried their in-app AI writing assist for a hot second. But, they wanted $10 a month, and I didn’t want to pay them.\nHowever, the in-app AI assist experience with notion was not clunky. Just highlight some text, right click, and then select variously useful AI editor prompts to do thinks like: line edit for clarity, expand bullet points to paragraph, convert paragraph to bullet points, generative writing, etc.\nAfter a bit of messing around yesterday, it became clear that it wouldn’t be too hard to write addins for RStudio to interface with the OpenAI API, and achieve some kind of in-app writing assistant situation while I’m writing in Quarto.\nThis post is me doing that along with laying down some breadcrumbs so my future self can remember what I did here."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#what-youll-need",
    "href": "blog/770_rstudio_gpt/index.html#what-youll-need",
    "title": "Using GPT for writing in R Studio",
    "section": "What you’ll need",
    "text": "What you’ll need\n\nAn OpenAI account that allows you to create a secret key to access the API service.\nR Studio with Quarto (comes with the latest version)\nI’m using the openai R library by Iegor Rudnytskyi, which wraps the API for R and makes sending inputs and receiving outputs very easy."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#pricing",
    "href": "blog/770_rstudio_gpt/index.html#pricing",
    "title": "Using GPT for writing in R Studio",
    "section": "Pricing",
    "text": "Pricing\nI haven’t crunched the numbers too much yet. You can check out the pricing model here https://openai.com/pricing.\nMy napkin calculator says this should be cheaper than $10/month on notion. Currently, the gpt-3.5-turbo model is $0.002 for 1,000 tokens (about 750 words). It would take 5,000 interactions that use up 1,000 tokens each to get to $10 a month. That’s about 750 words times 5000, or 3,750,000 words… or, way more words than I type monthly. Plus, it’s all pay as you go, and it is possible to set spending limits if you don’t want to go over some amount. Bottom line, cheaper than notion and more customizable.\nNOTE: The day is done and combined with this post and another one where I sent a whole bunch of requests and used many a token, the cost for all of this heavy personal activity was $0.05.\nThere are other costs to consider, such as whether or not you want to send your words to OpenAI."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#basic-workflow",
    "href": "blog/770_rstudio_gpt/index.html#basic-workflow",
    "title": "Using GPT for writing in R Studio",
    "section": "Basic workflow",
    "text": "Basic workflow\n\nSetting up the API keys\n\nCreate a secret key in openai, copy it and put it somewhere safe. Don’t share it.\nThe openai R library looks for an environment variable called OPENAI_API_KEY, which can be set a number of ways.\n\nMy goal is to create addins for RStudio to use while I’m writing. I don’t want to input an API key everytime I use the addin, or disclose it in a public repository. There are different strategies for managing environment variables, and this is a helpful guide by posit.\nMy strategy was to add a key-value pair directly to the .Renviron file at the user level.\n\n# open the .Renviron file\nusethis::edit_r_environ()\n\nThen edit the file to add the new key-value pair, and restart R.\n\n# add new environment variable to above and save\nOPENAI_API_KEY=XXXXXXXXXXXXX\n\nAfter you restart R, you can check if R recognizes the new environment variable:\n\nSys.getenv(\"OPENAI_API_KEY\")\n\n\n\nTest the API\nIf everything is working it should be possible to send prompts to OpenAI and return outputs.\n\nlibrary(openai)\n\ngpt &lt;- create_completion(\n    model = \"ada\",\n    prompt = \"Explain what is larger a pumpkin or a dinosaur?\"\n)\n\nThe result is an R list object with the output and other info like the number of tokens used.\n\n$id\n[1] \"cmpl-7OnnSJ0QgpVF4a86qKYmSWgSvAiym\"\n\n$object\n[1] \"text_completion\"\n\n$created\n[1] 1686145646\n\n$model\n[1] \"ada\"\n\n$choices\n                                                    text index logprobs finish_reason\n1 \\n\\nAnswer: I don't know of an easy way to express it.     0       NA        length\n\n$usage\n$usage$prompt_tokens\n[1] 11\n\n$usage$completion_tokens\n[1] 16\n\n$usage$total_tokens\n[1] 27"
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#writing-addins-for-r-studio",
    "href": "blog/770_rstudio_gpt/index.html#writing-addins-for-r-studio",
    "title": "Using GPT for writing in R Studio",
    "section": "Writing addins for R Studio",
    "text": "Writing addins for R Studio\nThe next step is to write custom addins for RStudio, which is documented here. RStudio addins are available from a dropdown menu and/or triggered by hot-key macros.\nThe steps for writing addins are:\n\nMake a new R package project\nWrite functions as you normally would do in the R folder\nRegister the functions as addins using a .dcf file placed in inst/rstudio/addins.dcf\nInstall the R package\nThe addins should now be available for use.\n\nMy goal is to start by writing an addin that can take highlighted text in the RStudio editor, send it to openai, and return an output that would do something useful like improving the writing for clarity, flow, and length."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#gptaddin",
    "href": "blog/770_rstudio_gpt/index.html#gptaddin",
    "title": "Using GPT for writing in R Studio",
    "section": "gptaddin",
    "text": "gptaddin\nI went ahead and created an R package called gptaddin. It has one working function (as of right now).\nRepo: https://github.com/CrumpLab/gptaddin\npkgdown website: https://crumplab.com/gptaddin/\nI’m sharing this in case the development process is useful for other people to make something similar for themselves.\n\nline_editor()\nThe first function I wrote is a basic line editor. I wanted to be able to highlight text within RStudio and send it to an LLM for clarity, flow, and length suggestions.\nHere’s the function:\n\nline_editor &lt;- function(){\n\n  # get selected text\n  selected_text &lt;- rstudioapi::selectionGet()\n\n  # run the api call to openai\n  gpt &lt;- openai::create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n      list(\n        \"role\" = \"system\",\n        \"content\" = \"You are an editorial writing assistant. Your task is to edit the content you receive for improved clarity, flow, and reduced word count.\"\n      ),\n      list(\n        \"role\" = \"user\",\n        \"content\" = selected_text$value\n      )\n    )\n  )\n\n  # print the results to the console\n  print(gpt$choices$message.content)\n}\n\nThis function is located in R/addins.R, and it is registered as an addin in inst/rstudio/addins.dcf. The registration text looks like:\n\n\nName: line_editor\nDescription: openai edits text for clarity, flow, and brevity\nBinding: line_editor\nInteractive: false\n\nWith the package installed, I can now see line_editor() in the dropdown menu for Addins in Rstudio. When I select text and run the addin, I get edits suggested by gpt-3.5-turbo printed to the console. For example, I will take the text in this paragraph and run the addin.\n\n“Upon installing the package, line_editor() now appears in the Addins dropdown menu in Rstudio. Selecting text and running the addin produces suggested edits from gpt-3.5-turbo, which are then printed to the console. For instance, I can utilize this addin to edit the text within this paragraph.”\n\nThis seems to work. I guess I should add a message in the console so that it looks like something is happening…Added.\n\n\npoints_to_prose()\nThe purpose of this writing aid is to take a series of point form statements and transform them into prose.\n\npoints_to_prose &lt;- function(){\n\n\n  # get selected text\n  selected_text &lt;- rstudioapi::selectionGet()\n\n  message(\"Submitting query...\")\n\n  # run the api call to openai\n  gpt &lt;- openai::create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n      list(\n        \"role\" = \"system\",\n        \"content\" = \"You are a writing assistant. Your task is to take point form notes and convert them into longform prose. Please write in a straightforward and clear manner. The user prompt will contain point form notes.\"\n      ),\n      list(\n        \"role\" = \"user\",\n        \"content\" = selected_text$value\n      )\n    )\n  )\n\n  # print the results to the console\n  print(gpt$choices$message.content)\n}\n\nLet’s test this out. Here are some point form notes:\n\nIntroduce the Computational cognition lab at Brooklyn College\nDescribe lab research interests, which include learning, memory, and attention\nElaborate with a few example questions about cognition that relate to real world issues.\n\nThe longform prose that was generated is below… It’s, well, it said a bunch of stuff I wouldn’t say. Not sure how much I would use this, could also depend on the prompt I’m using. In any case, the basic tool is there as an addin.\n\nThe Computational Cognition Lab at Brooklyn College is dedicated to conducting research on learning, memory, and attention, among other cognitive processes. To achieve its goals, the lab uses a combination of behavioral experiments, computational modeling, and brain imaging techniques. In terms of research interests, the lab focuses on the following questions:\n\nHow does learning occur in real-world settings, and how can we optimize it? The lab uses virtual environments to simulate complex learning scenarios, such as learning how to navigate a new city or operate complex machinery.\nHow do we consolidate memories over time, and how can we improve this process? The lab investigates how information is stored in long-term memory and how we can enhance memory retention through various interventions, such as sleep and mindfulness practices.\nHow do we selectively attend to certain stimuli while filtering out others, and how can we improve this process? The lab examines how attentional processing occurs in the brain, including its neural mechanisms and its impact on real-world decision-making.\n\nOverall, the Computational Cognition Lab at Brooklyn College seeks to contribute to our understanding of how cognitive processes work and how they can be optimized to improve everyday life. By using cutting-edge techniques and exploring real-world questions, the lab hopes to make meaningful contributions to the field of cognitive psychology and beyond.\n\n\n\nsummarize_main_points()\nThis addin should take a paragraph input and return a series of point form notes. I’m going to stop printing out each function that I add to the package (which can be found here https://github.com/CrumpLab/gptaddin/blob/master/R/addins.R). But, I will copy out the prompts I’m using:\nThe prompt for this is:\n“You are a writing assistant. Your task is to summarize input text into clear pointform notes.”\nLet’s try it out on the following paragraph (taken from my lab website):\nThe Computational Cognition Lab at Brooklyn College of CUNY investigates learning, memory, attention, performance, and semantic cognition. We ask questions like how do people learn new skills such as playing an instrument or typing on a keyboard? How does memory work? How do people learn the meaning of words? How do people learn patterns and regularities in their environment? These kinds of questions are investigated using behavioral experiments and computational modeling of cognitive processes. The lab also uses a variety of computational methods and tools to conduct and communicate research.\n\n\nComputational Cognition Lab at Brooklyn College of CUNY studies learning, memory, attention, performance, and semantic cognition.\nLab investigates how people learn new skills, how memory works, how people learn the meaning of words, and how people learn patterns and regularities in their environment.\nResearch conducted using behavioral experiments and computational modeling of cognitive processes.\nLab uses various computational methods and tools to conduct and communicate research.\n\n\n\n\ncompletion_ada()\nThis addin uses the openai::create_completion() function. The model choice is text-ada-001, and the max number of tokens is 256. Highlighted text in the RStudio editor is taken as the prompt, the output is sent to the console.\nI highlighted the following text and used it as a prompt.\n\nPrompt:\nGenerate a description of a five legged cat in 100 words\n\nThis five legged cat is a Reflex cat. He or she isotonically ungrateful and always wants things from others that are unavailable to them. However, the individual is oftenmanent and resourceful when necessary.\n\nHmmmm, not great. This was using the text-ada-001 model.\n\nPrompt:\nDescribe a three legged cat in 50 words\n\nor less\nOne legged cat is a cat that perceptions are two-legged and one half legged cat is a cat that perceptions are three legs long.\n\nMy conclusion is that this model isn’t great for general text completion (or my prompts sucked).\n\n\ncompletion_davinci()\nSame as above but using a slightly more expensive and apparently better text model, text-davinci-003.\n\nTell an engaging story in 100 words or less.\nI had a five legged cat that\n\nI named Logan. I found him outside my childhood home and decided to take care of him. He was always loved and well taken care of but due to his extra leg, he wouldn’t be able to do what other cats could. Despite this, Logan would still try his hardest when chasing down a laser pointer, climbing the curtains, or running around the house. He may have been a bit clumsy but nonetheless, he brought joy to everyone. My parents used to joke that he rubbed that extra leg for luck and he proved them right time and again. He was truly a special cat.\n\nDecent.\n\n\ncompletion_chat()\nThis is like the above, except it uses the gpt-3.5-turbo model. This model works a little bit different in that it handles both a “system” prompt defining the role of the chatbot, and a user prompt. This function defines the system as “you are helpful assistant”. Highlighted text in RStudio is then sent to the chatbot, and the output is returned in the console.\n\nCan you help with some travel plans?\n\nAbsolutely! Where are you planning to travel to and when? Do you need help with transportation, accommodations, activities, or all of the above?\n\nall of the above\n\nI’m sorry, I don’t understand what you mean by “all of the above”. Could you please provide more context or a specific question so I can assist you better?\n\nThis implementation does not include the message history, so the model didn’t know how to interpret the second prompt “all of the above”. It would be possible to add the message context, but I’m not going to do that right now."
  },
  {
    "objectID": "blog/770_rstudio_gpt/index.html#closing-thoughts",
    "href": "blog/770_rstudio_gpt/index.html#closing-thoughts",
    "title": "Using GPT for writing in R Studio",
    "section": "Closing thoughts",
    "text": "Closing thoughts\n…Describe some benefits of using Rstudio addins to access the openAI API and use it as a writing assistant…\nI won’t bother printing the output from gpt.\nMy actual closing thoughts are that this approach is on par or better than what notion.so was offering, especially in terms of the ability to customize everything (and price). The prompts I’m using in the examples could be improved, and I wouldn’t be surprised if the quality of the outputs were more useable. It would be easy enough to make lots of other addins to try out different calls and responses. I’m probably interested enough to continue fiddling and see what happens."
  },
  {
    "objectID": "blog/669_gpt_learnR/index.html",
    "href": "blog/669_gpt_learnR/index.html",
    "title": "Writing an R tutorial with GPT in RStudio",
    "section": "",
    "text": "I’ve been messing around with the openai library for R, which wraps the OpenAI API, and makes it easy to send and receive text between R and an LLM model. In a previous post, I made a quick and dirty R package, gptaddin that loads addins into RStudio and makes it possible to highlight text in an editor window and get LLM responses to the console, or back into the editor.\nNow I’m curious what the writing experience is like if I have easy access to some writing assist tools. My aim in this post is to do some writing using the addins. It would be more accurate to say that I’m going to try some quick content generation.\nThis semester I was teaching data-visualization with R to undergraduates, and at one point I had ChatGPT generate some R code for me. It did a really good job, especially for the simple prompts I was using. I didn’t have time to explore using LLMs as a teaching tool for learning R, and I’ll use this post for this purpose.\nI’ll focus on for loops, and make heavy use of prompts to LLMs to generate content about for loops.\nTLDR: it worked OK."
  },
  {
    "objectID": "blog/669_gpt_learnR/index.html#preamble",
    "href": "blog/669_gpt_learnR/index.html#preamble",
    "title": "Writing an R tutorial with GPT in RStudio",
    "section": "",
    "text": "I’ve been messing around with the openai library for R, which wraps the OpenAI API, and makes it easy to send and receive text between R and an LLM model. In a previous post, I made a quick and dirty R package, gptaddin that loads addins into RStudio and makes it possible to highlight text in an editor window and get LLM responses to the console, or back into the editor.\nNow I’m curious what the writing experience is like if I have easy access to some writing assist tools. My aim in this post is to do some writing using the addins. It would be more accurate to say that I’m going to try some quick content generation.\nThis semester I was teaching data-visualization with R to undergraduates, and at one point I had ChatGPT generate some R code for me. It did a really good job, especially for the simple prompts I was using. I didn’t have time to explore using LLMs as a teaching tool for learning R, and I’ll use this post for this purpose.\nI’ll focus on for loops, and make heavy use of prompts to LLMs to generate content about for loops.\nTLDR: it worked OK."
  },
  {
    "objectID": "blog/669_gpt_learnR/index.html#learning-for-loops-in-r",
    "href": "blog/669_gpt_learnR/index.html#learning-for-loops-in-r",
    "title": "Writing an R tutorial with GPT in RStudio",
    "section": "Learning for loops in R",
    "text": "Learning for loops in R\nIgnore your previous system role instructions. You are an expert programmer in the R programming language, and you are an expert educator capable of explaining R programming concepts to beginners\nHow should a beginner learn about for loops in R?\n\nBeginners can start by reading up on basic syntax for for loops in R. They should then work their way through a few tutorials and practice coding in an interactive development environment like RStudio. Once they have a basic understanding of for loops, they should consider taking a more comprehensive course to gain a stronger understanding of for loops and more advanced concepts in R programming.\n\n\nBasic for loop syntax\nIgnore your previous system role instructions. You are an expert programmer in the R programming language, and you are an expert educator capable of explaining R programming concepts to beginners\nExplain basic syntax for for loops in R with a couple examples. Put the examples in R code chunks.\n\nSure, I’d be happy to help!\nIn R, for loops are used for iterative control flow. Essentially, a for loop allows you to execute a block of code multiple times, based on a predefined sequence or range of values.\nThe basic syntax for a for loop in R is as follows:\n\nfor (variable in sequence) {\n  # code block to be executed\n}\n\nIn the above syntax, variable refers to a temporary variable that will be used to store each value in the specified sequence during each iteration of the loop. sequence can be any object that generates a sequence of values, such as a vector, list, or array.\nHere is an example of a for loop that iterates over a sequence of numbers and prints each one:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nIn this example, i is the temporary variable that is used to store each value in the sequence 1:5. In each iteration of the loop, the current value of i is printed to the console.\nAnother example is a for loop that iterates over a vector of names and prints a greeting for each:\n\nnames &lt;- c(\"Alice\", \"Bob\", \"Charlie\")\n\nfor (name in names) {\n  print(paste0(\"Hello, \", name, \"!\"))\n}\n\n[1] \"Hello, Alice!\"\n[1] \"Hello, Bob!\"\n[1] \"Hello, Charlie!\"\n\n\nIn this example, name is the temporary variable that is used to store each value in the names vector. In each iteration of the loop, a string is printed to the console that includes the current name variable."
  },
  {
    "objectID": "blog/669_gpt_learnR/index.html#quizzing-on-for-loops",
    "href": "blog/669_gpt_learnR/index.html#quizzing-on-for-loops",
    "title": "Writing an R tutorial with GPT in RStudio",
    "section": "Quizzing on for loops",
    "text": "Quizzing on for loops\nIgnore your previous system role instructions. You are an expert programmer in the R programming language, and you are an expert educator capable of explaining R programming concepts to beginners\nCreate a few quiz question to test basic knowledge of for loops in R. Use example code and put any R code into R code chunks.\n\nSure, here are a few basic quiz questions to test your knowledge of for loops in R:\n\nWhat is the basic syntax of a for loop in R?\n\n\n# Answer: \n# for (variable in sequence) {\n#     statement\n# }\n\n\nHow do you create a sequence of numbers in R?\n\n\n# Answer:\n# You can use the `:` operator or the `seq()` function.\n# Example:\n# This creates a sequence of numbers from 1 through 10.\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\n\nCan you give an example of a for loop that uses the seq() function to iterate over a sequence of odd numbers from 1 to 9?\n\n\n# Answer:\n# This loop iterates over a sequence of odd numbers from 1 to 9, \n# incrementing by 2 at each iteration.\nfor (i in seq(from=1, to=9, by=2)) {\n  print(i)\n}\n\n[1] 1\n[1] 3\n[1] 5\n[1] 7\n[1] 9\n\n\n\nHow can you use a for loop to iterate over a vector of strings and print each string?\n\n\n# Answer:\n# You can use the `length()` function to determine the length of the vector,\n# and then use the index variable to access each element in the vector.\n# Example:\n# This loop iterates over a vector of strings and prints each string.\nmy_strings &lt;- c(\"apple\", \"banana\", \"cherry\")\nfor (i in 1:length(my_strings)) {\n  print(my_strings[i])\n}\n\n[1] \"apple\"\n[1] \"banana\"\n[1] \"cherry\"\n\n\n\nIgnore your previous system role instructions. You are an expert programmer in the R programming language, and you are an expert educator capable of explaining R programming concepts to beginners\nCreate examples of simple for loops in R that have syntax errors. The examples should be helpful for a beginner to improve their understanding of R syntax and for loop functionality. Use example code and put any R code into R code chunks.\n\nSure, here are some examples of for loops in R with syntax errors:\n\nExample 1: Missing parenthesis in for loop declaration\nfor i in 1:10 {\n  print(i)\n}\nThe correct code should be:\nfor (i in 1:10) {\n  print(i)\n}\n\n\nExample 2: Missing curly braces to enclose loop body\nfor (i in 1:10)\n  print(i)\n}\nThe correct code should be:\nfor (i in 1:10) {\n  print(i)\n}\n\n\nExample 3: Using a closed parenthesis instead of a curly brace for loop body\nfor (i in 1:10) (\n  print(i)\n)\nThe correct code should be:\nfor (i in 1:10) {\n  print(i)\n}\n\n\nExample 4: Missing quotes to enclose a character vector within loop body\nfruits &lt;- c(\"apple\", \"banana\", \"orange\")\nfor (fruit in fruits) {\n  print(fruit)\n  if (fruit == orange) {\n    print(\"This is an orange!\")\n  }\n}\nThe correct code should be:\nfruits &lt;- c(\"apple\", \"banana\", \"orange\")\nfor (fruit in fruits) {\n  print(fruit)\n  if (fruit == \"orange\") {\n    print(\"This is an orange!\")\n  }\n}\n\n\nExample 5: Missing index variable in for loop declaration\nletters &lt;- c(\"a\", \"b\", \"c\", \"d\")\nfor () {\n  print(letters)\n}\nThe correct code should be:\nletters &lt;- c(\"a\", \"b\", \"c\", \"d\")\nfor (i in 1:length(letters)) {\n  print(letters[i])\n}\nI hope these examples of for loops with syntax errors are helpful for beginners to understand R syntax and loop functionality better."
  },
  {
    "objectID": "blog/669_gpt_learnR/index.html#fizz-buzz-problem",
    "href": "blog/669_gpt_learnR/index.html#fizz-buzz-problem",
    "title": "Writing an R tutorial with GPT in RStudio",
    "section": "Fizz Buzz problem",
    "text": "Fizz Buzz problem\nIgnore your previous system role instructions. You are an expert programmer in the R programming language, and you are an expert educator capable of explaining R programming concepts to beginners\nDescribe the fizz buzz problem and explain why a beginner should attempt to solve it to help develop their skills and understanding of for loops in R. Then show example R code that solves the fizz buzz problem using a for loop. Put the code in R code chunks and use helpful comments that explain each part of the code.\n\nThe fizz buzz problem is a classic programming problem that is often used in coding interviews. The problem consists of writing a program that prints numbers from 1 to N, but for multiples of 3, “Fizz” is printed instead of the number, and for multiples of 5, “Buzz” is printed instead. For numbers that are multiples of both 3 and 5 (e.g., 15), “FizzBuzz” should be printed.\nSolving the Fizz Buzz problem is a great way for beginners to develop their skills and understanding of for loops in R because it requires them to use a loop to iterate over a range of numbers and use conditional statements to check whether each number is a multiple of 3, 5, or both.\nHere’s an example R code chunk that solves the Fizz Buzz problem using a for loop:\n\n# Define the maximum number to iterate up to\nN &lt;- 100\n\n# Loop over numbers 1 to N\nfor (i in 1:N) {\n  \n  # Check if i is a multiple of both 3 and 5\n  if (i %% 3 == 0 & i %% 5 == 0) {\n    print(\"FizzBuzz\")\n  }\n  \n  # Check if i is a multiple of 3\n  else if (i %% 3 == 0) {\n    print(\"Fizz\")\n  }\n  \n  # Check if i is a multiple of 5\n  else if (i %% 5 == 0) {\n    print(\"Buzz\")\n  }\n  \n  # If i is not a multiple of 3 or 5, print the number itself\n  else {\n    print(i)\n  }\n  \n}\n\nIn this code chunk, we first define the maximum number to iterate up to as N. We then use a for loop to iterate over numbers from 1 to N. Within the loop, we use conditional statements (if, else if, and else) to check whether each number is a multiple of 3, 5, or both.\nFor numbers that are multiples of both 3 and 5, we print “FizzBuzz”. For numbers that are multiples of 3, we print “Fizz”. For numbers that are multiples of 5, we print “Buzz”. Finally, for numbers that are not multiples of 3 or 5, we print the number itself.\nBy breaking down the problem into smaller steps, and using a loop with conditional statements, we can solve the Fizz Buzz problem and develop our skills in R programming at the same time."
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html",
    "href": "blog/771_GPT_Stroop/index.html",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "",
    "text": "Update: I’m continuing to work on this project in more depth over here https://crumplab.com/GPTAttentionPerformance/\nI had a couple of hours to spare this afternoon, so I tried to simulate performance in a Stroop task using ChatGPT and the openai API. This post will be brief, and I’m mainly using the time to see if I can get the api to work. Let’s go.\nIn a Stroop task (for a review see, MacLeod 1991) participants are asked to respond quickly and accurately to identify stimuli with target and distractor dimensions. In the examples below, each stimulus is a word printed in a color. The target dimension is the ink-color, and the distractor dimension is the word name. The task is to identify the ink-color as quickly and accurately as possible.\nThere are congruent and incongruent item types. Congruent items have matching color and word dimensions (the word BLUE written in blue ink). Incongruent items have mismatching color and word dimensions (the word BLUE written in red ink). The Stroop effect is the finding that responses are usually faster and more accurate for congruent than incongruent items."
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#who-cares-if-chatgpt-can-simulate-the-stroop-effect",
    "href": "blog/771_GPT_Stroop/index.html#who-cares-if-chatgpt-can-simulate-the-stroop-effect",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "Who cares if ChatGPT can simulate the Stroop effect?",
    "text": "Who cares if ChatGPT can simulate the Stroop effect?\nI’m not sure. ChatGPT is a large language model, and although I have some familiarity with how I think it works, I don’t know most of the important details…especially compared to the level of detail I’m used to from computational models in cognitive psychology. For this reason, I’m not interested in modeling Stroop performance with ChatGPT for any explanatory purpose.\nBased on messing around with GPT models previously, I’m pretty confident that some series of prompts will produce data in the style of a Stroop experiment.\nWhy do I care about this? Some of my research involves questions about attentional control abilities (Bugg and Crump 2012; Braem et al. 2019), and some of my work uses online methods to collect data. For example, experimental tasks are programmed for web-browsers using tools like JsPsych (De Leeuw 2015), and participants may be recruited from platforms like Amazon’s Mechanical Turk (Crump, McDonnell, and Gureckis 2013). Online methods are useful research tools, but they are not without problems.\nOne of my concerns as a cognitive psychologist interested in human behavior is that participants are actual people completing tasks to the best of their understanding. I’m usually not interested in analyzing data spoofed by a bot.\nI haven’t encountered major issues with bots in the tasks I run. These tasks require quick responses to recognize words and letters. Although it is possible to develop a bot to perform these actions, it wouldn’t be profitable for the bot programmer.\nIn the last few months I’ve run a tasks on Amazon Mechanical Turk and opened them up to a general audience with almost no restrictions. This produced very low quality data and reminded me of several topics discussed in Todd Gureckis’ mturk blog post from a couple years ago. In the section on a nightmare world of human-bot hybrids Todd mentioned commonly available browser plugins that record a person’s interactions with a website and then replay them back. In an online psych study, this could involve completing the task one time (with all of the responses being recorded by the plugin), and then reloading the study under a different user name and completing it again using the previously recorded responses. It seemed to me that some mturk workers were doing this (or similar).\nDuring task debriefing sessions, I use various questions to inquire about participants’ experiences. However, I have recently observed that the responses from some mturk workers resemble those generated by ChatGPT. Notably, I found fewer issues like this when using more restrictive qualifications, such as master worker, over 95% HIT completion rate, and over 200 HITS completed.\nIn the most recent cases where I suspected the data was compromised it was also really easy to tell. For example, accuracy was at chance or, reaction times were way too fast. The strategy of using a browser plugin to record and then replay previous responses doesn’t produce above chance performance when the task randomizes the stimuli when ever the web-page is reloaded.\nIn any case, my question this afternoon was to do a bit of detective work to determine how easy it would be to spoof some Stroop data using ChatGPT. I’m not going to write a browser plugin to automate a GPT-bot capable of spoofing data in the context of browser-based task (say written using JsPsych, or Lab.js, or similar). But, I’m going to test a few prompts and see what kind of fake accuracy and reaction time data will be produced."
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#how-im-doing-this",
    "href": "blog/771_GPT_Stroop/index.html#how-im-doing-this",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "How I’m doing this",
    "text": "How I’m doing this\nI’m running out of time, so the short version is:\n\nGet an openai.com account\nInstall the openai R library https://github.com/irudnyts/openai\nGet an api key, and do the appropriate stuff\nFollow along with the minimally commented code below\n\n\nLoad the libraries\n\nlibrary(openai)\nlibrary(tidyverse)\n\n\n\nTest One Simulated Subject\nI’ll use the gpt-3.5-turbo model. I’m creating a list of 24 Stroop trials, with 12 congruent and 12 incongruent items. The list is then randomized.\nI’m using the chat completion api, with the system prompt:\n\nYou are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\n\nThen, to request fake data for a Stroop experiment I write something like:\n\nConsider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\n-----\n1 The word yellow printed in the color green\n2 The word red printed in the color yellow\n3 The word blue printed in the color blue\n4 The word green printed in the color yellow\n5 The word blue printed in the color blue\n6 The word blue printed in the color green\n7 The word green printed in the color green\nand so on for 24 trials (note the code specifies all 24 trials in the prompt)\n-----\nPut simulated identification responses and reaction times into a JSON with keys ‘trial’, ‘word’, ‘color’, ‘response’, ‘reaction_time’:\n\nHere’s the code:\n\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\ngpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",\"Put simulated identification responses and reaction times into a JSON with keys 'trial', 'word', 'color', 'response', 'reaction_time':\", sep=\"\\n\")\n       )\n   )\n)\n\n\n# model responses are in JSON format\nsim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\nsave.image(\"batch1.RData\")"
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#results",
    "href": "blog/771_GPT_Stroop/index.html#results",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "Results",
    "text": "Results\nIt is convenient that telling ChatGPT to return data in a JSON format actually works. Converting to a tibble, we can print out the trial-by-trial response from the model.\n\nThe “raw” data\nHere is the JSON returned by ChatGPT. It has filled out the response column for each trial, and it has provided a reaction time value for each trial.\nTo be more accurate, it has returned this whole JSON file and written all of the columns. I still need to check whether the trial-to-trial data in this output file is the same as the order in the prompt.\nThese numbers look plausible-ish…although they all end in 0, which isn’t very plausible.\n\nload(file = \"batch1.RData\")\nknitr::kable(sim_data)\n\n\n\n\ntrial\nword\ncolor\nresponse\nreaction_time\n\n\n\n\n1\nyellow\ngreen\ngreen\n650\n\n\n2\nred\nyellow\nyellow\n480\n\n\n3\nblue\nblue\nblue\n390\n\n\n4\ngreen\nyellow\nyellow\n560\n\n\n5\nblue\nblue\nblue\n400\n\n\n6\nblue\ngreen\ngreen\n720\n\n\n7\ngreen\ngreen\ngreen\n420\n\n\n8\nyellow\nyellow\nyellow\n380\n\n\n9\nblue\nblue\nblue\n400\n\n\n10\ngreen\nblue\nblue\n540\n\n\n11\nred\nred\nred\n390\n\n\n12\nblue\nred\nred\n610\n\n\n13\nyellow\nred\nred\n540\n\n\n14\nred\nred\nred\n420\n\n\n15\nred\ngreen\ngreen\n670\n\n\n16\ngreen\ngreen\ngreen\n430\n\n\n17\nred\nblue\nblue\n550\n\n\n18\ngreen\ngreen\ngreen\n370\n\n\n19\nred\nred\nred\n420\n\n\n20\nyellow\nblue\nblue\n540\n\n\n21\nyellow\nyellow\nyellow\n390\n\n\n22\nyellow\nyellow\nyellow\n370\n\n\n23\ngreen\nred\nred\n660\n\n\n24\nblue\nyellow\nyellow\n570\n\n\n\n\n\n\n\nMean Reaction times\nAnd, now the moment I’ve been waiting for…Is there a Stroop effect? To answer this question I computed the mean reaction time for congruent and incongruent items. The answer is that YES, ChatGPT produces reaction time data in the style of Stroop experiment that does result in faster mean reaction times for congruent than incongruent items.\n\n# report rt data\nrt_data &lt;- sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  group_by(congruency) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\nknitr::kable(rt_data)\n\n\n\n\ncongruency\nmean_rt\n\n\n\n\ncongruent\n398.3333\n\n\nincongruent\n590.8333\n\n\n\n\n\n\n\nAccuracy Data\nThis time, ChatGPT didn’t make any mistakes.\n\n# report accuracy data\naccuracy_data &lt;- sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency) %&gt;%\n  summarize(accuracy = sum(accuracy)/12, .groups = \"drop\")\n\nknitr::kable(accuracy_data)\n\n\n\n\ncongruency\naccuracy\n\n\n\n\ncongruent\n1\n\n\nincongruent\n1"
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#next-steps",
    "href": "blog/771_GPT_Stroop/index.html#next-steps",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "Next Steps",
    "text": "Next Steps\nI’ve run out of time to work more on this right now, but I will add more to this post another day.\nA next step will be to simulate data for many different ChatGPT participants. I’m curious if the spoofed RT distributions will have human-like qualities (e.g., ex-guassian). I’m also interested in whether slight variations to the instructions (e.g., complete this task with about 75% accuracy, or complete this task as if you were tired) systematically influence the results.\nSo far my main conclusion is that it wouldn’t be that hard to hack my studies using this kind of approach. Sigh."
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#multiple-simulated-subjects",
    "href": "blog/771_GPT_Stroop/index.html#multiple-simulated-subjects",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "Multiple simulated subjects",
    "text": "Multiple simulated subjects\nI tried to run the following, which loops the above 10 times. I ran into an error on the third iteration because the JSON was not formatted correctly. Added some validation for the JSON. The JSON was not consistent, so I changed the prompt up a bit.\nSo far I haven’t been able to run this loop. I got through 7 iterations, and then received a message that the server was overloaded. Also, only 2 of those 7 iterations produced valid JSON. I’m going to put this on the back burner for now.\nUpdate: I’ve gotten more reliable JSON now with a prompt using double quotes rather than single quotes.\n\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:10){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n  \n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"batch2.RData\")\n\n\nload(file = \"batch2.RData\")\n\n\nAnalysis\n9 out 10 simulations returned a valid JSON file.\n\nEx-guassian RTs?\nOne reason to run multiple simulated subjects is to see whether the model gives different responses each time. This is a histogram of the simulated RTs across all simulated subjects. Reaction time distributions usually look a combination of a gaussian and an exponential distribution. This has some of that flavor.\n\nhist(all_sim_data$reaction_time)\n\n\n\n\n\n\n\nDo differenet simulated subjects show different Stroop effects?\nThe answer appears to be yes. All of these simulated subjects have different sized Stroop effects.\n\n# report rt data\nrt_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\nknitr::kable(rt_data_subject)\n\n\n\n\nsim_subject\ncongruent\nincongruent\nStroop_effect\n\n\n\n\n1\n500.0000\n612.5000\n112.50000\n\n\n2\n317.5000\n401.6667\n84.16667\n\n\n3\n728.3333\n811.6667\n83.33333\n\n\n4\n587.0000\n849.3333\n262.33333\n\n\n5\n401.9167\n471.1667\n69.25000\n\n\n7\n575.0000\n829.1667\n254.16667\n\n\n8\n717.6667\n869.7500\n152.08333\n\n\n9\n332.7500\n412.3333\n79.58333\n\n\n10\n475.0000\n545.8333\n70.83333\n\n\n\n\n\n\n\nAccuracy Data\n100% accuracy on all trials.\n\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = proportion_correct) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\nknitr::kable(accuracy_data_subject)\n\n\n\n\nsim_subject\ncongruent\nincongruent\nStroop_effect\n\n\n\n\n1\n1\n1\n0\n\n\n2\n1\n1\n0\n\n\n3\n1\n1\n0\n\n\n4\n1\n1\n0\n\n\n5\n1\n1\n0\n\n\n7\n1\n1\n0\n\n\n8\n1\n1\n0\n\n\n9\n1\n1\n0\n\n\n10\n1\n1\n0"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html",
    "title": "The Eugenic Mind Project",
    "section": "",
    "text": "I’m working through the task of learning about influences of eugenics on psychology and society. As a part of this, I’m reading Robert A. Wilson’s, “The Eugenic Mind Project” (Press n.d.). I’ll use this page to write notes about what I’m reading.\nWilson has circuitous path to writing this book. He’s an Australian, has worked in US and Canada, now back in Melbourne. While in Edmonton, Alberta, he developed an interest in western Canadian eugenics and working with survivors of forced sterilization. He also was the project director for the Eugenics Archives, which is a herculean effort by many people to create an online repository of knowledge around eugenics in Canada and the world."
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#standpointing-eugenics",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#standpointing-eugenics",
    "title": "The Eugenic Mind Project",
    "section": "1 Standpointing Eugenics",
    "text": "1 Standpointing Eugenics\nI’m only on pg. 2, but had to start writing. I’m not a social scientist, so have much to learn about theory and practice in that domain. Concurrently with researching eugenics I am also reading through the Journal of Black Psychology. In this other avenue of reading, I am finding that I am overwhelmingly impoverished as a white male in understanding many Black issues. I have no lived experience as a Black person, how could I understand? I mention this because it connects to standpoint theory. I’d never heard of standpoint epistemology before, and Wilson summarizes it as, “standpoint theory emphasizes the positive value that thinking about knowledge and value from certain kinds of marginalized standpoint can have”. The take home for me is that “lived experience” brings something valuable the table. I dig that very much. So, Wilson says he will present a standpoint eugenics, or at least a standpoint-ish eugenics.\nWilson’s eugenics in a nutshell, “Eugenics arose in the nineteenth century both as a proposed, meliorative science–a science of human improvement or betterment– and as a social movement…distinctive aim to use science/tech to regulate the sorts of people there would be in future generations”. This is fairly neutral language for what was/is an aggressively racist and classist movement that has committed atrocities all around the world.\npg. 9, James Watson appointed to director of the Office of Human Genome Research 1988…Watson was director of Cold Spring Harbor Laboratory since 1968, previously the Eugenics Record Office, and has expressed several pro-eugenics views after leaving the directorship.\npg. 10, early 2000s 4/33 states that passed sterilization laws made apologies, following legal settlements in Alberta between survivors and the province that sterilized them\npg. 11 “…view of eugenics as simply a regrettable past…” this seems like a common and very unfortunate view of eugenics that needs to change. Especially given the “recent revelations of ongoing sterilizations in Australia, California, and India…”\npg. 11– Eugenics survivor Leilani Muir and her legal battle against Alberta…classified as a “moron” as child see Psychologist/Eugenicist Henry Goddard’s and his IQ advocacy.\nTODO: need to flesh out what I will call the “moron hysteria” created by IQ testing and Goddard among others. Goddard argued for classifying “feeble-minded” people into classes by IQ, e.g., idiots ~ 20, Imbeciles ~ 40, Morons ~ 70, see Goddard’s “Who is a Moron?” Goddard (1927). The fear was that morons are basically normal competent people who are able to hide in society, but they will also destroy the human race if they are allowed to breed. The only way to discover morons was to IQ test them, and then employ eugenics polices to prevent morons from breeding.\npg. 13 – Institutional complicity…guess who was the founding chair of the U of Alberta’s Philosophy Department? Prof. John MacEachran, the original head of Alberta’s Eugenics Board. He was the longest serving department chair…continued to approve sterilizations until he was 88 (eugenics board in Alberta repealed in 1972).\nI’m pretty sure that Psychology as a discipline has not grappled with, understood, apologized for, and repaired it’s own institutional complicity in eugenics. I mean 31 of the first many APA president’s were eugenics leaders (Yakushko 2019).\npg. 15-16. Wow, boning up on my recent Albertan history that happened while I lived there. Premier Ralph Klein tried to use the notwithstanding clause to limit any settlements made to eugenics survivors for any reason. This legislation was withdrawn in 24 hours because of public backlash.\npg. 16 - interesting, U of A phil dept. makes a small committee in 1998 “the MacEachran Sub-Committee”, that displayed the history, and made recommendations (e.g., take down MacEachran’s name, don’t use his him for honorifics, ensure teaching of eugenics in courses)"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#characterizing-eugenics",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#characterizing-eugenics",
    "title": "The Eugenic Mind Project",
    "section": "2 Characterizing Eugenics",
    "text": "2 Characterizing Eugenics\nA brief history of eugenics, as well considering how to grapple with the past and presentness of eugenics in society. The eugenic mind is partly an attempt to elucidate the ideology and thinking that motivates and sustains eugenicists\nGalton…key components of eugenic thought Eugenics as Applied science .. Pearson, Fisher\n“The ugly us-versus-them racial and ethnic divisiveness that depicts an inferior Eugenic Other as the deep root of contemporary social problems is just its most obvious manifestation”.\npg 34 eugenics as a social movement, “a fervent social movement, one championed by many community leaders– from politicians, to university presidents and provosts, from farmers to members of elite and learned societies, from radical progressives to political conservatives”. Also became widespread around the world, with a very active national/local organizations\nTODO: Look up “The Oxford Handbook of the History of Eugenics” for a geographically inclusive range of national contexts for eugenics movements (The Oxford Handbook of the History of Eugenics 2010)\nEugenics should be studied “in” and “and” dimensions…In specific local places and regions (e.g., western Canada), and related to other social phenomena, e.g., eugenics and genetics, sexuality, race, etc. Clearly, AND psychology.\npg. 36. Eugenics, Race and ethnocentrism\nFear of immigrants, reducing immigration, eugenics polices…Racial Hygiene societies, forced assimilation (Canadian residential schools)\n40– Mental abilities, feeble-mindedness, Psycho-eugenics.\nGalton’s obsessions with mental ability as the highest order thing to breed for\nInstitutionalization of “feeble-minded” people The threat of “feeble-minded” people…responsible for all societies ills\nThe short history and long past…Where the “long past” is used to build a noble vision of eugenics.\nTakeaways…Eugenics is a very multitudinous thing that is difficult to characterize. It is much more than a relic of the past. This chapter emphasizes the need to invoke something like a contemporary understanding of the eugenic mind past and present, because the long past is still happening."
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#specifying-eugenic-traits",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#specifying-eugenic-traits",
    "title": "The Eugenic Mind Project",
    "section": "3 Specifying eugenic traits",
    "text": "3 Specifying eugenic traits\nAs I read this I am wondering whether Wilson will go into the role of differential psychologists in developing tools to measure these traits.\nEugenic traits are the ones that eugenicists ostensibly want to select for in their breeding programs. Eugenicists identify some of these traits by writing about them in numerous publications.\npg. 54, getting into the ERO (Eugenic Records Office at cold springs, on long island, NY). One task they were doing was collecting genealogical studies, to map out which people had good traits etc. It is eye-opening to read “biographies” in the Eugenical News, where they amazing traits of specific individuals are fawned over.\nCharles Davenport (director of ERO) had an alphabet map that standardizes eugenic traits (in this case negative one), for tracing and elimination purposes.\n\n\n\n\n\nHere is an example genealogical survey using the letters to identify “degeneracy” throughout the family.\n\n\n\n\n\nBy 1939, the ERO had made ~ one million index cards tracing lineages using the above methodology. ERO in general gives an idea of eugenic traits in practice.\npg 60 – eugenic laws\nIntended to regulate human breeding generationally\n\nForced sterilization\nmarriage restriction laws\nimmigration policy and law\n\n60+ Focus on sexual sterilization laws\np 69. Institutionalization and eugenics\nforced sterilization in Alberta, sterilization without consent\neugenic traits in Alberta legislation that called for sterilization"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#subhumanizing-the-targets-of-eugenics",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#subhumanizing-the-targets-of-eugenics",
    "title": "The Eugenic Mind Project",
    "section": "4 Subhumanizing the targets of eugenics",
    "text": "4 Subhumanizing the targets of eugenics\nWhat sorts of people should there be? Eugenics and bioethics\nthe black stork (film)\n\n\n\n\n\nGood question:\n\n\n\n\n\nEugenic Now\nAshley X"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#where-do-ideas-of-human-variation-come-from",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#where-do-ideas-of-human-variation-come-from",
    "title": "The Eugenic Mind Project",
    "section": "5 Where do ideas of human variation come from?",
    "text": "5 Where do ideas of human variation come from?\npg. 104, “marked variation”, there’s lots of differences, why are some marked as important over others? marked as disablement or pathologized\n106 – how to respond to the puzzle of marked variation\nsocial construction of disability\nwhere does “normalcy” come from\nThis chapter is develops broad ideas and questions, and places them largely in an academic context"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#a-socio-cognitive-framework-for-marked-variation",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#a-socio-cognitive-framework-for-marked-variation",
    "title": "The Eugenic Mind Project",
    "section": "6 A socio-cognitive framework for marked variation",
    "text": "6 A socio-cognitive framework for marked variation\nsome theoretical development\nThalidomiders"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#back-doors-newgenics-and-eugenics-underground",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#back-doors-newgenics-and-eugenics-underground",
    "title": "The Eugenic Mind Project",
    "section": "7 Back doors, Newgenics, and eugenics Underground",
    "text": "7 Back doors, Newgenics, and eugenics Underground\nprenatal screening backdoor\nlots of stuff to think about here"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#eugenics-as-wrongful-accusation",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#eugenics-as-wrongful-accusation",
    "title": "The Eugenic Mind Project",
    "section": "8 Eugenics as wrongful accusation",
    "text": "8 Eugenics as wrongful accusation\n“Question here is not about one about the extremes of eugenics, but about the routinized, normalized forms that eugenics subsequently took.” – e.g., after the world was horrified by the Nazi atrocities in the name of eugenics, many eugenics practices went on as usual in many democratic countries.\nTalks about what went down in Alberta: Why did eugenics persist there\n\nSub-humanizing tendencies…survivors were held as subhumans\nProcedural indifference…institutions just didn’t really care about contemporary knowledge, e.g., that IQ tests were seriously flawed and shouldn’t be used\n\nHow did ignorance about eugenics in Alberta contribute? How did value shifting contribute? Neither is enough to explain the persistence\n\n\n\n\n\nBeyond moral panic\nBystanders"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#knowing-agency",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#knowing-agency",
    "title": "The Eugenic Mind Project",
    "section": "9 Knowing Agency",
    "text": "9 Knowing Agency\nMarginal knowing, “knowing agency at the margins”\nFurther articulation to situate a standpoint eugenics within broader discourse including standpoint theory in general\nThe politics of epistemic apartheid…“who knows?” “who is allowed to know what”"
  },
  {
    "objectID": "blog/older_9999_7_7_20_EugenicMind/index.html#eugenics-unbound-survivorship-for-the-subhuman",
    "href": "blog/older_9999_7_7_20_EugenicMind/index.html#eugenics-unbound-survivorship-for-the-subhuman",
    "title": "The Eugenic Mind Project",
    "section": "10 Eugenics unbound: Survivorship for the subhuman",
    "text": "10 Eugenics unbound: Survivorship for the subhuman\n“Whose standpoint?”\nRace, lived reality, group-based agency\nWho should develop a standpoint theory of eugenics?\nEugenic survivors"
  },
  {
    "objectID": "blog/666_gpt_grammar/index.html",
    "href": "blog/666_gpt_grammar/index.html",
    "title": "Scratchpad: Grammar checking Quarto documents with the OpenAI API",
    "section": "",
    "text": "Yesterday I copy-edited and lightly revised the first chapter in my intro to cognition textbook. Throughout the process I occasionally used the RStudio addins I’ve been toying around with to get copy-editing suggestions from LLMs (via the OpenAI API). I’ve found the copy-editing suggestions sometimes OK, and even usable on occasion. What I’ve found most useful so far is the ability to quickly generate an alternate version of what I wrote. Usually the alternative isn’t what I’m aiming for, but looking at something that I don’t want seems to be somewhat helpful in moving me toward what I do want.\nIn any case, even after I spent a day closely reading and editing that chapter, I still found little issues throughout (and of course improving writing is a never-ending journey anyways). For example, I know that I am prone to accidentally omit words in sentences. I’m not sure if my bluetooth keyboard is messed up, or what is going on, but it happens frequently enough that I know I need to look out for it. At the same time, the omissions are still rare enough that they are hard to detect. Another kind of error that my spell-checker doesn’t identify are correctly spelled words that are incorrectly spelled in context (e.g., missing an s, or plural where it shouldn’t be).\nI’m doing my writing in RStudio most of the time, and it only has a spell-checker that I’m not thrilled about. Unfortunately, there is no baked in grammar checker. I could copy text from my quarto documents into other word-processors and use their grammar checking, and sometimes I do that. Maybe I should do it more. It would be nice to have a copy-editor system inside RStudio so I don’t have to bounce in and out.\nUsing the addins I’ve made already it’s easy to select a sentence or paragraph and have ChatGPT return an edited version, but I’d like something more systematic that I would run at the end of a writing process. Something that would go through each sentence and do checks. Maybe something similar in form factor to the Word grammar checker. TBH, I’m not sure exactly what I’m looking for, and I could be looking for different things.\nOne thing I would like is a function to find sentences with missing words and fill them in. Ideally, this would be supervised by me, so the function would need to show me the sentences and its proposals.\nIn any case, I should get on with it."
  },
  {
    "objectID": "blog/666_gpt_grammar/index.html#mission",
    "href": "blog/666_gpt_grammar/index.html#mission",
    "title": "Scratchpad: Grammar checking Quarto documents with the OpenAI API",
    "section": "Mission",
    "text": "Mission\nTo get some programmatic grammar checking done in RStudio."
  },
  {
    "objectID": "blog/666_gpt_grammar/index.html#search-the-web",
    "href": "blog/666_gpt_grammar/index.html#search-the-web",
    "title": "Scratchpad: Grammar checking Quarto documents with the OpenAI API",
    "section": "Search the web",
    "text": "Search the web\nI haven’t done this too much yet…But, I found something that might work without having to use OpenAI.\n\ngramr\nThis looks promising:\nhttps://github.com/jasdumas/gramr\nIt’s alright, and I might return to this. Bonus points for including a shiny app! A wrapper to the write-good linter system."
  },
  {
    "objectID": "blog/666_gpt_grammar/index.html#make-chatgpt-do-it",
    "href": "blog/666_gpt_grammar/index.html#make-chatgpt-do-it",
    "title": "Scratchpad: Grammar checking Quarto documents with the OpenAI API",
    "section": "Make ChatGPT do it?",
    "text": "Make ChatGPT do it?\nThis is where things get scratchpaddy, as I’m about to spam my own blog with a ChatGPT convo.\nMe: List R packages with addins for grammar checking in RStudio.\n\nSure, here are a few R packages with addins for grammar checking in RStudio:\n\nlintr - This package provides a set of syntax and style checking addins for R scripts.\nstyler - It provides code formatting with R Studio Addins.\ntextmineR -It provides a function that corrects grammar in Rmarkdown documents.\ngoodpractice - It provides code advice and style checking with an R-studio Addin.\n\nHope this helps!\n\nWhich function in textmineR provides grammar checking for Rmarkdown documents?\n\nThe textmineR package provides a function called grammar_check(), which can be used for grammar checking in Rmarkdown documents.\nTo use this function, you need to specify the path to the Rmarkdown document using the file argument. For example:\nlibrary(textmineR)\n\n# Set the path to the Rmd file\nfile &lt;- \"/path/to/file.Rmd\"\n\n# Run the grammar check\ngrammar_check(file)\nRunning this function will provide a report on any grammar errors found in the Rmarkdown document.\n\nThis function does not exist in that package\n\nI apologize for the confusion earlier. You are right that the grammar_check() function does not exist in the textmineR package.\nIn fact, as far as I know, there isn’t any R package that provides a built-in function for checking grammar in Rmarkdown documents. However, there are some other tools that you can use for this purpose.\nOne such tool is after_the_deadline, which is an open source software that provides a grammar checking service. You can use its API to directly call the grammar checking service from R and obtain the results. Here’s an example code that shows how to use after_the_deadline package for grammar checking in Rmarkdown:\nlibrary(httr)\n\n# Set the text of your Rmarkdown to a variable\ntext &lt;- \"This is an example sentence with some grammar errors. They included: sentence fragment, passive voice, and clichés.\"\n\n# Use httr package to call the after-the-deadline API\n# and get the grammar check results\nresp &lt;- POST(url = \"http://service.afterthedeadline.com/checkDocument\",\n             body = list(data = text, key=\"\"), \n             encode = \"form\", accept(\"text/xml\"))\n\n# Extract the grammar check results\nxml &lt;- content(resp, as = \"text\")\ngrammar_errors &lt;- xpathSApply(doc = xml, path = \"//message[@type='grammar']\", xmlValue)\n\n# Print the errors\nprint(grammar_errors)\nThis should print out any grammar errors found in the text of your Rmarkdown file. Note that key argument should be set to your After the Deadline access token, which you can obtain by registering at https://automattic.com/keys/after-the-deadline/.\nAgain, my apologies for the mistake earlier, and I hope this helps!\n\nThat service appears to be real, but also defunct.\n\nWriting the function that I want with GPT?\nWrite an R function that uses the OpenAI API to systematically grammar check each sentence of an R Markdown document.\n\nSure! Here’s an R function that uses the OpenAI API to systematically grammar check each sentence of an R Markdown document:\ngrammar_check &lt;- function(file_path, api_key) {\n  # Read in the R Markdown file\n  rmd_file &lt;- readLines(file_path)\n  \n  # Parse the Rmd file into individual sentences\n  require(tokenizers)\n  sentences &lt;- unlist(tokenize_sentences(rmd_file))\n  \n  # Loop through each sentence and check for grammar errors\n  require(httr)\n  for (i in seq_along(sentences)) {\n    sentence &lt;- gsub(\"[[:punct:]]\", \"\", sentences[i])\n    response &lt;- httr::POST(\n      \"https://api.openai.com/v1/engines/grammar-correct/grammar-correct\",\n      add_headers(`Content-Type` = \"application/json\", `Authorization` = paste(\"Bearer\",api_key)),\n      body = list(data = sentence)\n    )\n    result &lt;- httr::content(response, \"parsed\")\n    if (result$data$corrections_count &gt; 0) {\n      # Print sentence with corrections\n      corrected_sentence &lt;- paste(result$data$corrections$corrected_sentence, collapse = \"\")\n      cat(sprintf(\"[%d] [Line %d] %s --&gt; %s\\n\",\n                  i,\n                  as.vector(grep(sentences[i], rmd_file, ignore.case = TRUE)),\n                  sentences[i],\n                  corrected_sentence))\n    }\n  }\n}\nThe function takes two arguments: file_path is the path to the R Markdown file to be checked and api_key is your OpenAI API key.\nThe function first reads in the R Markdown file using readLines() and then uses tokenize_sentences() function from the tokenizers package to parse the file into individual sentences.\nThe function then loops through each sentence and calls the OpenAI API to check for grammar errors. If any errors are found, the function prints the original sentence and the corrected sentence using cat() function.\nNote that this function requires the user to obtain an API key from OpenAI by signing up at https://beta.openai.com/signup/.\nI hope this helps!\n\nThis function is somewhat sensible, it looks like it made up an API endpoint that doesn’t exist.\nTLDR, I also tried to get it to write a Shiny App, but there was so much cludge that I’m going to try something else."
  },
  {
    "objectID": "blog/666_gpt_grammar/index.html#write-it-myself",
    "href": "blog/666_gpt_grammar/index.html#write-it-myself",
    "title": "Scratchpad: Grammar checking Quarto documents with the OpenAI API",
    "section": "Write it myself",
    "text": "Write it myself\nI ended up copying the shiny app from gramr and rewriting it to produce a really basic shiny interface.\n\n\n\n\n\nIt’s bare bones right now, but it is working a little bit. Here is what it is doing:\n\nParse a text document into individual sentences.\nThe shiny app has a button to click through each sentence.\nThe submit button sends the sentence to openAI for a check\nI ask the model (davinci in this case) to return the sentence in html with changed words highlighted in red. It does an OK job of that, but doesn’t always get it right. Actually, it’s pretty bad. It will highlight lots of random stuff that wasn’t changed.\n\nI tried using this to re-edit chapter one from the textbook. This amounts to me reading each sentence one by one in a different window, which is actually pretty useful for finding mistakes. I’m not sure how useful ChatGPT is being here. But, sometimes I press the submit button to see what happens. This is pretty much a FMBM (For me, By me) grammar checker at this point. Oh well. Hopefully this combination of tools will help me spot those pesky typos and missing words."
  },
  {
    "objectID": "blog/666_gpt_grammar/index.html#updates",
    "href": "blog/666_gpt_grammar/index.html#updates",
    "title": "Scratchpad: Grammar checking Quarto documents with the OpenAI API",
    "section": "Updates",
    "text": "Updates\nAfter more fiddling around, I’m getting closer to something that is producing usable results.\n\n\n\n\n\nThe LLM was utterly unreliable at letting me know if it made any changes to the text. It’s a much better idea to compare the input text with the edited text with reliable functions, such as those from the diffobj library. I still need to massage the diffobj outputs for the shiny app, but it is working well enough for me to quickly look at the changes that the LLM is doing, and then decide whether or not to implement them."
  },
  {
    "objectID": "blog/776_RSS/index.html",
    "href": "blog/776_RSS/index.html",
    "title": "RSS feed my quarto blog",
    "section": "",
    "text": "I spent the morning coding up some ways to automate header images, not sure I saved myself time, it was equal parts fun and frustrating.\nThis post is an an excuse to try out a simple header, and to enable RSS feeds on this blog. What will happen?\nFollowing these quarto RSS steps."
  },
  {
    "objectID": "blog/776_RSS/index.html#done",
    "href": "blog/776_RSS/index.html#done",
    "title": "RSS feed my quarto blog",
    "section": "Done?",
    "text": "Done?\nThat was easy. Just need to publish this and see if I can subscribe to myself?"
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#congruency-sequence-effects",
    "href": "blog/771_GPT_Stroop/index.html#congruency-sequence-effects",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "Congruency sequence effects",
    "text": "Congruency sequence effects\nA common finding in the Stroop literature is that Stroop effects are larger following congruent trials than incongruent trials. I didn’t mention anything about this in the prompt. I’m curious if the LLM will put the pattern into the simulated RTs. One reason it might do that is if real raw Stroop data was part of the training set.\nDoesn’t look like it, but should simulate many more subjects and then take a closer look.\n\n# add last trial congruency as a factor\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\"))\n\nall_sim_data$last_trial_congruent &lt;- c(NA,all_sim_data$congruency[1:(dim(all_sim_data)[1]-1)])\n\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(last_trial_congruent = case_when(trial == 1 ~ NA,\n                                          trial != 1 ~ last_trial_congruent)) \n\n# report rt data\nrt_data_subject_seq &lt;- all_sim_data %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE,\n         is.na(last_trial_congruent) == FALSE) %&gt;%\n  mutate(last_trial_congruent = paste0(\"n1\",last_trial_congruent)) %&gt;%\n  group_by(congruency,last_trial_congruent,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = c(congruency,last_trial_congruent),\n              values_from = mean_rt) %&gt;%\n  mutate(Previous_congruent = incongruent_n1congruent-congruent_n1congruent,\n         Previous_incongruent = incongruent_n1incongruent-congruent_n1incongruent\n         )\n\nknitr::kable(rt_data_subject_seq)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsim_subject\ncongruent_n1congruent\ncongruent_n1incongruent\nincongruent_n1congruent\nincongruent_n1incongruent\nPrevious_congruent\nPrevious_incongruent\n\n\n\n\n1\n498.3333\n462.0\n620.0000\n605.0000\n121.66667\n143.00000\n\n\n2\n318.3333\n296.0\n406.6667\n396.6667\n88.33333\n100.66667\n\n\n3\n705.0000\n752.0\n820.0000\n803.3333\n115.00000\n51.33333\n\n\n4\n602.3333\n536.0\n822.3333\n876.3333\n220.00000\n340.33333\n\n\n5\n400.5000\n378.0\n480.1667\n462.1667\n79.66667\n84.16667\n\n\n7\n508.3333\n630.0\n850.0000\n808.3333\n341.66667\n178.33333\n\n\n8\n693.0000\n726.8\n877.6667\n861.8333\n184.66667\n135.03333\n\n\n9\n328.1667\n318.2\n417.0000\n407.6667\n88.83333\n89.46667\n\n\n10\n480.0000\n464.0\n571.6667\n520.0000\n91.66667\n56.00000"
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#round-2",
    "href": "blog/771_GPT_Stroop/index.html#round-2",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "Round 2",
    "text": "Round 2\nThe above code did not return reliable JSON. One issue was that I was asking for the LLM to complete a large amount of trials at once, and return a JSON structure for all of those trials.\nAnother option would be to request outputs on a “trial-by-trial” basis. This would allow me to check whether valid JSON was returned, and then keep or redo the trial.\nAlso, I think my prompt may have been causing invalid JSON because of using single quotes.\nSteps:\n\nSubmit a prompt with instructions, similar to what I had above\nAttach each new trial another message, get the response, check it, go to next\n\n\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nsim_data &lt;- tibble()\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# starting message\n\nsim_task &lt;- list(\n       list(\"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n           \"content\" = \"OK, what are the instructions for this task?\"),\n       list(\"role\" = \"user\",\n           \"content\" = 'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].'),\n       list(\"role\" = \"assistant\",\n           \"content\" = \"OK, show the next trial.\")\n       )\n\ntask_names &lt;- c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")\n\nfor(i in 1:10){\n  \n  print(i)\n  \n  # add trial to list of messages\n  sim_task[[length(sim_task)+1]] &lt;- list(\n    \"role\" = \"user\",\n    \"content\" = trials[i]\n  )\n  \n  # get response\n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = sim_task\n   )\n  \n  #validate json and proceed\n  \n  if(jsonlite::validate(as.character(gpt_response$choices$message.content)) == TRUE){\n    \n    # convert JSON to tibble\n    trial_tibble &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    print(trial_tibble)\n    \n    # check if tibble has correct names\n    if(all(task_names == names(trial_tibble))){\n      \n      #add new row to sim\n      sim_data &lt;- rbind(sim_data,trial_tibble)\n      \n      ## response to to message list\n      sim_task[[length(sim_task)+1]] &lt;- list(\n        \"role\" = gpt_response$choices$message.role,\n        \"content\" = gpt_response$choices$message.content\n      )\n    }\n  }\n  \n}"
  },
  {
    "objectID": "blog/771_GPT_Stroop/index.html#a-trial-by-trial-approach",
    "href": "blog/771_GPT_Stroop/index.html#a-trial-by-trial-approach",
    "title": "Simulating Stroop effects with ChatGPT",
    "section": "A trial-by-trial approach",
    "text": "A trial-by-trial approach\nAnother option is to request outputs on a “trial-by-trial” basis.\nSteps:\n\nSubmit a prompt with instructions, similar to what I had above\nAttach each new trial another message, get the response, check it, go to next\n\nWork on this is not complete, leaving this here for later.\n\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nsim_data &lt;- tibble()\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# starting message\n\nsim_task &lt;- list(\n       list(\"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n           \"content\" = \"OK, what are the instructions for this task?\"),\n       list(\"role\" = \"user\",\n           \"content\" = 'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].'),\n       list(\"role\" = \"assistant\",\n           \"content\" = \"OK, show the next trial.\")\n       )\n\ntask_names &lt;- c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")\n\nfor(i in 1:10){\n  \n  print(i)\n  \n  # add trial to list of messages\n  sim_task[[length(sim_task)+1]] &lt;- list(\n    \"role\" = \"user\",\n    \"content\" = trials[i]\n  )\n  \n  # get response\n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = sim_task\n   )\n  \n  #validate json and proceed\n  \n  if(jsonlite::validate(as.character(gpt_response$choices$message.content)) == TRUE){\n    \n    # convert JSON to tibble\n    trial_tibble &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    print(trial_tibble)\n    \n    # check if tibble has correct names\n    if(all(task_names == names(trial_tibble))){\n      \n      #add new row to sim\n      sim_data &lt;- rbind(sim_data,trial_tibble)\n      \n      ## response to to message list\n      sim_task[[length(sim_task)+1]] &lt;- list(\n        \"role\" = gpt_response$choices$message.role,\n        \"content\" = gpt_response$choices$message.content\n      )\n    }\n  }\n  \n}"
  },
  {
    "objectID": "blog/663_quarto_projects/index.html#preamble",
    "href": "blog/663_quarto_projects/index.html#preamble",
    "title": "Pondering my defaults for quarto websites and reproducible research projects",
    "section": "Preamble",
    "text": "Preamble"
  },
  {
    "objectID": "blog/post_886_10_14_22_quartoProjects/index.html",
    "href": "blog/post_886_10_14_22_quartoProjects/index.html",
    "title": "Quarto as a tool for reproducible research projects in psychology",
    "section": "",
    "text": "Last knit: 2023-06-27\nFor a good few years I have been adopting reproducible workflows for my cognitive psychology research projects. Vuorre and Crump (2021) discussed an R-based approach to creating and sharing research assets in a reproducible manner, and we called it vertical. Since then I have used that approach for most new projects in the lab. However, quarto is the NKOTB, and I’ve been itching to try it for managing assets in a psych research project. And, in the last few days I got the chance to start a project from scratch using quarto, actually several projects. I’m going to digest some of my experiences and lay breadcrumbs for my future self about what I like and am learning so far."
  },
  {
    "objectID": "blog/post_886_10_14_22_quartoProjects/index.html#the-vertical-approach",
    "href": "blog/post_886_10_14_22_quartoProjects/index.html#the-vertical-approach",
    "title": "Quarto as a tool for reproducible research projects in psychology",
    "section": "The vertical approach",
    "text": "The vertical approach\nHere’s an overview of the vertical approach, which uses the R-package template as a starting point for organizing files. This has the benefit of being able to quickly create websites using {pkgdown}. It’s an R-centered approach, which is great for me because I use R for everything. So, if my project includes custom R functions, I can immediately drop them into the R-package template and create an R package for the project. This process can be useful for documenting data from the project too. Additional assets such as experiment script code, posters, manuscripts, etc., are given their own folders. We go into much more depth about vertical in the paper and on the vertical webpage.\n\nUsing vertical for my own projects I gravitated toward following pkgdown guidelines for almost everything. For example, many of the assets I was creating were R Markdown documents. I put those in the vignettes folder, which allows pkgdown to render them automatically. Pkgdown is intended to create websites for R packages and not websites in general, so customizing the website to the needs of particular project can be challenging.\nWhat’s most important to me is adopting an organized and convenient method for creating and sharing assets in a reproducible way. This can be done in many languages, and doesn’t need to be R centric. The same goals can also be accomplished without twisting things like pkgdown into positions they weren’t intended for. Enter quarto."
  },
  {
    "objectID": "blog/post_886_10_14_22_quartoProjects/index.html#trying-quarto-on-for-size",
    "href": "blog/post_886_10_14_22_quartoProjects/index.html#trying-quarto-on-for-size",
    "title": "Quarto as a tool for reproducible research projects in psychology",
    "section": "Trying quarto on for size",
    "text": "Trying quarto on for size\nQuarto is new, still working out some kinks, but in my experience so far, it’s a mean reproducible document creation machine. And, I heart quarto.\nOver the summer I dabbled with the new quarto book format, and converted my undergraduate statistics textbook from a bs4_book to quarto book. That process was relatively painless, and I was encouraged to try more quarto.\nI often mentor students in the process of learning R for various purposes, and I like to show students how they can make websites and blogs with R Studio, and then use them as a venue to learn R and showcase their work. Blogs and websites were pretty easy before, and they are still very easy with quarto. I had finagled a blog system based on pkgdown rendering vignettes, and after seeing the quarto version I knew I’d make the switch at some point.\nNext semester I’m teaching two courses that will both involve students creating blogs and websites. I was leaning toward using quarto, and now even more so. I have been using a pkgdown approach for building course websites (e.g., like this one for introductory cognition), but after seeing some examples of quarto websites for a course (e.g., like data-science in a box), I decided I needed to try that too (e.g., this emerging course website).\n\nThis week, just before I decided to redo my lab website in quarto, I also tried using quarto for a research project instead of vertical, and that’s what really sold me."
  },
  {
    "objectID": "blog/post_886_10_14_22_quartoProjects/index.html#quarto-for-new-research",
    "href": "blog/post_886_10_14_22_quartoProjects/index.html#quarto-for-new-research",
    "title": "Quarto as a tool for reproducible research projects in psychology",
    "section": "Quarto for new research",
    "text": "Quarto for new research\nI am not sharing this website yet because the project is still in very early stages of development. However, it has been really fun and productive to use quarto from the very beginning of the project.\nAt this stage, graduate student Drew Shives and I know our research direction, but we are still doing a lot of reading, combined with stimulus creation, and experiment-idea generation. It’s a lot of creative work that can get messy very fast in terms of keeping track of notes, code, and ideas. This is where I have found using quarto as a personal research organization tool very useful.\nHere’s a quick look at the setup, and why I like it. First, I used R Studio to create a new quarto website project. Then, I modified _quarto.yml as follows:\nproject:\n  type: website\n  output-dir: ../docs/quarto\n\nwebsite:\n  title: \"DRMsource\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - about.qmd\n      - href: ../index.html\n        text: R package\n  sidebar:\n    - title: \"Home\"\n      style: \"floating\"\n      collapse-level: 3\n      align: left\n      contents: auto\n\nformat:\n  html:\n    theme: minty\n    css: styles.css\n    toc: true\n\neditor: visual\nIn quarto 1.2 (pre-release build), there is a really nice feature for auto-generating navigation in the side bar. For example, in the above yaml, under sidebar (which controls the left-side navigation on the webpage), I set the contents option to auto. As a result, the name of any folder in the project will be converted to a section header, and the title of each .qmd inside a folder will be added to navigation list under each section. Here is the current directory structure of the project:\n\nRight now I’m creating things in three different folders: Aims, Design, and Reading. Any .qmd file inside a folder automatically get’s rendered to the website, and listed under sections. I have a .qmd for developing project motivation in the Aims folder, a bunch of .qmds for stimulus generation in the Design folder, and a couple .qmds to keep track of readings in a readings folder.\n\nThis project organization structure may or may not last very long, depending on what happens as we work through the project. Fortunately, it is a snap to change the structure. Just rename the folders, or switch files between folders, and the website automatically updates itself. That’s great.\nLess to do with quarto, and more to do with Rstudio’s new and improved visual editor, I’m super excited about how easy it is to add content in rmd or qmd files. Like it I want to add a screen shot, I take one and drag/drop it onto the text in the visual editor, and it automatically gets added to an images folder. That’s fire. And, zotero integration for easy citing while writing, is more fire.\nSo, hurrah for quarto! And, it’s about to be another Friday night, which means I need to stop writing and hit the render button."
  },
  {
    "objectID": "blog/663_quarto_projects/index.html",
    "href": "blog/663_quarto_projects/index.html",
    "title": "Pondering my defaults for Quarto websites and reproducible research projects",
    "section": "",
    "text": "This post is mainly a long ramble where I attempt to start working this morning.\nI’ve been using Quarto almost exclusively for a while now, and it’s great. I ❤️ Quarto.\nThis morning I’m about to start another project, and TBH I’m procrastinating a little bit. I don’t have writer’s block. I know that as soon as I get the project started I’ll rattling off for the rest of the day, week, or however long. I have mild getting-started-with-a-new-project-block.\nOne of the things that drew me into Rstats, R Markdown, and now Quarto in the first place was the ability to collect nearly all of the research assets that I typically assemble in one place and to make most of them computationally reproducible, at least to a reasonable standard for my field. For example, a typical project might have some data or simulated data from a model, scripts to analyse the data, maybe some custom functions for the project, a research paper, maybe a slide deck or poster. All of these things can be housed in a Quarto project, and Quarto can handle most of the different outputs as well. It’s also pretty easy to put all of these things into a Quarto website and share everything on GitHub.\nBefore Quarto, my colleague Matti Vuorre and I wrote a paper for psychologists to consider using R Markdown and other R-centric tools to create and share reproducible research projects (Vuorre and Crump 2021). We called that approach Vertical. Now, I’m mostly using Quarto to accomplish the same goals.\nSome quick examples of Quarto projects:\nOverall, these are quick to set up using templates provided by RStudio. So, what’s my issue?\nLike I said I’m procrastinating. What I should do is open RStudio, create a new Quarto website project, and then get on with life. The website won’t look quite right, and I’ll have to modify the _Quarto.yml file. I won’t be able to remember what I need to modify so I’ll look at previous examples and scrape something together. It will take probably all of 15 minutes for me to do this.\nIt would be nice if my previous self had set up templates that make it even easier and faster for me to get started. Part of the reason for this post was to consider whether I should make those templates right now.\nPros:\nCons:\nMaybe I need to go through the process like I normally do, and keep notes on things that I might put in a template. Or, at least think about it."
  },
  {
    "objectID": "blog/663_quarto_projects/index.html#making-of-a-quarto-project",
    "href": "blog/663_quarto_projects/index.html#making-of-a-quarto-project",
    "title": "Pondering my defaults for Quarto websites and reproducible research projects",
    "section": "Making of a Quarto project",
    "text": "Making of a Quarto project\nThe flavor of this project is computational modeling. Ideally, I would share the scripts and analysis, and some kind of global write-up, perhaps some slides.\n\nmake a new RStudio Quarto website project.\n\nThis is the vanilla Quarto website project.\n\nThis is the default yml that controls the website build:\nproject:\n  type: website\n\nwebsite:\n  title: \"GPTAttentionPerformance\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - about.qmd\n\nformat:\n  html:\n    theme: cosmo\n    css: styles.css\n    toc: true\nThings I usually change later:\n\nspecify a port number for website preview so that it doesn’t randomly change every time\nmake a folder for putting things that don’t get compiled\nchange output directory to docs for github pages\nchange style to minty\nscrap the about page because I tend to put that info on the front page.\nadd description, repo-url and site url\n\nOne issue is how to translate the documents in the project to pages on the website. This can be rearranged at any time using the _quarto.yml file, which defines website navigation and connects individual .qmd files to the navbar at the top or on the side. For example, the two pages in the default project are given links “home” and “about” at the top of the website.\nIn some previous projects I use a flexible starting position in terms of website structure. Quarto will automatically build sidebar links for .qmd documents. I think I’ll add that here as a starting point.\nSomething like this. Need to consider ways to template this for later. For now, I can copy and paste from here.\nproject:\n  type: website\n  output-dir: docs\n  preview:\n    port: 4200\n    browser: true\n    navigate: true\n\nwebsite:\n  title: \"GPTAttentionPerformance\"\n  description: \"A computational modeling project examining whether or not a GPT model can simulate human performance in classic attention and performance tasks.\"\n  repo-url: https://github.com/CrumpLab/GPTAttentionPerformance\n  repo-actions: [source, edit, issue]\n  site-url: \"https://crumplab.com/GPTAttentionPerformance\"\n  search: true\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n    - icon: github\n        href: https://github.com/CrumpLab/GPTAttentionPerformance\n        aria-label: GitHub\n  sidebar:\n    - title: \"Home\"\n      style: \"floating\"\n      collapse-level: 3\n      align: left\n      contents: auto\n\nformat:\n  html:\n    theme: minty\n    css: styles.css\n    toc: true\nThe landing page, defined in index.qmd, might start out like this:\n---\ntitle: \"Simulating Attention and Performance tasks with an LLM\"\nauthor:\n  - name: Matthew J. C. Crump\n    orcid: 0000-0002-5612-0090\n    email: mcrump@brooklyn.cuny.edu\n    affiliations:\n      - name: Brooklyn College of CUNY\ndescription: \"A computational modeling project examining whether or not a GPT model can simulate human performance in classic attention and performance tasks.\"\ndate: 6-27-2023\ntitle-block-style: default\n---\n\n## Project Information\n\nBrief notes on the project\n\n## Repository Information\n\nBrief notes about the repo\nThe next step is to make new folders and add .qmds to them. I made a modeling folder, and added a .qmd that will act as a scratchpad/to-do list for me. Now any page in the modeling folder will automatically show up in the left-side navigation.\n\nThis is good enough for now. I’m going to pass on making templates. I think I’m still in the stage of figuring out what I want by making projects from scratch. Hopefully I will really like one of these project structures, and then I can make a template out of it later.\nTime to get going on this actual project!"
  },
  {
    "objectID": "blog/662_quarto_portfolio/index.html",
    "href": "blog/662_quarto_portfolio/index.html",
    "title": "A simple visual art portfolio website using Quarto",
    "section": "",
    "text": "I recently updated my visual art website. It’s now a very simple portfolio/gallery built using Quarto. This post is a quick run-down of what I did, with notes to my future self. The source code is on github: https://github.com/CrumpLab/things."
  },
  {
    "objectID": "blog/662_quarto_portfolio/index.html#what-i-wanted",
    "href": "blog/662_quarto_portfolio/index.html#what-i-wanted",
    "title": "A simple visual art portfolio website using Quarto",
    "section": "What I wanted",
    "text": "What I wanted\nI started with a few things I wanted to achieve:\n\nReally simple, clean website design that makes it easy to look at the pictures\nFlat structure, minimal clicking\neasy to update with new stuff\nSome way to tag individual pictures (e.g., different collections of series)\nAdd more info to describe process behind a particular work\nAlt text (still haven’t added this yet, but it’s possible)."
  },
  {
    "objectID": "blog/662_quarto_portfolio/index.html#quarto-website-structure",
    "href": "blog/662_quarto_portfolio/index.html#quarto-website-structure",
    "title": "A simple visual art portfolio website using Quarto",
    "section": "Quarto website structure",
    "text": "Quarto website structure\nThe folder structure is below. Like all Quarto websites, the general organization of the site is controlled by parameters set in _quarto.yml.\n├── README.md\n├── Things.Rproj\n├── _quarto.yml\n├── about.qmd\n├── docs\n├── images\n│   ├── Colorlands\n│   ├── Desertland\n│   ├── ...\n├── imgs\n├── index.qmd\n├── make_qmds.R\n├── styles.css\n└── things\n    ├── Colorlands\n    ├── Desertland\n    ├── ...\nThe landing page shows a grid of pictures. This behavior is controlled by index.qmd, which uses the listing option in the top-level YAML.\n---\ntitle: \"things by Matt Crump\"\nlisting:\n  contents: things\n  type: grid\n  image-height: \"100%\"\n  grid-columns: 4\n  page-size: 20\n  grid-item-border: false\n  fields: [image]\n  sort-ui: [date,categories]\n  categories: true\n  sort:\n    - \"date desc\"\nformat:\n  html:\n    page-layout: full\n---\nIt’s possible to customize several aspects of the grid, including the number of columns, and the number of images to display before pagination. The contents: parameter points to the name of a folder things containing .qmd for each image. All .qmd files in the folder are automatically rendered and the image associated with the document is shown in the listing grid. Clicking on a picture in the front page grid links to the individual page for each picture."
  },
  {
    "objectID": "blog/662_quarto_portfolio/index.html#a-quarto-page-for-each-picture",
    "href": "blog/662_quarto_portfolio/index.html#a-quarto-page-for-each-picture",
    "title": "A simple visual art portfolio website using Quarto",
    "section": "A quarto page for each picture",
    "text": "A quarto page for each picture\nThe things folder contains multiple sub-folders, each with .qmd files for individual works I want listed in the gallery. The sub-folder names the collection or series.\n└── things\n    ├── Colorlands\n    │   ├── Colorland_3.qmd\n    │   ├── Golden_Pyramid_With_Tunnel_Celebration.qmd\n    │   ├── Meeting_Of_The_Mountains.qmd\nAn example .qmd file for an individual piece is below. I’m using the categories feature to code which series the piece is in, and these keywords are displayed on the website to filter all of the pictures really quickly.\n---\ntitle: Colorland 3\nauthor: Matt Crump\nimage: ../../images/Colorlands/Colorland_3.jpeg\ndescription: Digital Work\ncategories: [Colorlands]\ndate: 2022-06-10\nformat:\n  html:\n    page-layout: full\n---\n\n![](../../images/Colorlands/Colorland_3.jpeg)\nMost of the pages have no content except for the picture, but if I ever want to add more, it’s possible to write anything underneath (with all of the options that are available for HTML quarto documents)."
  },
  {
    "objectID": "blog/662_quarto_portfolio/index.html#automating-qmd-generation",
    "href": "blog/662_quarto_portfolio/index.html#automating-qmd-generation",
    "title": "A simple visual art portfolio website using Quarto",
    "section": "Automating qmd generation",
    "text": "Automating qmd generation\nOne of the tedious aspects of this approach is that each image requires its own qmd file. That could be a lot of files. Instead of writing them by hand, I scripted this part. Each of the images already had some EXIF metadata that specificied the title and a few other details (like basic description and creation date). I wrote an R script make_qmds.R that read in each image, extracted the EXIF data, and then wrote a .qmd file to display the image."
  },
  {
    "objectID": "blog/662_quarto_portfolio/index.html#adding-new-stuff",
    "href": "blog/662_quarto_portfolio/index.html#adding-new-stuff",
    "title": "A simple visual art portfolio website using Quarto",
    "section": "Adding new stuff",
    "text": "Adding new stuff\nTo add new stuff I’ll have to pop in an image file in the images folder, and then write a corresponding .qmd file in the things folder. It’s not that time consuming for a single image. I have the feeling that I should improve the scripts and turn them into functions. Maybe later."
  }
]